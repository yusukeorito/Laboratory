{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusukeorito/Laboratory/blob/main/Exp010_Train_model001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k4jttm-bBRQw",
        "outputId": "d36a993b-6ab2-47f8-fecd-6cdc71c75f7e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n問題設定：分類問題\\n学習データサイズ M：訓練6000、テスト10000\\nレイヤー数L : 10 or 20\\nネットワークの幅N:100\\nノイズパラメータλ:1.5\\n\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "問題設定：分類問題\n",
        "学習データサイズ M：訓練6000、テスト10000\n",
        "レイヤー数L : 10 or 20\n",
        "ネットワークの幅N:100\n",
        "ノイズパラメータλ:1.5\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJH8A7QCbdT",
        "outputId": "1da5de8c-0d4f-447c-c1ae-0634ba7f2ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_tPowEVCb-b",
        "outputId": "fbcc3973-6de6-4f34-c363-1a7ed3dbd54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Master_research/exp010\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Master_research/exp010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW8siZNYCkfh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,Activation\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class CFG:\n",
        "    task = 'classification'\n",
        "    seed1 = 820\n",
        "    seed2=314\n",
        "    data_seed = 42\n",
        "    save_dir = '../Model/'\n",
        "    output_dir = '../Output/'\n",
        "    L=10\n",
        "    M=60000\n",
        "    N=100\n",
        "    #A=1.5#ノイズの強さ\n",
        "    C=10#結合を持つweightの個数\n",
        "    ini_type = 'A'\n",
        "    train='train'\n",
        "    mean = 0.5  # 平均\n",
        "    std_dev = 0.1  # 標準偏差\n",
        "    layer_name_list =['batch_normalization1', 'batch_normalization2', 'batch_normalization3',\n",
        "                   'batch_normalization4', 'batch_normalization5', 'batch_normalization6', 'batch_normalization7', 'batch_normalization8',\n",
        "                   'batch_normalization9','batch_normalization10',]\n",
        "\n",
        "def set_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    # optional\n",
        "    # for numpy.random\n",
        "    np.random.seed(seed)\n",
        "    # for built-in random\n",
        "    random.seed(seed)\n",
        "    # for hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "def preprocess_data(X_train_, y_train_):\n",
        "    # Rasterize and normalize samples\n",
        "\n",
        "    X_train_ = X_train_.reshape(X_train_.shape[0], -1)\n",
        "    y_train_ = y_train_.reshape(y_train_.shape[0], -1)\n",
        "\n",
        "    X_train_ = X_train_ / 255\n",
        "    y_train_ = y_train_ / 255\n",
        "\n",
        "    # Use 32-bit instead of 64-bit float\n",
        "    X_train_ = X_train_.astype(\"float32\")\n",
        "    y_train_ = y_train_.astype(\"float32\")\n",
        "\n",
        "    return X_train_, y_train_\n",
        "\n",
        "def PCA_SS_func(input_train,input_test):\n",
        "  input_d=100\n",
        "  # Make an instance of the Model\n",
        "  pca = PCA(n_components=input_d)\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  train_img = pca.fit_transform(input_train)\n",
        "  print(np.sum(pca.explained_variance_ratio_[:]))\n",
        "  train_img =scaler.fit_transform(train_img)\n",
        "  test_img = pca.transform(input_test)\n",
        "  test_img =scaler.transform(test_img)\n",
        "  print('Train:',train_img.shape)\n",
        "  print('Test:',test_img.shape)\n",
        "  return train_img, test_img, pca, scaler\n",
        "\n",
        "class LogEpochIntermediateCallcack(Callback):\n",
        "  def __init__(self, layer_name_list,model_num):\n",
        "    self.layer_name_list = layer_name_list\n",
        "    self.spin_dict = {key: [] for key in self.layer_name_list}\n",
        "    #self.spin_dict_test = {key: [] for key in self.layer_name_list}\n",
        "    self.nextMeas=1\n",
        "    self.model_num = model_num\n",
        "\n",
        "\n",
        "  def on_train_begin(self, batch, logs=None):\n",
        "    self.spin_dict['time'] = [0]\n",
        "    #self.spin_dict_test['time'] = [0]\n",
        "    for l in self.layer_name_list:\n",
        "      intermediate_layer_model = tf.keras.Model(inputs=self.model.input,outputs=self.model.get_layer(l).output)\n",
        "      if CFG.M == 60000:\n",
        "        intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "      else:\n",
        "        ntermediate_output = intermediate_layer_model.predict(X_train)\n",
        "      #intermediate_output_test = intermediate_layer_model.predict(test_in)\n",
        "      tf.keras.backend.clear_session()\n",
        "      self.spin_dict[l].append(intermediate_output)\n",
        "      #self.spin_dict_test[l].append(intermediate_output_test)\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "      self.ep = epoch\n",
        "\n",
        "  def on_epoch_end(self, batch, logs):\n",
        "      if self.ep+1==self.nextMeas:\n",
        "        for l in self.layer_name_list:\n",
        "          intermediate_layer_model = tf.keras.Model(inputs=self.model.input,outputs=self.model.get_layer(l).output)\n",
        "          if CFG.M == 60000:\n",
        "            intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "          else:\n",
        "            intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "          #intermediate_output_test = intermediate_layer_model.predict(test_in)\n",
        "          tf.keras.backend.clear_session()\n",
        "          self.spin_dict[l].append(intermediate_output)\n",
        "          #self.spin_dict_test[l].append(intermediate_output_test)\n",
        "        self.spin_dict['time']+=[self.ep+1]\n",
        "        #self.spin_dict_test['time']+=[self.ep+1]\n",
        "        self.nextMeas=int(self.nextMeas*1.1)\n",
        "        if self.ep+1==self.nextMeas:\n",
        "          self.nextMeas = self.nextMeas+1\n",
        "\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    for l in self.layer_name_list:\n",
        "      self.spin_dict[l] = np.array(self.spin_dict[l])\n",
        "      #self.spin_dict_test[l] = np.array(self.spin_dict_test[l])\n",
        "    with open(f'./Output/Spin/M{CFG.M}/model{self.model_num}_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "      pickle.dump(self.spin_dict, handle)\n",
        "    #with open(f'./Output/Spin/M600/model{self.model_num}_M{CFG.M}_L{CFG.L}_A{CFG.A}_test.txt','wb') as handle:\n",
        "        #pickle.dump(self.spin_dict_test, handle)\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean, std_dev, alpha):\n",
        "    noise = np.random.normal(mean, std_dev, image.shape)\n",
        "    noisy_image = image + alpha * noise\n",
        "    return np.clip(noisy_image, 0, 1)  # ピクセル値を0から1の範囲にクリップ\n",
        "\n",
        "\n",
        "\n",
        "class CustomConstraint(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, mask):\n",
        "        self.mask = mask\n",
        "\n",
        "    def __call__(self, w):\n",
        "        # マスク行列を使用して、指定された部分を0で固定する\n",
        "        w.assign(tf.math.multiply(w, self.mask))\n",
        "        return w\n",
        "\n",
        "def get_mask(shape, C, dtype=int):\n",
        "    \"\"\"\n",
        "    C:コネクションを持つweightの数\n",
        "    \"\"\"\n",
        "    masks = np.zeros(shape)\n",
        "    for col in range(shape[1]):\n",
        "        non_zero_indices = np.random.choice(shape[0], C, replace=False)\n",
        "        masks[non_zero_indices, col] = 1\n",
        "    return tf.constant(masks, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "def create_model(params:dict,w_initializer,Mask_list):\n",
        "    \"\"\"\n",
        "    Creates a neural network model based on the given parameters.\n",
        "\n",
        "    Args:\n",
        "        params (dict): Dictionary containing model parameters.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = Sequential(name='custom_model')\n",
        "    model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],input_shape=(params['input_size'],), name='Affine1',kernel_constraint=CustomConstraint(mask=Mask_list[0])))\n",
        "    model.add(BatchNormalization(name='batch_normalization1'))\n",
        "    model.add(Activation('relu', name='activation1'))\n",
        "    for i in range(1, params['num_layers'] - 1):\n",
        "        model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name=f'Affine{i+1}',kernel_constraint=CustomConstraint(mask=Mask_list[i])))\n",
        "        model.add(BatchNormalization(name=f'batch_normalization{i+1}'))\n",
        "        model.add(Activation('relu',name=f'activation{i+1}'))\n",
        "\n",
        "    model.add(Dense(params['output_size'],kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name='output',kernel_constraint=CustomConstraint(mask=Mask_list[9])))\n",
        "    model.add(BatchNormalization(name=f'batch_normalization{params[\"num_layers\"]}'))\n",
        "    model.add(Activation('softmax', name=f'activation{params[\"num_layers\"]}'))\n",
        "    model.compile(loss=params['loss'], optimizer='adam',metrics=params['metrics']\n",
        "                  )\n",
        "    return model\n",
        "\n",
        "\n",
        "def calc_q_(A: np.ndarray, B: np.ndarray) -> float:\n",
        "    M, N = A.shape\n",
        "    dot_product = np.dot(A.T, B)\n",
        "    x = np.sum(dot_product ** 2)\n",
        "    x /= N * M * M\n",
        "    x -= N / M\n",
        "    return x\n",
        "\n",
        "def get_q2(spinA, spinB):\n",
        "    qab_dict={'time':spinA['time']}#時刻の初期化\n",
        "    qaa_dict={'time':spinA['time']}\n",
        "    q2_dict={'time':spinA['time']}\n",
        "    for l in tqdm(CFG.layer_name_list):\n",
        "        qab_list=[]\n",
        "        qaa_list=[]\n",
        "        q2_list=[]\n",
        "        for i in range(len(spinA[l])):\n",
        "            ab = calc_q_(spinA[l][i],spinB[l][i])\n",
        "            aa= calc_q_(spinA[l][i],spinA[l][i])\n",
        "            bb = calc_q_(spinB[l][i],spinB[l][i])\n",
        "            q2 = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
        "            qab_list.append(ab)\n",
        "            qaa_list.append(aa)\n",
        "            q2_list.append(q2)\n",
        "        qab_dict[l] = qab_list\n",
        "        qaa_dict[l] = qaa_list\n",
        "        q2_dict[l] = q2_list\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qab_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qab_dict, handle)\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qaa_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qaa_dict, handle)\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/M{CFG.M}/q2_norm_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(q2_dict, handle)\n",
        "    return qab_dict, qaa_dict, q2_dict\n",
        "\n",
        "\n",
        "\n",
        "def get_layer_overlap(qab:dict,qaa:dict,q2:dict):\n",
        "  layer_dict={}\n",
        "  layer_q2=[]\n",
        "  layer_qab=[]\n",
        "  layer_qaa=[]\n",
        "\n",
        "  for i, l in enumerate(CFG.layer_name_list):\n",
        "      layer_q2.append(q2[l][-1])#平衡状態のOverlapを取得\n",
        "      layer_qab.append(qab[l][-1])\n",
        "      layer_qaa.append(qaa[l][-1])\n",
        "  layer_dict['q2']=layer_q2\n",
        "  layer_dict['qab']=layer_qab\n",
        "  layer_dict['qaa']=layer_qaa\n",
        "\n",
        "  with open(f'./Output/Overlap/Layer_q/M{CFG.M}/layerq_norm_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(layer_dict, handle)\n",
        "  return layer_dict\n",
        "\n",
        "def get_normalized_spin(SpinA, SpinB):\n",
        "  spinA_norm = SpinA.copy()\n",
        "  spinB_norm = SpinB.copy()\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "        squared_sum_A = np.sum(SpinA[l]**2, axis=2)\n",
        "        squared_sum_B = np.sum(SpinB[l]**2, axis=2)\n",
        "        # 規格化定数を計算\n",
        "        normalization_constA = np.sqrt(100 / squared_sum_A)\n",
        "        normalization_constB = np.sqrt(100 / squared_sum_B)\n",
        "        # 規格化した配列を計算\n",
        "        spinA_norm[l] = SpinA[l] * normalization_constA[:, :, np.newaxis]\n",
        "        spinB_norm[l] = SpinB[l] * normalization_constB[:, :, np.newaxis]\n",
        "\n",
        "  return spinA_norm, spinB_norm\n",
        "\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    'num_layers':CFG.L,\n",
        "    'input_size': 100,#width of network\n",
        "    'output_size': 10,\n",
        "    'batch_size':256,\n",
        "    'width':100,\n",
        "    'epochs':1500,\n",
        "    'metrics':'accuracy',\n",
        "    'loss':'sparse_categorical_crossentropy',\n",
        "    'activation':'relu',\n",
        "    'activation_last':'softmax',\n",
        "    #'weight_initializer': tf.keras.initializers.RandomNormal(mean=0.0, stddev=1),\n",
        "    'bias_initializer_value': 0.1,\n",
        "    'bias_initializer': tf.keras.initializers.Constant(0.1),\n",
        "    'optimizer':'adam',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZpwqvrqsisf",
        "outputId": "cac53508-3093-42ae-917e-d587515d900e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============Data Load===============\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "===============Preprocess data===============\n",
            "N_classes: 10\n",
            "Train size: (60000, 784) Test size: (60000,)\n",
            "===============PCA===============\n",
            "0.91186106\n",
            "Train: (60000, 100)\n",
            "Test: (10000, 100)\n",
            "Train size after PCA: (60000, 100) Test size after PCA: (10000, 100)\n",
            "M=60000\n",
            "X_train for mesure: (6000, 100) y_train for mesure: (6000,)\n",
            "===============get_mask===============\n",
            "===============Build model1===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1762 - accuracy: 0.9324 - val_loss: 0.5240 - val_accuracy: 0.8527\n",
            "Epoch 881/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1754 - accuracy: 0.9335 - val_loss: 0.5264 - val_accuracy: 0.8544\n",
            "Epoch 882/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1772 - accuracy: 0.9332 - val_loss: 0.5212 - val_accuracy: 0.8559\n",
            "Epoch 883/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1774 - accuracy: 0.9320 - val_loss: 0.5268 - val_accuracy: 0.8529\n",
            "Epoch 884/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1757 - accuracy: 0.9338 - val_loss: 0.5222 - val_accuracy: 0.8528\n",
            "Epoch 885/1500\n",
            "235/235 [==============================] - 5s 15ms/step - loss: 0.1746 - accuracy: 0.9334 - val_loss: 0.5209 - val_accuracy: 0.8556\n",
            "Epoch 886/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1758 - accuracy: 0.9334 - val_loss: 0.5232 - val_accuracy: 0.8519\n",
            "Epoch 887/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1743 - accuracy: 0.9342 - val_loss: 0.5205 - val_accuracy: 0.8554\n",
            "Epoch 888/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1791 - accuracy: 0.9319 - val_loss: 0.5205 - val_accuracy: 0.8538\n",
            "Epoch 889/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1741 - accuracy: 0.9339 - val_loss: 0.5205 - val_accuracy: 0.8514\n",
            "Epoch 890/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1765 - accuracy: 0.9328 - val_loss: 0.5219 - val_accuracy: 0.8530\n",
            "Epoch 891/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1739 - accuracy: 0.9344 - val_loss: 0.5243 - val_accuracy: 0.8538\n",
            "Epoch 892/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1742 - accuracy: 0.9337 - val_loss: 0.5235 - val_accuracy: 0.8535\n",
            "Epoch 893/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1765 - accuracy: 0.9327 - val_loss: 0.5267 - val_accuracy: 0.8561\n",
            "Epoch 894/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1762 - accuracy: 0.9336 - val_loss: 0.5222 - val_accuracy: 0.8542\n",
            "Epoch 895/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1783 - accuracy: 0.9320 - val_loss: 0.5224 - val_accuracy: 0.8543\n",
            "Epoch 896/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1762 - accuracy: 0.9318 - val_loss: 0.5235 - val_accuracy: 0.8527\n",
            "Epoch 897/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1740 - accuracy: 0.9337 - val_loss: 0.5248 - val_accuracy: 0.8524\n",
            "Epoch 898/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1781 - accuracy: 0.9323 - val_loss: 0.5195 - val_accuracy: 0.8546\n",
            "Epoch 899/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9327 - val_loss: 0.5217 - val_accuracy: 0.8557\n",
            "Epoch 900/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1750 - accuracy: 0.9340 - val_loss: 0.5226 - val_accuracy: 0.8541\n",
            "Epoch 901/1500\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1777 - accuracy: 0.9323 - val_loss: 0.5252 - val_accuracy: 0.8523\n",
            "Epoch 902/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1746 - accuracy: 0.9345 - val_loss: 0.5215 - val_accuracy: 0.8548\n",
            "Epoch 903/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1788 - accuracy: 0.9317 - val_loss: 0.5244 - val_accuracy: 0.8524\n",
            "Epoch 904/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1794 - accuracy: 0.9320 - val_loss: 0.5243 - val_accuracy: 0.8534\n",
            "Epoch 905/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1785 - accuracy: 0.9324 - val_loss: 0.5221 - val_accuracy: 0.8540\n",
            "Epoch 906/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1741 - accuracy: 0.9338 - val_loss: 0.5259 - val_accuracy: 0.8555\n",
            "Epoch 907/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1740 - accuracy: 0.9342 - val_loss: 0.5224 - val_accuracy: 0.8544\n",
            "Epoch 908/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1743 - accuracy: 0.9338 - val_loss: 0.5256 - val_accuracy: 0.8543\n",
            "Epoch 909/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1731 - accuracy: 0.9341 - val_loss: 0.5274 - val_accuracy: 0.8528\n",
            "Epoch 910/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1751 - accuracy: 0.9329 - val_loss: 0.5232 - val_accuracy: 0.8556\n",
            "Epoch 911/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1754 - accuracy: 0.9327 - val_loss: 0.5186 - val_accuracy: 0.8534\n",
            "Epoch 912/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1758 - accuracy: 0.9340 - val_loss: 0.5219 - val_accuracy: 0.8541\n",
            "Epoch 913/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1775 - accuracy: 0.9325 - val_loss: 0.5257 - val_accuracy: 0.8528\n",
            "Epoch 914/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9338 - val_loss: 0.5256 - val_accuracy: 0.8531\n",
            "Epoch 915/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1764 - accuracy: 0.9329 - val_loss: 0.5245 - val_accuracy: 0.8515\n",
            "Epoch 916/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1747 - accuracy: 0.9334 - val_loss: 0.5187 - val_accuracy: 0.8526\n",
            "Epoch 917/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1771 - accuracy: 0.9327 - val_loss: 0.5263 - val_accuracy: 0.8539\n",
            "Epoch 918/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1755 - accuracy: 0.9327 - val_loss: 0.5176 - val_accuracy: 0.8536\n",
            "Epoch 919/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1742 - accuracy: 0.9341 - val_loss: 0.5241 - val_accuracy: 0.8537\n",
            "Epoch 920/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1746 - accuracy: 0.9338 - val_loss: 0.5217 - val_accuracy: 0.8540\n",
            "Epoch 921/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1731 - accuracy: 0.9343 - val_loss: 0.5303 - val_accuracy: 0.8499\n",
            "Epoch 922/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1774 - accuracy: 0.9322 - val_loss: 0.5228 - val_accuracy: 0.8524\n",
            "Epoch 923/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1767 - accuracy: 0.9334 - val_loss: 0.5250 - val_accuracy: 0.8544\n",
            "Epoch 924/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1761 - accuracy: 0.9331 - val_loss: 0.5210 - val_accuracy: 0.8542\n",
            "Epoch 925/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1767 - accuracy: 0.9325 - val_loss: 0.5226 - val_accuracy: 0.8553\n",
            "Epoch 926/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 0.5252 - val_accuracy: 0.8544\n",
            "Epoch 927/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1801 - accuracy: 0.9329 - val_loss: 0.5238 - val_accuracy: 0.8525\n",
            "Epoch 928/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1755 - accuracy: 0.9334 - val_loss: 0.5235 - val_accuracy: 0.8554\n",
            "Epoch 929/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1758 - accuracy: 0.9336 - val_loss: 0.5248 - val_accuracy: 0.8518\n",
            "Epoch 930/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1775 - accuracy: 0.9337 - val_loss: 0.5223 - val_accuracy: 0.8517\n",
            "Epoch 931/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1758 - accuracy: 0.9341 - val_loss: 0.5231 - val_accuracy: 0.8538\n",
            "Epoch 932/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1749 - accuracy: 0.9338 - val_loss: 0.5283 - val_accuracy: 0.8537\n",
            "Epoch 933/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1763 - accuracy: 0.9329 - val_loss: 0.5199 - val_accuracy: 0.8545\n",
            "Epoch 934/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1772 - accuracy: 0.9328 - val_loss: 0.5327 - val_accuracy: 0.8516\n",
            "Epoch 935/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1747 - accuracy: 0.9342 - val_loss: 0.5232 - val_accuracy: 0.8512\n",
            "Epoch 936/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1784 - accuracy: 0.9325 - val_loss: 0.5203 - val_accuracy: 0.8529\n",
            "Epoch 937/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9338 - val_loss: 0.5251 - val_accuracy: 0.8543\n",
            "Epoch 938/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9344 - val_loss: 0.5217 - val_accuracy: 0.8528\n",
            "Epoch 939/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1767 - accuracy: 0.9331 - val_loss: 0.5199 - val_accuracy: 0.8533\n",
            "Epoch 940/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1748 - accuracy: 0.9340 - val_loss: 0.5242 - val_accuracy: 0.8524\n",
            "Epoch 941/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1737 - accuracy: 0.9337 - val_loss: 0.5256 - val_accuracy: 0.8547\n",
            "Epoch 942/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1745 - accuracy: 0.9332 - val_loss: 0.5269 - val_accuracy: 0.8558\n",
            "Epoch 943/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1753 - accuracy: 0.9335 - val_loss: 0.5256 - val_accuracy: 0.8534\n",
            "Epoch 944/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1751 - accuracy: 0.9341 - val_loss: 0.5228 - val_accuracy: 0.8537\n",
            "Epoch 945/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9330 - val_loss: 0.5248 - val_accuracy: 0.8532\n",
            "Epoch 946/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1762 - accuracy: 0.9328 - val_loss: 0.5252 - val_accuracy: 0.8521\n",
            "Epoch 947/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1754 - accuracy: 0.9338 - val_loss: 0.5275 - val_accuracy: 0.8530\n",
            "Epoch 948/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1756 - accuracy: 0.9322 - val_loss: 0.5322 - val_accuracy: 0.8525\n",
            "Epoch 949/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1736 - accuracy: 0.9343 - val_loss: 0.5376 - val_accuracy: 0.8539\n",
            "Epoch 950/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1724 - accuracy: 0.9344 - val_loss: 0.5293 - val_accuracy: 0.8508\n",
            "Epoch 951/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1732 - accuracy: 0.9340 - val_loss: 0.5289 - val_accuracy: 0.8534\n",
            "Epoch 952/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1743 - accuracy: 0.9331 - val_loss: 0.5277 - val_accuracy: 0.8560\n",
            "Epoch 953/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1731 - accuracy: 0.9341 - val_loss: 0.5342 - val_accuracy: 0.8541\n",
            "Epoch 954/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1742 - accuracy: 0.9339 - val_loss: 0.5218 - val_accuracy: 0.8552\n",
            "Epoch 955/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1746 - accuracy: 0.9338 - val_loss: 0.5239 - val_accuracy: 0.8534\n",
            "Epoch 956/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1725 - accuracy: 0.9342 - val_loss: 0.5273 - val_accuracy: 0.8549\n",
            "Epoch 957/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1743 - accuracy: 0.9331 - val_loss: 0.5197 - val_accuracy: 0.8549\n",
            "Epoch 958/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1758 - accuracy: 0.9332 - val_loss: 0.5254 - val_accuracy: 0.8511\n",
            "Epoch 959/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1745 - accuracy: 0.9330 - val_loss: 0.5273 - val_accuracy: 0.8526\n",
            "Epoch 960/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1750 - accuracy: 0.9341 - val_loss: 0.5245 - val_accuracy: 0.8534\n",
            "Epoch 961/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1734 - accuracy: 0.9336 - val_loss: 0.5291 - val_accuracy: 0.8516\n",
            "Epoch 962/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1765 - accuracy: 0.9331 - val_loss: 0.5282 - val_accuracy: 0.8496\n",
            "Epoch 963/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1738 - accuracy: 0.9332 - val_loss: 0.5320 - val_accuracy: 0.8545\n",
            "Epoch 964/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1749 - accuracy: 0.9339 - val_loss: 0.5294 - val_accuracy: 0.8536\n",
            "Epoch 965/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1751 - accuracy: 0.9335 - val_loss: 0.5297 - val_accuracy: 0.8507\n",
            "Epoch 966/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1743 - accuracy: 0.9339 - val_loss: 0.5264 - val_accuracy: 0.8540\n",
            "Epoch 967/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1766 - accuracy: 0.9332 - val_loss: 0.5307 - val_accuracy: 0.8512\n",
            "Epoch 968/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1708 - accuracy: 0.9345 - val_loss: 0.5241 - val_accuracy: 0.8527\n",
            "Epoch 969/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1718 - accuracy: 0.9359 - val_loss: 0.5291 - val_accuracy: 0.8544\n",
            "Epoch 970/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1720 - accuracy: 0.9344 - val_loss: 0.5287 - val_accuracy: 0.8529\n",
            "Epoch 971/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1760 - accuracy: 0.9331 - val_loss: 0.5322 - val_accuracy: 0.8517\n",
            "Epoch 972/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 45ms/step - loss: 0.1713 - accuracy: 0.9345 - val_loss: 0.5325 - val_accuracy: 0.8526\n",
            "Epoch 973/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1735 - accuracy: 0.9338 - val_loss: 0.5300 - val_accuracy: 0.8509\n",
            "Epoch 974/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1757 - accuracy: 0.9338 - val_loss: 0.5297 - val_accuracy: 0.8513\n",
            "Epoch 975/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9338 - val_loss: 0.5239 - val_accuracy: 0.8529\n",
            "Epoch 976/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1743 - accuracy: 0.9343 - val_loss: 0.5298 - val_accuracy: 0.8496\n",
            "Epoch 977/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1733 - accuracy: 0.9338 - val_loss: 0.5259 - val_accuracy: 0.8518\n",
            "Epoch 978/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1751 - accuracy: 0.9338 - val_loss: 0.5276 - val_accuracy: 0.8505\n",
            "Epoch 979/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1737 - accuracy: 0.9339 - val_loss: 0.5266 - val_accuracy: 0.8524\n",
            "Epoch 980/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9342 - val_loss: 0.5281 - val_accuracy: 0.8536\n",
            "Epoch 981/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1746 - accuracy: 0.9334 - val_loss: 0.5304 - val_accuracy: 0.8492\n",
            "Epoch 982/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1731 - accuracy: 0.9336 - val_loss: 0.5236 - val_accuracy: 0.8516\n",
            "Epoch 983/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1735 - accuracy: 0.9339 - val_loss: 0.5240 - val_accuracy: 0.8509\n",
            "Epoch 984/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1755 - accuracy: 0.9335 - val_loss: 0.5294 - val_accuracy: 0.8484\n",
            "Epoch 985/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1767 - accuracy: 0.9322 - val_loss: 0.5281 - val_accuracy: 0.8503\n",
            "Epoch 986/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1725 - accuracy: 0.9349 - val_loss: 0.5289 - val_accuracy: 0.8509\n",
            "Epoch 987/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1763 - accuracy: 0.9335 - val_loss: 0.5244 - val_accuracy: 0.8530\n",
            "Epoch 988/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1759 - accuracy: 0.9339 - val_loss: 0.5256 - val_accuracy: 0.8517\n",
            "Epoch 989/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1752 - accuracy: 0.9326 - val_loss: 0.5369 - val_accuracy: 0.8515\n",
            "Epoch 990/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1755 - accuracy: 0.9333 - val_loss: 0.5278 - val_accuracy: 0.8519\n",
            "Epoch 991/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1740 - accuracy: 0.9332 - val_loss: 0.5242 - val_accuracy: 0.8532\n",
            "Epoch 992/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1720 - accuracy: 0.9346 - val_loss: 0.5290 - val_accuracy: 0.8527\n",
            "Epoch 993/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1747 - accuracy: 0.9327 - val_loss: 0.5347 - val_accuracy: 0.8539\n",
            "Epoch 994/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1758 - accuracy: 0.9338 - val_loss: 0.5230 - val_accuracy: 0.8509\n",
            "Epoch 995/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1775 - accuracy: 0.9320 - val_loss: 0.5301 - val_accuracy: 0.8512\n",
            "Epoch 996/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.5254 - val_accuracy: 0.8517\n",
            "Epoch 997/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1704 - accuracy: 0.9355 - val_loss: 0.5272 - val_accuracy: 0.8508\n",
            "Epoch 998/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1766 - accuracy: 0.9328 - val_loss: 0.5250 - val_accuracy: 0.8523\n",
            "Epoch 999/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9345 - val_loss: 0.5261 - val_accuracy: 0.8513\n",
            "Epoch 1000/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1745 - accuracy: 0.9341 - val_loss: 0.5296 - val_accuracy: 0.8526\n",
            "Epoch 1001/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1733 - accuracy: 0.9345 - val_loss: 0.5315 - val_accuracy: 0.8515\n",
            "Epoch 1002/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1726 - accuracy: 0.9349 - val_loss: 0.5293 - val_accuracy: 0.8491\n",
            "Epoch 1003/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1741 - accuracy: 0.9333 - val_loss: 0.5303 - val_accuracy: 0.8493\n",
            "Epoch 1004/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1744 - accuracy: 0.9332 - val_loss: 0.5310 - val_accuracy: 0.8500\n",
            "Epoch 1005/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1731 - accuracy: 0.9331 - val_loss: 0.5313 - val_accuracy: 0.8509\n",
            "Epoch 1006/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1757 - accuracy: 0.9331 - val_loss: 0.5341 - val_accuracy: 0.8493\n",
            "Epoch 1007/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1716 - accuracy: 0.9341 - val_loss: 0.5274 - val_accuracy: 0.8520\n",
            "Epoch 1008/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9345 - val_loss: 0.5333 - val_accuracy: 0.8518\n",
            "Epoch 1009/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1750 - accuracy: 0.9334 - val_loss: 0.5322 - val_accuracy: 0.8507\n",
            "Epoch 1010/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1740 - accuracy: 0.9339 - val_loss: 0.5278 - val_accuracy: 0.8516\n",
            "Epoch 1011/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1702 - accuracy: 0.9355 - val_loss: 0.5283 - val_accuracy: 0.8514\n",
            "Epoch 1012/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1783 - accuracy: 0.9332 - val_loss: 0.5315 - val_accuracy: 0.8506\n",
            "Epoch 1013/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1723 - accuracy: 0.9341 - val_loss: 0.5280 - val_accuracy: 0.8525\n",
            "Epoch 1014/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1739 - accuracy: 0.9339 - val_loss: 0.5297 - val_accuracy: 0.8515\n",
            "Epoch 1015/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1711 - accuracy: 0.9344 - val_loss: 0.5317 - val_accuracy: 0.8508\n",
            "Epoch 1016/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1732 - accuracy: 0.9349 - val_loss: 0.5355 - val_accuracy: 0.8522\n",
            "Epoch 1017/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1737 - accuracy: 0.9344 - val_loss: 0.5280 - val_accuracy: 0.8526\n",
            "Epoch 1018/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1740 - accuracy: 0.9349 - val_loss: 0.5299 - val_accuracy: 0.8542\n",
            "Epoch 1019/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1756 - accuracy: 0.9328 - val_loss: 0.5272 - val_accuracy: 0.8487\n",
            "Epoch 1020/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1765 - accuracy: 0.9337 - val_loss: 0.5270 - val_accuracy: 0.8529\n",
            "Epoch 1021/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1724 - accuracy: 0.9348 - val_loss: 0.5289 - val_accuracy: 0.8507\n",
            "Epoch 1022/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1693 - accuracy: 0.9354 - val_loss: 0.5339 - val_accuracy: 0.8492\n",
            "Epoch 1023/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1721 - accuracy: 0.9344 - val_loss: 0.5314 - val_accuracy: 0.8528\n",
            "Epoch 1024/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1751 - accuracy: 0.9328 - val_loss: 0.5299 - val_accuracy: 0.8507\n",
            "Epoch 1025/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1717 - accuracy: 0.9342 - val_loss: 0.5280 - val_accuracy: 0.8509\n",
            "Epoch 1026/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1740 - accuracy: 0.9337 - val_loss: 0.5299 - val_accuracy: 0.8512\n",
            "Epoch 1027/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1730 - accuracy: 0.9344 - val_loss: 0.5343 - val_accuracy: 0.8500\n",
            "Epoch 1028/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1745 - accuracy: 0.9337 - val_loss: 0.5276 - val_accuracy: 0.8529\n",
            "Epoch 1029/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1714 - accuracy: 0.9352 - val_loss: 0.5291 - val_accuracy: 0.8532\n",
            "Epoch 1030/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1723 - accuracy: 0.9342 - val_loss: 0.5286 - val_accuracy: 0.8515\n",
            "Epoch 1031/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1741 - accuracy: 0.9331 - val_loss: 0.5282 - val_accuracy: 0.8551\n",
            "Epoch 1032/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1736 - accuracy: 0.9338 - val_loss: 0.5312 - val_accuracy: 0.8509\n",
            "Epoch 1033/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1706 - accuracy: 0.9348 - val_loss: 0.5300 - val_accuracy: 0.8532\n",
            "Epoch 1034/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1744 - accuracy: 0.9336 - val_loss: 0.5249 - val_accuracy: 0.8508\n",
            "Epoch 1035/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1718 - accuracy: 0.9346 - val_loss: 0.5295 - val_accuracy: 0.8532\n",
            "Epoch 1036/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1728 - accuracy: 0.9345 - val_loss: 0.5326 - val_accuracy: 0.8516\n",
            "Epoch 1037/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1737 - accuracy: 0.9342 - val_loss: 0.5293 - val_accuracy: 0.8514\n",
            "Epoch 1038/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1746 - accuracy: 0.9331 - val_loss: 0.5318 - val_accuracy: 0.8517\n",
            "Epoch 1039/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1763 - accuracy: 0.9334 - val_loss: 0.5232 - val_accuracy: 0.8520\n",
            "Epoch 1040/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1737 - accuracy: 0.9337 - val_loss: 0.5289 - val_accuracy: 0.8517\n",
            "Epoch 1041/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1732 - accuracy: 0.9341 - val_loss: 0.5344 - val_accuracy: 0.8513\n",
            "Epoch 1042/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1738 - accuracy: 0.9341 - val_loss: 0.5325 - val_accuracy: 0.8524\n",
            "Epoch 1043/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1757 - accuracy: 0.9331 - val_loss: 0.5271 - val_accuracy: 0.8508\n",
            "Epoch 1044/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1699 - accuracy: 0.9351 - val_loss: 0.5293 - val_accuracy: 0.8518\n",
            "Epoch 1045/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1747 - accuracy: 0.9343 - val_loss: 0.5307 - val_accuracy: 0.8491\n",
            "Epoch 1046/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 0.5286 - val_accuracy: 0.8487\n",
            "Epoch 1047/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1729 - accuracy: 0.9335 - val_loss: 0.5318 - val_accuracy: 0.8516\n",
            "Epoch 1048/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1711 - accuracy: 0.9355 - val_loss: 0.5308 - val_accuracy: 0.8528\n",
            "Epoch 1049/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1717 - accuracy: 0.9334 - val_loss: 0.5298 - val_accuracy: 0.8525\n",
            "Epoch 1050/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1724 - accuracy: 0.9351 - val_loss: 0.5347 - val_accuracy: 0.8523\n",
            "Epoch 1051/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1728 - accuracy: 0.9350 - val_loss: 0.5359 - val_accuracy: 0.8519\n",
            "Epoch 1052/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1754 - accuracy: 0.9334 - val_loss: 0.5363 - val_accuracy: 0.8536\n",
            "Epoch 1053/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1747 - accuracy: 0.9325 - val_loss: 0.5288 - val_accuracy: 0.8519\n",
            "Epoch 1054/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1707 - accuracy: 0.9347 - val_loss: 0.5306 - val_accuracy: 0.8530\n",
            "Epoch 1055/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1744 - accuracy: 0.9348 - val_loss: 0.5278 - val_accuracy: 0.8521\n",
            "Epoch 1056/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1700 - accuracy: 0.9362 - val_loss: 0.5313 - val_accuracy: 0.8515\n",
            "Epoch 1057/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.5277 - val_accuracy: 0.8519\n",
            "Epoch 1058/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1737 - accuracy: 0.9342 - val_loss: 0.5398 - val_accuracy: 0.8533\n",
            "Epoch 1059/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9340 - val_loss: 0.5349 - val_accuracy: 0.8527\n",
            "Epoch 1060/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1698 - accuracy: 0.9359 - val_loss: 0.5339 - val_accuracy: 0.8522\n",
            "Epoch 1061/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1717 - accuracy: 0.9337 - val_loss: 0.5298 - val_accuracy: 0.8541\n",
            "Epoch 1062/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1727 - accuracy: 0.9347 - val_loss: 0.5323 - val_accuracy: 0.8523\n",
            "Epoch 1063/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1740 - accuracy: 0.9341 - val_loss: 0.5349 - val_accuracy: 0.8522\n",
            "Epoch 1064/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1735 - accuracy: 0.9348 - val_loss: 0.5326 - val_accuracy: 0.8529\n",
            "Epoch 1065/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9333 - val_loss: 0.5289 - val_accuracy: 0.8529\n",
            "Epoch 1066/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1737 - accuracy: 0.9334 - val_loss: 0.5312 - val_accuracy: 0.8534\n",
            "Epoch 1067/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1711 - accuracy: 0.9353 - val_loss: 0.5364 - val_accuracy: 0.8519\n",
            "Epoch 1068/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1727 - accuracy: 0.9342 - val_loss: 0.5351 - val_accuracy: 0.8523\n",
            "Epoch 1069/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1725 - accuracy: 0.9341 - val_loss: 0.5331 - val_accuracy: 0.8541\n",
            "Epoch 1070/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1734 - accuracy: 0.9339 - val_loss: 0.5321 - val_accuracy: 0.8551\n",
            "Epoch 1071/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1713 - accuracy: 0.9355 - val_loss: 0.5363 - val_accuracy: 0.8510\n",
            "Epoch 1072/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1717 - accuracy: 0.9342 - val_loss: 0.5308 - val_accuracy: 0.8531\n",
            "Epoch 1073/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1714 - accuracy: 0.9348 - val_loss: 0.5308 - val_accuracy: 0.8548\n",
            "Epoch 1074/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1769 - accuracy: 0.9326 - val_loss: 0.5299 - val_accuracy: 0.8527\n",
            "Epoch 1075/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1708 - accuracy: 0.9357 - val_loss: 0.5324 - val_accuracy: 0.8536\n",
            "Epoch 1076/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1709 - accuracy: 0.9342 - val_loss: 0.5301 - val_accuracy: 0.8528\n",
            "Epoch 1077/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1725 - accuracy: 0.9341 - val_loss: 0.5358 - val_accuracy: 0.8545\n",
            "Epoch 1078/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1742 - accuracy: 0.9335 - val_loss: 0.5290 - val_accuracy: 0.8549\n",
            "Epoch 1079/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1736 - accuracy: 0.9344 - val_loss: 0.5274 - val_accuracy: 0.8540\n",
            "Epoch 1080/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1708 - accuracy: 0.9348 - val_loss: 0.5302 - val_accuracy: 0.8542\n",
            "Epoch 1081/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1726 - accuracy: 0.9352 - val_loss: 0.5306 - val_accuracy: 0.8525\n",
            "Epoch 1082/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1717 - accuracy: 0.9351 - val_loss: 0.5342 - val_accuracy: 0.8539\n",
            "Epoch 1083/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1704 - accuracy: 0.9356 - val_loss: 0.5327 - val_accuracy: 0.8505\n",
            "Epoch 1084/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1740 - accuracy: 0.9323 - val_loss: 0.5356 - val_accuracy: 0.8525\n",
            "Epoch 1085/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1761 - accuracy: 0.9332 - val_loss: 0.5343 - val_accuracy: 0.8514\n",
            "Epoch 1086/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1730 - accuracy: 0.9351 - val_loss: 0.5322 - val_accuracy: 0.8523\n",
            "Epoch 1087/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1709 - accuracy: 0.9356 - val_loss: 0.5332 - val_accuracy: 0.8552\n",
            "Epoch 1088/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1718 - accuracy: 0.9349 - val_loss: 0.5339 - val_accuracy: 0.8539\n",
            "Epoch 1089/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1747 - accuracy: 0.9340 - val_loss: 0.5310 - val_accuracy: 0.8526\n",
            "Epoch 1090/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1720 - accuracy: 0.9354 - val_loss: 0.5302 - val_accuracy: 0.8521\n",
            "Epoch 1091/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1717 - accuracy: 0.9351 - val_loss: 0.5319 - val_accuracy: 0.8510\n",
            "Epoch 1092/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1712 - accuracy: 0.9352 - val_loss: 0.5325 - val_accuracy: 0.8509\n",
            "Epoch 1093/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1722 - accuracy: 0.9355 - val_loss: 0.5299 - val_accuracy: 0.8511\n",
            "Epoch 1094/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1734 - accuracy: 0.9336 - val_loss: 0.5292 - val_accuracy: 0.8524\n",
            "Epoch 1095/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1711 - accuracy: 0.9348 - val_loss: 0.5298 - val_accuracy: 0.8526\n",
            "Epoch 1096/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1698 - accuracy: 0.9361 - val_loss: 0.5320 - val_accuracy: 0.8510\n",
            "Epoch 1097/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1731 - accuracy: 0.9344 - val_loss: 0.5304 - val_accuracy: 0.8516\n",
            "Epoch 1098/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1693 - accuracy: 0.9364 - val_loss: 0.5318 - val_accuracy: 0.8515\n",
            "Epoch 1099/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1716 - accuracy: 0.9346 - val_loss: 0.5296 - val_accuracy: 0.8531\n",
            "Epoch 1100/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1712 - accuracy: 0.9344 - val_loss: 0.5347 - val_accuracy: 0.8529\n",
            "Epoch 1101/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1701 - accuracy: 0.9344 - val_loss: 0.5389 - val_accuracy: 0.8527\n",
            "Epoch 1102/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1706 - accuracy: 0.9364 - val_loss: 0.5377 - val_accuracy: 0.8528\n",
            "Epoch 1103/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.5339 - val_accuracy: 0.8526\n",
            "Epoch 1104/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1725 - accuracy: 0.9339 - val_loss: 0.5375 - val_accuracy: 0.8502\n",
            "Epoch 1105/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1724 - accuracy: 0.9347 - val_loss: 0.5380 - val_accuracy: 0.8508\n",
            "Epoch 1106/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1711 - accuracy: 0.9348 - val_loss: 0.5384 - val_accuracy: 0.8526\n",
            "Epoch 1107/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1711 - accuracy: 0.9348 - val_loss: 0.5372 - val_accuracy: 0.8494\n",
            "Epoch 1108/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1724 - accuracy: 0.9342 - val_loss: 0.5327 - val_accuracy: 0.8525\n",
            "Epoch 1109/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1712 - accuracy: 0.9356 - val_loss: 0.5344 - val_accuracy: 0.8528\n",
            "Epoch 1110/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9357 - val_loss: 0.5354 - val_accuracy: 0.8523\n",
            "Epoch 1111/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1711 - accuracy: 0.9350 - val_loss: 0.5378 - val_accuracy: 0.8523\n",
            "Epoch 1112/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1731 - accuracy: 0.9342 - val_loss: 0.5356 - val_accuracy: 0.8522\n",
            "Epoch 1113/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1725 - accuracy: 0.9338 - val_loss: 0.5339 - val_accuracy: 0.8529\n",
            "Epoch 1114/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1715 - accuracy: 0.9354 - val_loss: 0.5310 - val_accuracy: 0.8515\n",
            "Epoch 1115/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9354 - val_loss: 0.5315 - val_accuracy: 0.8502\n",
            "Epoch 1116/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9332 - val_loss: 0.5323 - val_accuracy: 0.8530\n",
            "Epoch 1117/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1706 - accuracy: 0.9339 - val_loss: 0.5295 - val_accuracy: 0.8522\n",
            "Epoch 1118/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1696 - accuracy: 0.9363 - val_loss: 0.5329 - val_accuracy: 0.8501\n",
            "Epoch 1119/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1696 - accuracy: 0.9356 - val_loss: 0.5378 - val_accuracy: 0.8505\n",
            "Epoch 1120/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1742 - accuracy: 0.9344 - val_loss: 0.5316 - val_accuracy: 0.8539\n",
            "Epoch 1121/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9352 - val_loss: 0.5262 - val_accuracy: 0.8511\n",
            "Epoch 1122/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1717 - accuracy: 0.9346 - val_loss: 0.5291 - val_accuracy: 0.8513\n",
            "Epoch 1123/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1722 - accuracy: 0.9341 - val_loss: 0.5365 - val_accuracy: 0.8523\n",
            "Epoch 1124/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1722 - accuracy: 0.9344 - val_loss: 0.5313 - val_accuracy: 0.8543\n",
            "Epoch 1125/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1712 - accuracy: 0.9349 - val_loss: 0.5266 - val_accuracy: 0.8536\n",
            "Epoch 1126/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1713 - accuracy: 0.9339 - val_loss: 0.5264 - val_accuracy: 0.8528\n",
            "Epoch 1127/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1722 - accuracy: 0.9347 - val_loss: 0.5270 - val_accuracy: 0.8525\n",
            "Epoch 1128/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1750 - accuracy: 0.9334 - val_loss: 0.5259 - val_accuracy: 0.8554\n",
            "Epoch 1129/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1726 - accuracy: 0.9332 - val_loss: 0.5285 - val_accuracy: 0.8546\n",
            "Epoch 1130/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1700 - accuracy: 0.9364 - val_loss: 0.5283 - val_accuracy: 0.8521\n",
            "Epoch 1131/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1736 - accuracy: 0.9343 - val_loss: 0.5326 - val_accuracy: 0.8523\n",
            "Epoch 1132/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1706 - accuracy: 0.9341 - val_loss: 0.5312 - val_accuracy: 0.8523\n",
            "Epoch 1133/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1713 - accuracy: 0.9342 - val_loss: 0.5316 - val_accuracy: 0.8549\n",
            "Epoch 1134/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1684 - accuracy: 0.9347 - val_loss: 0.5333 - val_accuracy: 0.8532\n",
            "Epoch 1135/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1701 - accuracy: 0.9350 - val_loss: 0.5326 - val_accuracy: 0.8523\n",
            "Epoch 1136/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1721 - accuracy: 0.9345 - val_loss: 0.5294 - val_accuracy: 0.8540\n",
            "Epoch 1137/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1697 - accuracy: 0.9348 - val_loss: 0.5292 - val_accuracy: 0.8540\n",
            "Epoch 1138/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1712 - accuracy: 0.9345 - val_loss: 0.5292 - val_accuracy: 0.8517\n",
            "Epoch 1139/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1737 - accuracy: 0.9339 - val_loss: 0.5293 - val_accuracy: 0.8525\n",
            "Epoch 1140/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1731 - accuracy: 0.9338 - val_loss: 0.5292 - val_accuracy: 0.8531\n",
            "Epoch 1141/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1750 - accuracy: 0.9336 - val_loss: 0.5281 - val_accuracy: 0.8531\n",
            "Epoch 1142/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1737 - accuracy: 0.9349 - val_loss: 0.5291 - val_accuracy: 0.8523\n",
            "Epoch 1143/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1704 - accuracy: 0.9359 - val_loss: 0.5316 - val_accuracy: 0.8540\n",
            "Epoch 1144/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1701 - accuracy: 0.9353 - val_loss: 0.5369 - val_accuracy: 0.8531\n",
            "Epoch 1145/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1670 - accuracy: 0.9363 - val_loss: 0.5346 - val_accuracy: 0.8531\n",
            "Epoch 1146/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1707 - accuracy: 0.9359 - val_loss: 0.5359 - val_accuracy: 0.8530\n",
            "Epoch 1147/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1700 - accuracy: 0.9363 - val_loss: 0.5354 - val_accuracy: 0.8532\n",
            "Epoch 1148/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1712 - accuracy: 0.9355 - val_loss: 0.5305 - val_accuracy: 0.8523\n",
            "Epoch 1149/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1734 - accuracy: 0.9348 - val_loss: 0.5324 - val_accuracy: 0.8540\n",
            "Epoch 1150/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.5344 - val_accuracy: 0.8522\n",
            "Epoch 1151/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1732 - accuracy: 0.9343 - val_loss: 0.5291 - val_accuracy: 0.8528\n",
            "Epoch 1152/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1705 - accuracy: 0.9360 - val_loss: 0.5265 - val_accuracy: 0.8540\n",
            "Epoch 1153/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1720 - accuracy: 0.9336 - val_loss: 0.5317 - val_accuracy: 0.8540\n",
            "Epoch 1154/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1701 - accuracy: 0.9354 - val_loss: 0.5285 - val_accuracy: 0.8531\n",
            "Epoch 1155/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1722 - accuracy: 0.9348 - val_loss: 0.5338 - val_accuracy: 0.8563\n",
            "Epoch 1156/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1670 - accuracy: 0.9372 - val_loss: 0.5336 - val_accuracy: 0.8535\n",
            "Epoch 1157/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1692 - accuracy: 0.9348 - val_loss: 0.5280 - val_accuracy: 0.8535\n",
            "Epoch 1158/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1703 - accuracy: 0.9353 - val_loss: 0.5352 - val_accuracy: 0.8535\n",
            "Epoch 1159/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1683 - accuracy: 0.9360 - val_loss: 0.5351 - val_accuracy: 0.8536\n",
            "Epoch 1160/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1701 - accuracy: 0.9352 - val_loss: 0.5347 - val_accuracy: 0.8550\n",
            "Epoch 1161/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1695 - accuracy: 0.9360 - val_loss: 0.5369 - val_accuracy: 0.8527\n",
            "Epoch 1162/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1721 - accuracy: 0.9345 - val_loss: 0.5361 - val_accuracy: 0.8544\n",
            "Epoch 1163/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1709 - accuracy: 0.9345 - val_loss: 0.5330 - val_accuracy: 0.8537\n",
            "Epoch 1164/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1727 - accuracy: 0.9348 - val_loss: 0.5322 - val_accuracy: 0.8538\n",
            "Epoch 1165/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1721 - accuracy: 0.9343 - val_loss: 0.5346 - val_accuracy: 0.8562\n",
            "Epoch 1166/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1726 - accuracy: 0.9338 - val_loss: 0.5309 - val_accuracy: 0.8539\n",
            "Epoch 1167/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1706 - accuracy: 0.9356 - val_loss: 0.5343 - val_accuracy: 0.8522\n",
            "Epoch 1168/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1724 - accuracy: 0.9353 - val_loss: 0.5313 - val_accuracy: 0.8530\n",
            "Epoch 1169/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1718 - accuracy: 0.9341 - val_loss: 0.5303 - val_accuracy: 0.8539\n",
            "Epoch 1170/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1709 - accuracy: 0.9349 - val_loss: 0.5335 - val_accuracy: 0.8534\n",
            "Epoch 1171/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1668 - accuracy: 0.9359 - val_loss: 0.5346 - val_accuracy: 0.8520\n",
            "Epoch 1172/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1723 - accuracy: 0.9339 - val_loss: 0.5369 - val_accuracy: 0.8529\n",
            "Epoch 1173/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1723 - accuracy: 0.9341 - val_loss: 0.5318 - val_accuracy: 0.8544\n",
            "Epoch 1174/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1725 - accuracy: 0.9338 - val_loss: 0.5303 - val_accuracy: 0.8540\n",
            "Epoch 1175/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1716 - accuracy: 0.9359 - val_loss: 0.5310 - val_accuracy: 0.8544\n",
            "Epoch 1176/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1704 - accuracy: 0.9341 - val_loss: 0.5339 - val_accuracy: 0.8535\n",
            "Epoch 1177/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1705 - accuracy: 0.9352 - val_loss: 0.5305 - val_accuracy: 0.8529\n",
            "Epoch 1178/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1720 - accuracy: 0.9341 - val_loss: 0.5341 - val_accuracy: 0.8535\n",
            "Epoch 1179/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1698 - accuracy: 0.9362 - val_loss: 0.5313 - val_accuracy: 0.8512\n",
            "Epoch 1180/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1686 - accuracy: 0.9359 - val_loss: 0.5327 - val_accuracy: 0.8525\n",
            "Epoch 1181/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1716 - accuracy: 0.9345 - val_loss: 0.5325 - val_accuracy: 0.8530\n",
            "Epoch 1182/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1697 - accuracy: 0.9356 - val_loss: 0.5329 - val_accuracy: 0.8518\n",
            "Epoch 1183/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1716 - accuracy: 0.9352 - val_loss: 0.5354 - val_accuracy: 0.8539\n",
            "Epoch 1184/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1694 - accuracy: 0.9351 - val_loss: 0.5319 - val_accuracy: 0.8515\n",
            "Epoch 1185/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1744 - accuracy: 0.9341 - val_loss: 0.5351 - val_accuracy: 0.8545\n",
            "Epoch 1186/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1698 - accuracy: 0.9360 - val_loss: 0.5304 - val_accuracy: 0.8534\n",
            "Epoch 1187/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1690 - accuracy: 0.9358 - val_loss: 0.5320 - val_accuracy: 0.8549\n",
            "Epoch 1188/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1674 - accuracy: 0.9364 - val_loss: 0.5367 - val_accuracy: 0.8534\n",
            "Epoch 1189/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1699 - accuracy: 0.9358 - val_loss: 0.5368 - val_accuracy: 0.8523\n",
            "Epoch 1190/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1713 - accuracy: 0.9351 - val_loss: 0.5335 - val_accuracy: 0.8515\n",
            "Epoch 1191/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1734 - accuracy: 0.9341 - val_loss: 0.5342 - val_accuracy: 0.8536\n",
            "Epoch 1192/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1714 - accuracy: 0.9343 - val_loss: 0.5361 - val_accuracy: 0.8515\n",
            "Epoch 1193/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1690 - accuracy: 0.9358 - val_loss: 0.5315 - val_accuracy: 0.8512\n",
            "Epoch 1194/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1696 - accuracy: 0.9351 - val_loss: 0.5300 - val_accuracy: 0.8531\n",
            "Epoch 1195/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1709 - accuracy: 0.9348 - val_loss: 0.5294 - val_accuracy: 0.8522\n",
            "Epoch 1196/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1705 - accuracy: 0.9355 - val_loss: 0.5347 - val_accuracy: 0.8536\n",
            "Epoch 1197/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1722 - accuracy: 0.9349 - val_loss: 0.5340 - val_accuracy: 0.8543\n",
            "Epoch 1198/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1690 - accuracy: 0.9350 - val_loss: 0.5337 - val_accuracy: 0.8535\n",
            "Epoch 1199/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1717 - accuracy: 0.9346 - val_loss: 0.5309 - val_accuracy: 0.8534\n",
            "Epoch 1200/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1712 - accuracy: 0.9352 - val_loss: 0.5343 - val_accuracy: 0.8527\n",
            "Epoch 1201/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1730 - accuracy: 0.9347 - val_loss: 0.5326 - val_accuracy: 0.8547\n",
            "Epoch 1202/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9353 - val_loss: 0.5329 - val_accuracy: 0.8538\n",
            "Epoch 1203/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1692 - accuracy: 0.9353 - val_loss: 0.5311 - val_accuracy: 0.8532\n",
            "Epoch 1204/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1746 - accuracy: 0.9331 - val_loss: 0.5301 - val_accuracy: 0.8526\n",
            "Epoch 1205/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1721 - accuracy: 0.9354 - val_loss: 0.5289 - val_accuracy: 0.8520\n",
            "Epoch 1206/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1741 - accuracy: 0.9337 - val_loss: 0.5274 - val_accuracy: 0.8544\n",
            "Epoch 1207/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1732 - accuracy: 0.9339 - val_loss: 0.5309 - val_accuracy: 0.8537\n",
            "Epoch 1208/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1718 - accuracy: 0.9337 - val_loss: 0.5292 - val_accuracy: 0.8516\n",
            "Epoch 1209/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1707 - accuracy: 0.9351 - val_loss: 0.5265 - val_accuracy: 0.8545\n",
            "Epoch 1210/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1732 - accuracy: 0.9343 - val_loss: 0.5300 - val_accuracy: 0.8525\n",
            "Epoch 1211/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1690 - accuracy: 0.9359 - val_loss: 0.5282 - val_accuracy: 0.8540\n",
            "Epoch 1212/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1724 - accuracy: 0.9343 - val_loss: 0.5302 - val_accuracy: 0.8537\n",
            "Epoch 1213/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1685 - accuracy: 0.9359 - val_loss: 0.5334 - val_accuracy: 0.8541\n",
            "Epoch 1214/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1719 - accuracy: 0.9347 - val_loss: 0.5280 - val_accuracy: 0.8543\n",
            "Epoch 1215/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1702 - accuracy: 0.9343 - val_loss: 0.5336 - val_accuracy: 0.8545\n",
            "Epoch 1216/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1707 - accuracy: 0.9339 - val_loss: 0.5348 - val_accuracy: 0.8558\n",
            "Epoch 1217/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1707 - accuracy: 0.9339 - val_loss: 0.5330 - val_accuracy: 0.8521\n",
            "Epoch 1218/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1726 - accuracy: 0.9343 - val_loss: 0.5339 - val_accuracy: 0.8544\n",
            "Epoch 1219/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1728 - accuracy: 0.9344 - val_loss: 0.5302 - val_accuracy: 0.8536\n",
            "Epoch 1220/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1720 - accuracy: 0.9351 - val_loss: 0.5279 - val_accuracy: 0.8533\n",
            "Epoch 1221/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1706 - accuracy: 0.9347 - val_loss: 0.5325 - val_accuracy: 0.8536\n",
            "Epoch 1222/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1672 - accuracy: 0.9362 - val_loss: 0.5299 - val_accuracy: 0.8544\n",
            "Epoch 1223/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1694 - accuracy: 0.9357 - val_loss: 0.5273 - val_accuracy: 0.8535\n",
            "Epoch 1224/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1695 - accuracy: 0.9356 - val_loss: 0.5325 - val_accuracy: 0.8505\n",
            "Epoch 1225/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1715 - accuracy: 0.9335 - val_loss: 0.5322 - val_accuracy: 0.8533\n",
            "Epoch 1226/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1733 - accuracy: 0.9339 - val_loss: 0.5268 - val_accuracy: 0.8543\n",
            "Epoch 1227/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1696 - accuracy: 0.9358 - val_loss: 0.5250 - val_accuracy: 0.8544\n",
            "Epoch 1228/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1675 - accuracy: 0.9374 - val_loss: 0.5258 - val_accuracy: 0.8553\n",
            "Epoch 1229/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1698 - accuracy: 0.9355 - val_loss: 0.5231 - val_accuracy: 0.8556\n",
            "Epoch 1230/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1726 - accuracy: 0.9345 - val_loss: 0.5285 - val_accuracy: 0.8509\n",
            "Epoch 1231/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1717 - accuracy: 0.9354 - val_loss: 0.5289 - val_accuracy: 0.8543\n",
            "Epoch 1232/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1679 - accuracy: 0.9362 - val_loss: 0.5336 - val_accuracy: 0.8549\n",
            "Epoch 1233/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1706 - accuracy: 0.9352 - val_loss: 0.5299 - val_accuracy: 0.8532\n",
            "Epoch 1234/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1680 - accuracy: 0.9373 - val_loss: 0.5289 - val_accuracy: 0.8544\n",
            "Epoch 1235/1500\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1691 - accuracy: 0.9360 - val_loss: 0.5355 - val_accuracy: 0.8526\n",
            "Epoch 1236/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1718 - accuracy: 0.9342 - val_loss: 0.5367 - val_accuracy: 0.8526\n",
            "Epoch 1237/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1706 - accuracy: 0.9357 - val_loss: 0.5317 - val_accuracy: 0.8540\n",
            "Epoch 1238/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1699 - accuracy: 0.9351 - val_loss: 0.5318 - val_accuracy: 0.8551\n",
            "Epoch 1239/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9336 - val_loss: 0.5283 - val_accuracy: 0.8538\n",
            "Epoch 1240/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1659 - accuracy: 0.9362 - val_loss: 0.5380 - val_accuracy: 0.8542\n",
            "Epoch 1241/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1693 - accuracy: 0.9360 - val_loss: 0.5331 - val_accuracy: 0.8551\n",
            "Epoch 1242/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1723 - accuracy: 0.9344 - val_loss: 0.5316 - val_accuracy: 0.8539\n",
            "Epoch 1243/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1719 - accuracy: 0.9345 - val_loss: 0.5328 - val_accuracy: 0.8539\n",
            "Epoch 1244/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9365 - val_loss: 0.5284 - val_accuracy: 0.8530\n",
            "Epoch 1245/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1702 - accuracy: 0.9352 - val_loss: 0.5312 - val_accuracy: 0.8536\n",
            "Epoch 1246/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9356 - val_loss: 0.5298 - val_accuracy: 0.8525\n",
            "Epoch 1247/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1711 - accuracy: 0.9352 - val_loss: 0.5292 - val_accuracy: 0.8556\n",
            "Epoch 1248/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9353 - val_loss: 0.5340 - val_accuracy: 0.8567\n",
            "Epoch 1249/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1699 - accuracy: 0.9350 - val_loss: 0.5316 - val_accuracy: 0.8539\n",
            "Epoch 1250/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9354 - val_loss: 0.5323 - val_accuracy: 0.8543\n",
            "Epoch 1251/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1702 - accuracy: 0.9354 - val_loss: 0.5338 - val_accuracy: 0.8516\n",
            "Epoch 1252/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1684 - accuracy: 0.9354 - val_loss: 0.5245 - val_accuracy: 0.8541\n",
            "Epoch 1253/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1682 - accuracy: 0.9363 - val_loss: 0.5285 - val_accuracy: 0.8547\n",
            "Epoch 1254/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9352 - val_loss: 0.5289 - val_accuracy: 0.8535\n",
            "Epoch 1255/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1707 - accuracy: 0.9351 - val_loss: 0.5301 - val_accuracy: 0.8563\n",
            "Epoch 1256/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1702 - accuracy: 0.9362 - val_loss: 0.5280 - val_accuracy: 0.8557\n",
            "Epoch 1257/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1692 - accuracy: 0.9356 - val_loss: 0.5354 - val_accuracy: 0.8530\n",
            "Epoch 1258/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1678 - accuracy: 0.9368 - val_loss: 0.5334 - val_accuracy: 0.8539\n",
            "Epoch 1259/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1695 - accuracy: 0.9354 - val_loss: 0.5327 - val_accuracy: 0.8551\n",
            "Epoch 1260/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1701 - accuracy: 0.9352 - val_loss: 0.5294 - val_accuracy: 0.8544\n",
            "Epoch 1261/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9341 - val_loss: 0.5273 - val_accuracy: 0.8561\n",
            "Epoch 1262/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9359 - val_loss: 0.5302 - val_accuracy: 0.8539\n",
            "Epoch 1263/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9354 - val_loss: 0.5324 - val_accuracy: 0.8547\n",
            "Epoch 1264/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1646 - accuracy: 0.9380 - val_loss: 0.5310 - val_accuracy: 0.8546\n",
            "Epoch 1265/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1738 - accuracy: 0.9343 - val_loss: 0.5312 - val_accuracy: 0.8538\n",
            "Epoch 1266/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1710 - accuracy: 0.9353 - val_loss: 0.5303 - val_accuracy: 0.8550\n",
            "Epoch 1267/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9361 - val_loss: 0.5268 - val_accuracy: 0.8532\n",
            "Epoch 1268/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1709 - accuracy: 0.9340 - val_loss: 0.5288 - val_accuracy: 0.8552\n",
            "Epoch 1269/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9358 - val_loss: 0.5326 - val_accuracy: 0.8550\n",
            "Epoch 1270/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1689 - accuracy: 0.9348 - val_loss: 0.5311 - val_accuracy: 0.8562\n",
            "Epoch 1271/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1701 - accuracy: 0.9354 - val_loss: 0.5300 - val_accuracy: 0.8537\n",
            "Epoch 1272/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9354 - val_loss: 0.5295 - val_accuracy: 0.8554\n",
            "Epoch 1273/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9352 - val_loss: 0.5309 - val_accuracy: 0.8553\n",
            "Epoch 1274/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9346 - val_loss: 0.5327 - val_accuracy: 0.8530\n",
            "Epoch 1275/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1698 - accuracy: 0.9358 - val_loss: 0.5331 - val_accuracy: 0.8543\n",
            "Epoch 1276/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1711 - accuracy: 0.9349 - val_loss: 0.5298 - val_accuracy: 0.8563\n",
            "Epoch 1277/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1705 - accuracy: 0.9356 - val_loss: 0.5322 - val_accuracy: 0.8557\n",
            "Epoch 1278/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9358 - val_loss: 0.5282 - val_accuracy: 0.8535\n",
            "Epoch 1279/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1702 - accuracy: 0.9350 - val_loss: 0.5318 - val_accuracy: 0.8558\n",
            "Epoch 1280/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9362 - val_loss: 0.5268 - val_accuracy: 0.8529\n",
            "Epoch 1281/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9354 - val_loss: 0.5307 - val_accuracy: 0.8545\n",
            "Epoch 1282/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1695 - accuracy: 0.9354 - val_loss: 0.5305 - val_accuracy: 0.8547\n",
            "Epoch 1283/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1705 - accuracy: 0.9359 - val_loss: 0.5259 - val_accuracy: 0.8558\n",
            "Epoch 1284/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9358 - val_loss: 0.5288 - val_accuracy: 0.8539\n",
            "Epoch 1285/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9367 - val_loss: 0.5305 - val_accuracy: 0.8560\n",
            "Epoch 1286/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1715 - accuracy: 0.9352 - val_loss: 0.5284 - val_accuracy: 0.8547\n",
            "Epoch 1287/1500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1684 - accuracy: 0.9362 - val_loss: 0.5318 - val_accuracy: 0.8554\n",
            "Epoch 1288/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1674 - accuracy: 0.9360 - val_loss: 0.5366 - val_accuracy: 0.8545\n",
            "Epoch 1289/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1731 - accuracy: 0.9343 - val_loss: 0.5351 - val_accuracy: 0.8548\n",
            "Epoch 1290/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1699 - accuracy: 0.9352 - val_loss: 0.5317 - val_accuracy: 0.8537\n",
            "Epoch 1291/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1682 - accuracy: 0.9364 - val_loss: 0.5303 - val_accuracy: 0.8544\n",
            "Epoch 1292/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.1680 - accuracy: 0.9355 - val_loss: 0.5311 - val_accuracy: 0.8526\n",
            "Epoch 1293/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1679 - accuracy: 0.9355 - val_loss: 0.5337 - val_accuracy: 0.8544\n",
            "Epoch 1294/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1678 - accuracy: 0.9367 - val_loss: 0.5322 - val_accuracy: 0.8564\n",
            "Epoch 1295/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1670 - accuracy: 0.9373 - val_loss: 0.5357 - val_accuracy: 0.8542\n",
            "Epoch 1296/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1690 - accuracy: 0.9360 - val_loss: 0.5356 - val_accuracy: 0.8561\n",
            "Epoch 1297/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1666 - accuracy: 0.9369 - val_loss: 0.5300 - val_accuracy: 0.8546\n",
            "Epoch 1298/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1710 - accuracy: 0.9355 - val_loss: 0.5327 - val_accuracy: 0.8558\n",
            "Epoch 1299/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1689 - accuracy: 0.9359 - val_loss: 0.5303 - val_accuracy: 0.8560\n",
            "Epoch 1300/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9356 - val_loss: 0.5341 - val_accuracy: 0.8533\n",
            "Epoch 1301/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1706 - accuracy: 0.9353 - val_loss: 0.5349 - val_accuracy: 0.8534\n",
            "Epoch 1302/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1689 - accuracy: 0.9362 - val_loss: 0.5351 - val_accuracy: 0.8544\n",
            "Epoch 1303/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1693 - accuracy: 0.9352 - val_loss: 0.5301 - val_accuracy: 0.8556\n",
            "Epoch 1304/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1666 - accuracy: 0.9366 - val_loss: 0.5363 - val_accuracy: 0.8555\n",
            "Epoch 1305/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9364 - val_loss: 0.5388 - val_accuracy: 0.8544\n",
            "Epoch 1306/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1681 - accuracy: 0.9359 - val_loss: 0.5330 - val_accuracy: 0.8541\n",
            "Epoch 1307/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9347 - val_loss: 0.5313 - val_accuracy: 0.8563\n",
            "Epoch 1308/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1696 - accuracy: 0.9352 - val_loss: 0.5374 - val_accuracy: 0.8547\n",
            "Epoch 1309/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1693 - accuracy: 0.9362 - val_loss: 0.5389 - val_accuracy: 0.8536\n",
            "Epoch 1310/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1717 - accuracy: 0.9353 - val_loss: 0.5343 - val_accuracy: 0.8536\n",
            "Epoch 1311/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1686 - accuracy: 0.9356 - val_loss: 0.5357 - val_accuracy: 0.8543\n",
            "Epoch 1312/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9349 - val_loss: 0.5367 - val_accuracy: 0.8547\n",
            "Epoch 1313/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9358 - val_loss: 0.5378 - val_accuracy: 0.8541\n",
            "Epoch 1314/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1672 - accuracy: 0.9370 - val_loss: 0.5404 - val_accuracy: 0.8553\n",
            "Epoch 1315/1500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1683 - accuracy: 0.9366 - val_loss: 0.5374 - val_accuracy: 0.8552\n",
            "Epoch 1316/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1672 - accuracy: 0.9352 - val_loss: 0.5373 - val_accuracy: 0.8543\n",
            "Epoch 1317/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9344 - val_loss: 0.5327 - val_accuracy: 0.8537\n",
            "Epoch 1318/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1648 - accuracy: 0.9377 - val_loss: 0.5369 - val_accuracy: 0.8542\n",
            "Epoch 1319/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9368 - val_loss: 0.5400 - val_accuracy: 0.8542\n",
            "Epoch 1320/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9348 - val_loss: 0.5390 - val_accuracy: 0.8550\n",
            "Epoch 1321/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9364 - val_loss: 0.5370 - val_accuracy: 0.8554\n",
            "Epoch 1322/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1671 - accuracy: 0.9365 - val_loss: 0.5349 - val_accuracy: 0.8525\n",
            "Epoch 1323/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1680 - accuracy: 0.9358 - val_loss: 0.5392 - val_accuracy: 0.8524\n",
            "Epoch 1324/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9361 - val_loss: 0.5391 - val_accuracy: 0.8520\n",
            "Epoch 1325/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1679 - accuracy: 0.9354 - val_loss: 0.5359 - val_accuracy: 0.8567\n",
            "Epoch 1326/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1702 - accuracy: 0.9355 - val_loss: 0.5389 - val_accuracy: 0.8545\n",
            "Epoch 1327/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9365 - val_loss: 0.5354 - val_accuracy: 0.8539\n",
            "Epoch 1328/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1698 - accuracy: 0.9365 - val_loss: 0.5390 - val_accuracy: 0.8551\n",
            "Epoch 1329/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1717 - accuracy: 0.9350 - val_loss: 0.5334 - val_accuracy: 0.8562\n",
            "Epoch 1330/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9358 - val_loss: 0.5317 - val_accuracy: 0.8548\n",
            "Epoch 1331/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1698 - accuracy: 0.9357 - val_loss: 0.5280 - val_accuracy: 0.8542\n",
            "Epoch 1332/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9352 - val_loss: 0.5284 - val_accuracy: 0.8554\n",
            "Epoch 1333/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9355 - val_loss: 0.5298 - val_accuracy: 0.8552\n",
            "Epoch 1334/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1640 - accuracy: 0.9383 - val_loss: 0.5340 - val_accuracy: 0.8550\n",
            "Epoch 1335/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9362 - val_loss: 0.5366 - val_accuracy: 0.8536\n",
            "Epoch 1336/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1657 - accuracy: 0.9383 - val_loss: 0.5369 - val_accuracy: 0.8528\n",
            "Epoch 1337/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9357 - val_loss: 0.5360 - val_accuracy: 0.8536\n",
            "Epoch 1338/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9364 - val_loss: 0.5364 - val_accuracy: 0.8551\n",
            "Epoch 1339/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9358 - val_loss: 0.5368 - val_accuracy: 0.8539\n",
            "Epoch 1340/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1709 - accuracy: 0.9350 - val_loss: 0.5295 - val_accuracy: 0.8546\n",
            "Epoch 1341/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1705 - accuracy: 0.9361 - val_loss: 0.5353 - val_accuracy: 0.8568\n",
            "Epoch 1342/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1669 - accuracy: 0.9362 - val_loss: 0.5330 - val_accuracy: 0.8543\n",
            "Epoch 1343/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1682 - accuracy: 0.9354 - val_loss: 0.5322 - val_accuracy: 0.8540\n",
            "Epoch 1344/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1659 - accuracy: 0.9365 - val_loss: 0.5332 - val_accuracy: 0.8541\n",
            "Epoch 1345/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9364 - val_loss: 0.5360 - val_accuracy: 0.8539\n",
            "Epoch 1346/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9369 - val_loss: 0.5345 - val_accuracy: 0.8545\n",
            "Epoch 1347/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9364 - val_loss: 0.5373 - val_accuracy: 0.8525\n",
            "Epoch 1348/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1679 - accuracy: 0.9370 - val_loss: 0.5433 - val_accuracy: 0.8551\n",
            "Epoch 1349/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9357 - val_loss: 0.5356 - val_accuracy: 0.8537\n",
            "Epoch 1350/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9341 - val_loss: 0.5301 - val_accuracy: 0.8575\n",
            "Epoch 1351/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9349 - val_loss: 0.5302 - val_accuracy: 0.8549\n",
            "Epoch 1352/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1703 - accuracy: 0.9359 - val_loss: 0.5371 - val_accuracy: 0.8537\n",
            "Epoch 1353/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9356 - val_loss: 0.5339 - val_accuracy: 0.8557\n",
            "Epoch 1354/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9362 - val_loss: 0.5319 - val_accuracy: 0.8531\n",
            "Epoch 1355/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9366 - val_loss: 0.5311 - val_accuracy: 0.8563\n",
            "Epoch 1356/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9352 - val_loss: 0.5303 - val_accuracy: 0.8550\n",
            "Epoch 1357/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9356 - val_loss: 0.5347 - val_accuracy: 0.8548\n",
            "Epoch 1358/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9366 - val_loss: 0.5332 - val_accuracy: 0.8549\n",
            "Epoch 1359/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9359 - val_loss: 0.5364 - val_accuracy: 0.8538\n",
            "Epoch 1360/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9356 - val_loss: 0.5344 - val_accuracy: 0.8534\n",
            "Epoch 1361/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1671 - accuracy: 0.9371 - val_loss: 0.5332 - val_accuracy: 0.8552\n",
            "Epoch 1362/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9360 - val_loss: 0.5325 - val_accuracy: 0.8552\n",
            "Epoch 1363/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9355 - val_loss: 0.5343 - val_accuracy: 0.8555\n",
            "Epoch 1364/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9352 - val_loss: 0.5320 - val_accuracy: 0.8531\n",
            "Epoch 1365/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9355 - val_loss: 0.5352 - val_accuracy: 0.8540\n",
            "Epoch 1366/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9355 - val_loss: 0.5290 - val_accuracy: 0.8548\n",
            "Epoch 1367/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9368 - val_loss: 0.5333 - val_accuracy: 0.8548\n",
            "Epoch 1368/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1691 - accuracy: 0.9352 - val_loss: 0.5333 - val_accuracy: 0.8532\n",
            "Epoch 1369/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1700 - accuracy: 0.9360 - val_loss: 0.5268 - val_accuracy: 0.8533\n",
            "Epoch 1370/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9360 - val_loss: 0.5323 - val_accuracy: 0.8525\n",
            "Epoch 1371/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9343 - val_loss: 0.5277 - val_accuracy: 0.8544\n",
            "Epoch 1372/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9367 - val_loss: 0.5286 - val_accuracy: 0.8533\n",
            "Epoch 1373/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9362 - val_loss: 0.5346 - val_accuracy: 0.8536\n",
            "Epoch 1374/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9353 - val_loss: 0.5318 - val_accuracy: 0.8537\n",
            "Epoch 1375/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1685 - accuracy: 0.9361 - val_loss: 0.5370 - val_accuracy: 0.8540\n",
            "Epoch 1376/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9362 - val_loss: 0.5320 - val_accuracy: 0.8542\n",
            "Epoch 1377/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9357 - val_loss: 0.5288 - val_accuracy: 0.8558\n",
            "Epoch 1378/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9369 - val_loss: 0.5295 - val_accuracy: 0.8551\n",
            "Epoch 1379/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1681 - accuracy: 0.9360 - val_loss: 0.5332 - val_accuracy: 0.8544\n",
            "Epoch 1380/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1669 - accuracy: 0.9375 - val_loss: 0.5284 - val_accuracy: 0.8551\n",
            "Epoch 1381/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9365 - val_loss: 0.5313 - val_accuracy: 0.8559\n",
            "Epoch 1382/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9365 - val_loss: 0.5355 - val_accuracy: 0.8531\n",
            "Epoch 1383/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9357 - val_loss: 0.5347 - val_accuracy: 0.8529\n",
            "Epoch 1384/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9360 - val_loss: 0.5318 - val_accuracy: 0.8542\n",
            "Epoch 1385/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9351 - val_loss: 0.5280 - val_accuracy: 0.8568\n",
            "Epoch 1386/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9356 - val_loss: 0.5328 - val_accuracy: 0.8534\n",
            "Epoch 1387/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9366 - val_loss: 0.5335 - val_accuracy: 0.8543\n",
            "Epoch 1388/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1689 - accuracy: 0.9360 - val_loss: 0.5378 - val_accuracy: 0.8525\n",
            "Epoch 1389/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1654 - accuracy: 0.9368 - val_loss: 0.5336 - val_accuracy: 0.8542\n",
            "Epoch 1390/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9372 - val_loss: 0.5384 - val_accuracy: 0.8533\n",
            "Epoch 1391/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1705 - accuracy: 0.9341 - val_loss: 0.5330 - val_accuracy: 0.8536\n",
            "Epoch 1392/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9364 - val_loss: 0.5341 - val_accuracy: 0.8544\n",
            "Epoch 1393/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1678 - accuracy: 0.9358 - val_loss: 0.5352 - val_accuracy: 0.8550\n",
            "Epoch 1394/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9363 - val_loss: 0.5366 - val_accuracy: 0.8577\n",
            "Epoch 1395/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1704 - accuracy: 0.9349 - val_loss: 0.5362 - val_accuracy: 0.8545\n",
            "Epoch 1396/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9368 - val_loss: 0.5358 - val_accuracy: 0.8551\n",
            "Epoch 1397/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1701 - accuracy: 0.9354 - val_loss: 0.5313 - val_accuracy: 0.8552\n",
            "Epoch 1398/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1663 - accuracy: 0.9371 - val_loss: 0.5324 - val_accuracy: 0.8551\n",
            "Epoch 1399/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9367 - val_loss: 0.5309 - val_accuracy: 0.8530\n",
            "Epoch 1400/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1653 - accuracy: 0.9369 - val_loss: 0.5316 - val_accuracy: 0.8547\n",
            "Epoch 1401/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1653 - accuracy: 0.9376 - val_loss: 0.5388 - val_accuracy: 0.8540\n",
            "Epoch 1402/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9363 - val_loss: 0.5340 - val_accuracy: 0.8553\n",
            "Epoch 1403/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1644 - accuracy: 0.9381 - val_loss: 0.5339 - val_accuracy: 0.8549\n",
            "Epoch 1404/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9355 - val_loss: 0.5346 - val_accuracy: 0.8532\n",
            "Epoch 1405/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9361 - val_loss: 0.5357 - val_accuracy: 0.8544\n",
            "Epoch 1406/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9362 - val_loss: 0.5382 - val_accuracy: 0.8545\n",
            "Epoch 1407/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1654 - accuracy: 0.9370 - val_loss: 0.5355 - val_accuracy: 0.8544\n",
            "Epoch 1408/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9366 - val_loss: 0.5370 - val_accuracy: 0.8552\n",
            "Epoch 1409/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9371 - val_loss: 0.5399 - val_accuracy: 0.8559\n",
            "Epoch 1410/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1677 - accuracy: 0.9359 - val_loss: 0.5371 - val_accuracy: 0.8539\n",
            "Epoch 1411/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1658 - accuracy: 0.9372 - val_loss: 0.5338 - val_accuracy: 0.8540\n",
            "Epoch 1412/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1675 - accuracy: 0.9351 - val_loss: 0.5328 - val_accuracy: 0.8559\n",
            "Epoch 1413/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1660 - accuracy: 0.9378 - val_loss: 0.5364 - val_accuracy: 0.8533\n",
            "Epoch 1414/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9361 - val_loss: 0.5408 - val_accuracy: 0.8532\n",
            "Epoch 1415/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1664 - accuracy: 0.9373 - val_loss: 0.5378 - val_accuracy: 0.8541\n",
            "Epoch 1416/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9366 - val_loss: 0.5351 - val_accuracy: 0.8559\n",
            "Epoch 1417/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9344 - val_loss: 0.5383 - val_accuracy: 0.8551\n",
            "Epoch 1418/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9361 - val_loss: 0.5364 - val_accuracy: 0.8537\n",
            "Epoch 1419/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9356 - val_loss: 0.5348 - val_accuracy: 0.8542\n",
            "Epoch 1420/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9356 - val_loss: 0.5347 - val_accuracy: 0.8551\n",
            "Epoch 1421/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.1665 - accuracy: 0.9363 - val_loss: 0.5353 - val_accuracy: 0.8556\n",
            "Epoch 1422/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1661 - accuracy: 0.9376 - val_loss: 0.5377 - val_accuracy: 0.8544\n",
            "Epoch 1423/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1657 - accuracy: 0.9372 - val_loss: 0.5406 - val_accuracy: 0.8542\n",
            "Epoch 1424/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9351 - val_loss: 0.5409 - val_accuracy: 0.8539\n",
            "Epoch 1425/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9367 - val_loss: 0.5378 - val_accuracy: 0.8551\n",
            "Epoch 1426/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.5410 - val_accuracy: 0.8537\n",
            "Epoch 1427/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9362 - val_loss: 0.5374 - val_accuracy: 0.8534\n",
            "Epoch 1428/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9362 - val_loss: 0.5336 - val_accuracy: 0.8551\n",
            "Epoch 1429/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1683 - accuracy: 0.9351 - val_loss: 0.5392 - val_accuracy: 0.8555\n",
            "Epoch 1430/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1701 - accuracy: 0.9356 - val_loss: 0.5347 - val_accuracy: 0.8550\n",
            "Epoch 1431/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9371 - val_loss: 0.5383 - val_accuracy: 0.8544\n",
            "Epoch 1432/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9355 - val_loss: 0.5370 - val_accuracy: 0.8535\n",
            "Epoch 1433/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9369 - val_loss: 0.5336 - val_accuracy: 0.8554\n",
            "Epoch 1434/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9366 - val_loss: 0.5371 - val_accuracy: 0.8543\n",
            "Epoch 1435/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9354 - val_loss: 0.5352 - val_accuracy: 0.8557\n",
            "Epoch 1436/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9361 - val_loss: 0.5404 - val_accuracy: 0.8548\n",
            "Epoch 1437/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1680 - accuracy: 0.9363 - val_loss: 0.5369 - val_accuracy: 0.8536\n",
            "Epoch 1438/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1659 - accuracy: 0.9364 - val_loss: 0.5380 - val_accuracy: 0.8554\n",
            "Epoch 1439/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9357 - val_loss: 0.5361 - val_accuracy: 0.8551\n",
            "Epoch 1440/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1656 - accuracy: 0.9370 - val_loss: 0.5343 - val_accuracy: 0.8553\n",
            "Epoch 1441/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9359 - val_loss: 0.5336 - val_accuracy: 0.8547\n",
            "Epoch 1442/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.5360 - val_accuracy: 0.8562\n",
            "Epoch 1443/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9347 - val_loss: 0.5337 - val_accuracy: 0.8563\n",
            "Epoch 1444/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9376 - val_loss: 0.5394 - val_accuracy: 0.8553\n",
            "Epoch 1445/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1678 - accuracy: 0.9359 - val_loss: 0.5363 - val_accuracy: 0.8560\n",
            "Epoch 1446/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9349 - val_loss: 0.5352 - val_accuracy: 0.8556\n",
            "Epoch 1447/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9372 - val_loss: 0.5342 - val_accuracy: 0.8552\n",
            "Epoch 1448/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9378 - val_loss: 0.5388 - val_accuracy: 0.8538\n",
            "Epoch 1449/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1651 - accuracy: 0.9368 - val_loss: 0.5330 - val_accuracy: 0.8559\n",
            "Epoch 1450/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9350 - val_loss: 0.5341 - val_accuracy: 0.8552\n",
            "Epoch 1451/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1666 - accuracy: 0.9376 - val_loss: 0.5364 - val_accuracy: 0.8562\n",
            "Epoch 1452/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1643 - accuracy: 0.9374 - val_loss: 0.5345 - val_accuracy: 0.8557\n",
            "Epoch 1453/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9362 - val_loss: 0.5339 - val_accuracy: 0.8560\n",
            "Epoch 1454/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1669 - accuracy: 0.9363 - val_loss: 0.5357 - val_accuracy: 0.8566\n",
            "Epoch 1455/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9356 - val_loss: 0.5388 - val_accuracy: 0.8535\n",
            "Epoch 1456/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1707 - accuracy: 0.9339 - val_loss: 0.5361 - val_accuracy: 0.8553\n",
            "Epoch 1457/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1649 - accuracy: 0.9370 - val_loss: 0.5370 - val_accuracy: 0.8566\n",
            "Epoch 1458/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9365 - val_loss: 0.5428 - val_accuracy: 0.8525\n",
            "Epoch 1459/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9362 - val_loss: 0.5419 - val_accuracy: 0.8559\n",
            "Epoch 1460/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1658 - accuracy: 0.9371 - val_loss: 0.5358 - val_accuracy: 0.8545\n",
            "Epoch 1461/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1663 - accuracy: 0.9362 - val_loss: 0.5369 - val_accuracy: 0.8562\n",
            "Epoch 1462/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1673 - accuracy: 0.9377 - val_loss: 0.5383 - val_accuracy: 0.8560\n",
            "Epoch 1463/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1648 - accuracy: 0.9373 - val_loss: 0.5366 - val_accuracy: 0.8533\n",
            "Epoch 1464/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1648 - accuracy: 0.9379 - val_loss: 0.5383 - val_accuracy: 0.8559\n",
            "Epoch 1465/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1669 - accuracy: 0.9357 - val_loss: 0.5349 - val_accuracy: 0.8544\n",
            "Epoch 1466/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1656 - accuracy: 0.9373 - val_loss: 0.5370 - val_accuracy: 0.8572\n",
            "Epoch 1467/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9357 - val_loss: 0.5464 - val_accuracy: 0.8532\n",
            "Epoch 1468/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1652 - accuracy: 0.9375 - val_loss: 0.5393 - val_accuracy: 0.8556\n",
            "Epoch 1469/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1649 - accuracy: 0.9380 - val_loss: 0.5432 - val_accuracy: 0.8534\n",
            "Epoch 1470/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1668 - accuracy: 0.9374 - val_loss: 0.5484 - val_accuracy: 0.8555\n",
            "Epoch 1471/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9358 - val_loss: 0.5433 - val_accuracy: 0.8544\n",
            "Epoch 1472/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1671 - accuracy: 0.9372 - val_loss: 0.5422 - val_accuracy: 0.8540\n",
            "Epoch 1473/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9361 - val_loss: 0.5422 - val_accuracy: 0.8558\n",
            "Epoch 1474/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1669 - accuracy: 0.9358 - val_loss: 0.5360 - val_accuracy: 0.8533\n",
            "Epoch 1475/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1657 - accuracy: 0.9371 - val_loss: 0.5416 - val_accuracy: 0.8529\n",
            "Epoch 1476/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1663 - accuracy: 0.9365 - val_loss: 0.5379 - val_accuracy: 0.8522\n",
            "Epoch 1477/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9362 - val_loss: 0.5414 - val_accuracy: 0.8541\n",
            "Epoch 1478/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1635 - accuracy: 0.9374 - val_loss: 0.5389 - val_accuracy: 0.8547\n",
            "Epoch 1479/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1670 - accuracy: 0.9370 - val_loss: 0.5489 - val_accuracy: 0.8539\n",
            "Epoch 1480/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1670 - accuracy: 0.9367 - val_loss: 0.5432 - val_accuracy: 0.8553\n",
            "Epoch 1481/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1670 - accuracy: 0.9361 - val_loss: 0.5424 - val_accuracy: 0.8556\n",
            "Epoch 1482/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1655 - accuracy: 0.9372 - val_loss: 0.5414 - val_accuracy: 0.8564\n",
            "Epoch 1483/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9354 - val_loss: 0.5394 - val_accuracy: 0.8550\n",
            "Epoch 1484/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9363 - val_loss: 0.5401 - val_accuracy: 0.8548\n",
            "Epoch 1485/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9366 - val_loss: 0.5397 - val_accuracy: 0.8536\n",
            "Epoch 1486/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9362 - val_loss: 0.5373 - val_accuracy: 0.8562\n",
            "Epoch 1487/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9363 - val_loss: 0.5420 - val_accuracy: 0.8560\n",
            "Epoch 1488/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9369 - val_loss: 0.5442 - val_accuracy: 0.8544\n",
            "Epoch 1489/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9357 - val_loss: 0.5361 - val_accuracy: 0.8547\n",
            "Epoch 1490/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1684 - accuracy: 0.9359 - val_loss: 0.5379 - val_accuracy: 0.8553\n",
            "Epoch 1491/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1664 - accuracy: 0.9369 - val_loss: 0.5352 - val_accuracy: 0.8563\n",
            "Epoch 1492/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9360 - val_loss: 0.5372 - val_accuracy: 0.8550\n",
            "Epoch 1493/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1665 - accuracy: 0.9359 - val_loss: 0.5342 - val_accuracy: 0.8565\n",
            "Epoch 1494/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9366 - val_loss: 0.5415 - val_accuracy: 0.8548\n",
            "Epoch 1495/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9369 - val_loss: 0.5371 - val_accuracy: 0.8557\n",
            "Epoch 1496/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9367 - val_loss: 0.5388 - val_accuracy: 0.8551\n",
            "Epoch 1497/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9369 - val_loss: 0.5384 - val_accuracy: 0.8558\n",
            "Epoch 1498/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1652 - accuracy: 0.9362 - val_loss: 0.5414 - val_accuracy: 0.8565\n",
            "Epoch 1499/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9374 - val_loss: 0.5345 - val_accuracy: 0.8552\n",
            "Epoch 1500/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1654 - accuracy: 0.9381 - val_loss: 0.5395 - val_accuracy: 0.8537\n",
            "===============Save loss and acc===============\n",
            "===============build model2===============\n",
            "[[ 0.9125702   1.0695566  -0.17167082 ... -0.09951374  0.72831595\n",
            "  -0.23625985]\n",
            " [ 0.6600948   0.06240575  1.3144156  ... -1.8161316  -0.00564129\n",
            "   0.1620477 ]\n",
            " [ 1.0321238   0.15680301 -1.7170254  ...  1.4370385   1.405816\n",
            "   1.1456367 ]\n",
            " ...\n",
            " [-1.3542069  -0.3898817   0.22639309 ... -1.5649254   1.3800268\n",
            "   0.6186452 ]\n",
            " [ 0.73457015  0.46793255  1.422731   ... -0.47923353 -0.45793504\n",
            "   0.32027408]\n",
            " [-0.00762544 -0.38873342 -0.4980457  ... -0.58920044 -0.34291363\n",
            "  -1.7683132 ]]\n",
            "===============Train model2===============\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "Epoch 1/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 18s 46ms/step - loss: 2.3629 - accuracy: 0.1892 - val_loss: 2.2896 - val_accuracy: 0.2539\n",
            "Epoch 2/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 1.9117 - accuracy: 0.3476 - val_loss: 1.7417 - val_accuracy: 0.4193\n",
            "Epoch 3/1500\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 1.5644 - accuracy: 0.4939 - val_loss: 1.3915 - val_accuracy: 0.5523\n",
            "Epoch 4/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 1.2471 - accuracy: 0.6058 - val_loss: 1.1101 - val_accuracy: 0.6425\n",
            "Epoch 5/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 1.0080 - accuracy: 0.6793 - val_loss: 0.9220 - val_accuracy: 0.6959\n",
            "Epoch 6/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 0.8532 - accuracy: 0.7225 - val_loss: 0.8005 - val_accuracy: 0.7333\n",
            "Epoch 7/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.7479 - accuracy: 0.7529 - val_loss: 0.7200 - val_accuracy: 0.7593\n",
            "Epoch 8/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 0.6747 - accuracy: 0.7750 - val_loss: 0.6635 - val_accuracy: 0.7741\n",
            "Epoch 9/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.6197 - accuracy: 0.7900 - val_loss: 0.6185 - val_accuracy: 0.7869\n",
            "Epoch 10/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 0.5811 - accuracy: 0.8023 - val_loss: 0.5867 - val_accuracy: 0.7966\n",
            "Epoch 11/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.5489 - accuracy: 0.8117 - val_loss: 0.5632 - val_accuracy: 0.8045\n",
            "Epoch 12/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.5234 - accuracy: 0.8192 - val_loss: 0.5418 - val_accuracy: 0.8122\n",
            "Epoch 13/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 44ms/step - loss: 0.5035 - accuracy: 0.8241 - val_loss: 0.5268 - val_accuracy: 0.8157\n",
            "Epoch 14/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 44ms/step - loss: 0.4858 - accuracy: 0.8312 - val_loss: 0.5147 - val_accuracy: 0.8192\n",
            "Epoch 15/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.4728 - accuracy: 0.8342 - val_loss: 0.5022 - val_accuracy: 0.8216\n",
            "Epoch 16/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.4587 - accuracy: 0.8398 - val_loss: 0.4932 - val_accuracy: 0.8245\n",
            "Epoch 17/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.4485 - accuracy: 0.8413 - val_loss: 0.4860 - val_accuracy: 0.8279\n",
            "Epoch 18/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.4371 - accuracy: 0.8453 - val_loss: 0.4787 - val_accuracy: 0.8297\n",
            "Epoch 19/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 0.4290 - accuracy: 0.8493 - val_loss: 0.4713 - val_accuracy: 0.8309\n",
            "Epoch 20/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 42ms/step - loss: 0.4181 - accuracy: 0.8524 - val_loss: 0.4674 - val_accuracy: 0.8337\n",
            "Epoch 21/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.4109 - accuracy: 0.8543 - val_loss: 0.4622 - val_accuracy: 0.8350\n",
            "Epoch 22/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.4059 - accuracy: 0.8558 - val_loss: 0.4569 - val_accuracy: 0.8363\n",
            "Epoch 23/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.4001 - accuracy: 0.8569 - val_loss: 0.4537 - val_accuracy: 0.8385\n",
            "Epoch 24/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.3934 - accuracy: 0.8597 - val_loss: 0.4496 - val_accuracy: 0.8403\n",
            "Epoch 25/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3886 - accuracy: 0.8612 - val_loss: 0.4478 - val_accuracy: 0.8398\n",
            "Epoch 26/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.3839 - accuracy: 0.8627 - val_loss: 0.4427 - val_accuracy: 0.8437\n",
            "Epoch 27/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3758 - accuracy: 0.8646 - val_loss: 0.4397 - val_accuracy: 0.8444\n",
            "Epoch 28/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3732 - accuracy: 0.8654 - val_loss: 0.4368 - val_accuracy: 0.8440\n",
            "Epoch 29/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3672 - accuracy: 0.8681 - val_loss: 0.4354 - val_accuracy: 0.8461\n",
            "Epoch 30/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.3652 - accuracy: 0.8679 - val_loss: 0.4338 - val_accuracy: 0.8462\n",
            "Epoch 31/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3617 - accuracy: 0.8688 - val_loss: 0.4304 - val_accuracy: 0.8482\n",
            "Epoch 32/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3569 - accuracy: 0.8710 - val_loss: 0.4277 - val_accuracy: 0.8480\n",
            "Epoch 33/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 45ms/step - loss: 0.3529 - accuracy: 0.8721 - val_loss: 0.4264 - val_accuracy: 0.8494\n",
            "Epoch 34/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3512 - accuracy: 0.8726 - val_loss: 0.4241 - val_accuracy: 0.8488\n",
            "Epoch 35/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3455 - accuracy: 0.8742 - val_loss: 0.4218 - val_accuracy: 0.8486\n",
            "Epoch 36/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.3455 - accuracy: 0.8746 - val_loss: 0.4212 - val_accuracy: 0.8506\n",
            "Epoch 37/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3409 - accuracy: 0.8758 - val_loss: 0.4202 - val_accuracy: 0.8518\n",
            "Epoch 38/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3380 - accuracy: 0.8762 - val_loss: 0.4182 - val_accuracy: 0.8505\n",
            "Epoch 39/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3351 - accuracy: 0.8780 - val_loss: 0.4180 - val_accuracy: 0.8487\n",
            "Epoch 40/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3334 - accuracy: 0.8788 - val_loss: 0.4153 - val_accuracy: 0.8510\n",
            "Epoch 41/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3307 - accuracy: 0.8798 - val_loss: 0.4165 - val_accuracy: 0.8502\n",
            "Epoch 42/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3278 - accuracy: 0.8809 - val_loss: 0.4144 - val_accuracy: 0.8508\n",
            "Epoch 43/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3280 - accuracy: 0.8795 - val_loss: 0.4126 - val_accuracy: 0.8513\n",
            "Epoch 44/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.3252 - accuracy: 0.8816 - val_loss: 0.4115 - val_accuracy: 0.8530\n",
            "Epoch 45/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3238 - accuracy: 0.8809 - val_loss: 0.4121 - val_accuracy: 0.8524\n",
            "Epoch 46/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3207 - accuracy: 0.8826 - val_loss: 0.4106 - val_accuracy: 0.8521\n",
            "Epoch 47/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3191 - accuracy: 0.8831 - val_loss: 0.4089 - val_accuracy: 0.8544\n",
            "Epoch 48/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3172 - accuracy: 0.8839 - val_loss: 0.4116 - val_accuracy: 0.8536\n",
            "Epoch 49/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3146 - accuracy: 0.8844 - val_loss: 0.4104 - val_accuracy: 0.8551\n",
            "Epoch 50/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.3146 - accuracy: 0.8842 - val_loss: 0.4105 - val_accuracy: 0.8537\n",
            "Epoch 51/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3115 - accuracy: 0.8860 - val_loss: 0.4130 - val_accuracy: 0.8527\n",
            "Epoch 52/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3100 - accuracy: 0.8866 - val_loss: 0.4099 - val_accuracy: 0.8548\n",
            "Epoch 53/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3088 - accuracy: 0.8868 - val_loss: 0.4119 - val_accuracy: 0.8548\n",
            "Epoch 54/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3073 - accuracy: 0.8869 - val_loss: 0.4112 - val_accuracy: 0.8550\n",
            "Epoch 55/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3058 - accuracy: 0.8870 - val_loss: 0.4111 - val_accuracy: 0.8547\n",
            "Epoch 56/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3038 - accuracy: 0.8887 - val_loss: 0.4099 - val_accuracy: 0.8563\n",
            "Epoch 57/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3031 - accuracy: 0.8875 - val_loss: 0.4104 - val_accuracy: 0.8583\n",
            "Epoch 58/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3019 - accuracy: 0.8895 - val_loss: 0.4078 - val_accuracy: 0.8543\n",
            "Epoch 59/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3006 - accuracy: 0.8891 - val_loss: 0.4105 - val_accuracy: 0.8550\n",
            "Epoch 60/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.2989 - accuracy: 0.8906 - val_loss: 0.4084 - val_accuracy: 0.8569\n",
            "Epoch 61/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2981 - accuracy: 0.8903 - val_loss: 0.4079 - val_accuracy: 0.8569\n",
            "Epoch 62/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2950 - accuracy: 0.8914 - val_loss: 0.4085 - val_accuracy: 0.8560\n",
            "Epoch 63/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2963 - accuracy: 0.8903 - val_loss: 0.4087 - val_accuracy: 0.8560\n",
            "Epoch 64/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2928 - accuracy: 0.8915 - val_loss: 0.4093 - val_accuracy: 0.8576\n",
            "Epoch 65/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2930 - accuracy: 0.8918 - val_loss: 0.4075 - val_accuracy: 0.8584\n",
            "Epoch 66/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.2894 - accuracy: 0.8931 - val_loss: 0.4075 - val_accuracy: 0.8579\n",
            "Epoch 67/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2918 - accuracy: 0.8915 - val_loss: 0.4072 - val_accuracy: 0.8593\n",
            "Epoch 68/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2907 - accuracy: 0.8928 - val_loss: 0.4063 - val_accuracy: 0.8590\n",
            "Epoch 69/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2891 - accuracy: 0.8931 - val_loss: 0.4078 - val_accuracy: 0.8579\n",
            "Epoch 70/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2870 - accuracy: 0.8934 - val_loss: 0.4085 - val_accuracy: 0.8589\n",
            "Epoch 71/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2865 - accuracy: 0.8943 - val_loss: 0.4071 - val_accuracy: 0.8591\n",
            "Epoch 72/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2848 - accuracy: 0.8952 - val_loss: 0.4083 - val_accuracy: 0.8575\n",
            "Epoch 73/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2860 - accuracy: 0.8943 - val_loss: 0.4090 - val_accuracy: 0.8569\n",
            "Epoch 74/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2821 - accuracy: 0.8951 - val_loss: 0.4092 - val_accuracy: 0.8603\n",
            "Epoch 75/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2841 - accuracy: 0.8946 - val_loss: 0.4071 - val_accuracy: 0.8594\n",
            "Epoch 76/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2787 - accuracy: 0.8969 - val_loss: 0.4045 - val_accuracy: 0.8594\n",
            "Epoch 77/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2821 - accuracy: 0.8955 - val_loss: 0.4058 - val_accuracy: 0.8582\n",
            "Epoch 78/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2796 - accuracy: 0.8975 - val_loss: 0.4081 - val_accuracy: 0.8572\n",
            "Epoch 79/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.2778 - accuracy: 0.8972 - val_loss: 0.4112 - val_accuracy: 0.8567\n",
            "Epoch 80/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2799 - accuracy: 0.8960 - val_loss: 0.4097 - val_accuracy: 0.8596\n",
            "Epoch 81/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2755 - accuracy: 0.8979 - val_loss: 0.4099 - val_accuracy: 0.8588\n",
            "Epoch 82/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2742 - accuracy: 0.8980 - val_loss: 0.4093 - val_accuracy: 0.8594\n",
            "Epoch 83/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2741 - accuracy: 0.8979 - val_loss: 0.4144 - val_accuracy: 0.8570\n",
            "Epoch 84/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2750 - accuracy: 0.8981 - val_loss: 0.4087 - val_accuracy: 0.8608\n",
            "Epoch 85/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2753 - accuracy: 0.8985 - val_loss: 0.4102 - val_accuracy: 0.8579\n",
            "Epoch 86/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2740 - accuracy: 0.8985 - val_loss: 0.4116 - val_accuracy: 0.8571\n",
            "Epoch 87/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2701 - accuracy: 0.9008 - val_loss: 0.4113 - val_accuracy: 0.8587\n",
            "Epoch 88/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2735 - accuracy: 0.8986 - val_loss: 0.4125 - val_accuracy: 0.8588\n",
            "Epoch 89/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2703 - accuracy: 0.8995 - val_loss: 0.4097 - val_accuracy: 0.8593\n",
            "Epoch 90/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2683 - accuracy: 0.8995 - val_loss: 0.4107 - val_accuracy: 0.8591\n",
            "Epoch 91/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2668 - accuracy: 0.9010 - val_loss: 0.4109 - val_accuracy: 0.8588\n",
            "Epoch 92/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2678 - accuracy: 0.9009 - val_loss: 0.4137 - val_accuracy: 0.8592\n",
            "Epoch 93/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2655 - accuracy: 0.9008 - val_loss: 0.4156 - val_accuracy: 0.8581\n",
            "Epoch 94/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.2682 - accuracy: 0.9002 - val_loss: 0.4151 - val_accuracy: 0.8591\n",
            "Epoch 95/1500\n",
            "235/235 [==============================] - 5s 14ms/step - loss: 0.2671 - accuracy: 0.9008 - val_loss: 0.4151 - val_accuracy: 0.8591\n",
            "Epoch 96/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2644 - accuracy: 0.9014 - val_loss: 0.4163 - val_accuracy: 0.8584\n",
            "Epoch 97/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2647 - accuracy: 0.9014 - val_loss: 0.4170 - val_accuracy: 0.8581\n",
            "Epoch 98/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2641 - accuracy: 0.9021 - val_loss: 0.4183 - val_accuracy: 0.8553\n",
            "Epoch 99/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2611 - accuracy: 0.9037 - val_loss: 0.4163 - val_accuracy: 0.8577\n",
            "Epoch 100/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2637 - accuracy: 0.9021 - val_loss: 0.4148 - val_accuracy: 0.8586\n",
            "Epoch 101/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2619 - accuracy: 0.9025 - val_loss: 0.4169 - val_accuracy: 0.8574\n",
            "Epoch 102/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2618 - accuracy: 0.9026 - val_loss: 0.4191 - val_accuracy: 0.8573\n",
            "Epoch 103/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.2605 - accuracy: 0.9042 - val_loss: 0.4186 - val_accuracy: 0.8562\n",
            "Epoch 104/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2598 - accuracy: 0.9038 - val_loss: 0.4193 - val_accuracy: 0.8569\n",
            "Epoch 105/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2577 - accuracy: 0.9044 - val_loss: 0.4183 - val_accuracy: 0.8560\n",
            "Epoch 106/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2583 - accuracy: 0.9040 - val_loss: 0.4163 - val_accuracy: 0.8587\n",
            "Epoch 107/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2566 - accuracy: 0.9050 - val_loss: 0.4187 - val_accuracy: 0.8574\n",
            "Epoch 108/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2575 - accuracy: 0.9045 - val_loss: 0.4192 - val_accuracy: 0.8577\n",
            "Epoch 109/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2568 - accuracy: 0.9039 - val_loss: 0.4175 - val_accuracy: 0.8589\n",
            "Epoch 110/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2555 - accuracy: 0.9052 - val_loss: 0.4176 - val_accuracy: 0.8577\n",
            "Epoch 111/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2547 - accuracy: 0.9051 - val_loss: 0.4195 - val_accuracy: 0.8570\n",
            "Epoch 112/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2533 - accuracy: 0.9060 - val_loss: 0.4214 - val_accuracy: 0.8563\n",
            "Epoch 113/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.2553 - accuracy: 0.9054 - val_loss: 0.4183 - val_accuracy: 0.8603\n",
            "Epoch 114/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2528 - accuracy: 0.9060 - val_loss: 0.4212 - val_accuracy: 0.8589\n",
            "Epoch 115/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2541 - accuracy: 0.9048 - val_loss: 0.4221 - val_accuracy: 0.8588\n",
            "Epoch 116/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2510 - accuracy: 0.9061 - val_loss: 0.4210 - val_accuracy: 0.8595\n",
            "Epoch 117/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2507 - accuracy: 0.9068 - val_loss: 0.4213 - val_accuracy: 0.8587\n",
            "Epoch 118/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2518 - accuracy: 0.9058 - val_loss: 0.4203 - val_accuracy: 0.8592\n",
            "Epoch 119/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2509 - accuracy: 0.9072 - val_loss: 0.4207 - val_accuracy: 0.8592\n",
            "Epoch 120/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2485 - accuracy: 0.9077 - val_loss: 0.4245 - val_accuracy: 0.8563\n",
            "Epoch 121/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2508 - accuracy: 0.9073 - val_loss: 0.4223 - val_accuracy: 0.8574\n",
            "Epoch 122/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2503 - accuracy: 0.9069 - val_loss: 0.4243 - val_accuracy: 0.8588\n",
            "Epoch 123/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2479 - accuracy: 0.9081 - val_loss: 0.4220 - val_accuracy: 0.8602\n",
            "Epoch 124/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.2464 - accuracy: 0.9073 - val_loss: 0.4234 - val_accuracy: 0.8573\n",
            "Epoch 125/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2469 - accuracy: 0.9086 - val_loss: 0.4270 - val_accuracy: 0.8594\n",
            "Epoch 126/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2452 - accuracy: 0.9095 - val_loss: 0.4277 - val_accuracy: 0.8579\n",
            "Epoch 127/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2494 - accuracy: 0.9077 - val_loss: 0.4261 - val_accuracy: 0.8580\n",
            "Epoch 128/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2470 - accuracy: 0.9087 - val_loss: 0.4272 - val_accuracy: 0.8595\n",
            "Epoch 129/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2455 - accuracy: 0.9088 - val_loss: 0.4249 - val_accuracy: 0.8590\n",
            "Epoch 130/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2447 - accuracy: 0.9085 - val_loss: 0.4284 - val_accuracy: 0.8586\n",
            "Epoch 131/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2473 - accuracy: 0.9084 - val_loss: 0.4252 - val_accuracy: 0.8582\n",
            "Epoch 132/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2458 - accuracy: 0.9089 - val_loss: 0.4254 - val_accuracy: 0.8567\n",
            "Epoch 133/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2425 - accuracy: 0.9092 - val_loss: 0.4295 - val_accuracy: 0.8573\n",
            "Epoch 134/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2438 - accuracy: 0.9086 - val_loss: 0.4248 - val_accuracy: 0.8612\n",
            "Epoch 135/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2432 - accuracy: 0.9096 - val_loss: 0.4285 - val_accuracy: 0.8581\n",
            "Epoch 136/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.2437 - accuracy: 0.9089 - val_loss: 0.4265 - val_accuracy: 0.8575\n",
            "Epoch 137/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.2413 - accuracy: 0.9100 - val_loss: 0.4243 - val_accuracy: 0.8565\n",
            "Epoch 138/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2439 - accuracy: 0.9096 - val_loss: 0.4266 - val_accuracy: 0.8579\n",
            "Epoch 139/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2405 - accuracy: 0.9098 - val_loss: 0.4262 - val_accuracy: 0.8572\n",
            "Epoch 140/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2414 - accuracy: 0.9111 - val_loss: 0.4283 - val_accuracy: 0.8589\n",
            "Epoch 141/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2421 - accuracy: 0.9100 - val_loss: 0.4250 - val_accuracy: 0.8600\n",
            "Epoch 142/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2450 - accuracy: 0.9093 - val_loss: 0.4274 - val_accuracy: 0.8582\n",
            "Epoch 143/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2418 - accuracy: 0.9094 - val_loss: 0.4259 - val_accuracy: 0.8618\n",
            "Epoch 144/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2411 - accuracy: 0.9102 - val_loss: 0.4251 - val_accuracy: 0.8595\n",
            "Epoch 145/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2378 - accuracy: 0.9112 - val_loss: 0.4274 - val_accuracy: 0.8605\n",
            "Epoch 146/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2398 - accuracy: 0.9106 - val_loss: 0.4288 - val_accuracy: 0.8572\n",
            "Epoch 147/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2403 - accuracy: 0.9111 - val_loss: 0.4306 - val_accuracy: 0.8586\n",
            "Epoch 148/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2401 - accuracy: 0.9100 - val_loss: 0.4346 - val_accuracy: 0.8542\n",
            "Epoch 149/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.2399 - accuracy: 0.9101 - val_loss: 0.4316 - val_accuracy: 0.8565\n",
            "Epoch 150/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2408 - accuracy: 0.9103 - val_loss: 0.4337 - val_accuracy: 0.8559\n",
            "Epoch 151/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2418 - accuracy: 0.9100 - val_loss: 0.4320 - val_accuracy: 0.8581\n",
            "Epoch 152/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2348 - accuracy: 0.9123 - val_loss: 0.4296 - val_accuracy: 0.8568\n",
            "Epoch 153/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2383 - accuracy: 0.9111 - val_loss: 0.4292 - val_accuracy: 0.8587\n",
            "Epoch 154/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2382 - accuracy: 0.9112 - val_loss: 0.4287 - val_accuracy: 0.8562\n",
            "Epoch 155/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2359 - accuracy: 0.9130 - val_loss: 0.4324 - val_accuracy: 0.8585\n",
            "Epoch 156/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2343 - accuracy: 0.9127 - val_loss: 0.4328 - val_accuracy: 0.8567\n",
            "Epoch 157/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2374 - accuracy: 0.9117 - val_loss: 0.4329 - val_accuracy: 0.8572\n",
            "Epoch 158/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2366 - accuracy: 0.9117 - val_loss: 0.4321 - val_accuracy: 0.8571\n",
            "Epoch 159/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2346 - accuracy: 0.9131 - val_loss: 0.4356 - val_accuracy: 0.8568\n",
            "Epoch 160/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2353 - accuracy: 0.9130 - val_loss: 0.4332 - val_accuracy: 0.8554\n",
            "Epoch 161/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2344 - accuracy: 0.9125 - val_loss: 0.4352 - val_accuracy: 0.8544\n",
            "Epoch 162/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2342 - accuracy: 0.9136 - val_loss: 0.4333 - val_accuracy: 0.8583\n",
            "Epoch 163/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.2336 - accuracy: 0.9130 - val_loss: 0.4369 - val_accuracy: 0.8556\n",
            "Epoch 164/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2332 - accuracy: 0.9133 - val_loss: 0.4373 - val_accuracy: 0.8565\n",
            "Epoch 165/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2333 - accuracy: 0.9136 - val_loss: 0.4387 - val_accuracy: 0.8574\n",
            "Epoch 166/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2326 - accuracy: 0.9140 - val_loss: 0.4355 - val_accuracy: 0.8584\n",
            "Epoch 167/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2352 - accuracy: 0.9123 - val_loss: 0.4376 - val_accuracy: 0.8596\n",
            "Epoch 168/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2317 - accuracy: 0.9137 - val_loss: 0.4371 - val_accuracy: 0.8562\n",
            "Epoch 169/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2322 - accuracy: 0.9137 - val_loss: 0.4358 - val_accuracy: 0.8563\n",
            "Epoch 170/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2341 - accuracy: 0.9119 - val_loss: 0.4376 - val_accuracy: 0.8594\n",
            "Epoch 171/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2323 - accuracy: 0.9133 - val_loss: 0.4339 - val_accuracy: 0.8593\n",
            "Epoch 172/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2314 - accuracy: 0.9147 - val_loss: 0.4364 - val_accuracy: 0.8582\n",
            "Epoch 173/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2320 - accuracy: 0.9139 - val_loss: 0.4379 - val_accuracy: 0.8586\n",
            "Epoch 174/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2306 - accuracy: 0.9146 - val_loss: 0.4358 - val_accuracy: 0.8589\n",
            "Epoch 175/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2305 - accuracy: 0.9144 - val_loss: 0.4389 - val_accuracy: 0.8588\n",
            "Epoch 176/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2304 - accuracy: 0.9129 - val_loss: 0.4386 - val_accuracy: 0.8583\n",
            "Epoch 177/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2309 - accuracy: 0.9148 - val_loss: 0.4409 - val_accuracy: 0.8584\n",
            "Epoch 178/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2314 - accuracy: 0.9129 - val_loss: 0.4412 - val_accuracy: 0.8557\n",
            "Epoch 179/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.2281 - accuracy: 0.9147 - val_loss: 0.4410 - val_accuracy: 0.8583\n",
            "Epoch 180/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2284 - accuracy: 0.9147 - val_loss: 0.4375 - val_accuracy: 0.8581\n",
            "Epoch 181/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2275 - accuracy: 0.9147 - val_loss: 0.4394 - val_accuracy: 0.8578\n",
            "Epoch 182/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2292 - accuracy: 0.9142 - val_loss: 0.4392 - val_accuracy: 0.8593\n",
            "Epoch 183/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2267 - accuracy: 0.9149 - val_loss: 0.4427 - val_accuracy: 0.8586\n",
            "Epoch 184/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2265 - accuracy: 0.9141 - val_loss: 0.4446 - val_accuracy: 0.8550\n",
            "Epoch 185/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2270 - accuracy: 0.9153 - val_loss: 0.4408 - val_accuracy: 0.8548\n",
            "Epoch 186/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2286 - accuracy: 0.9152 - val_loss: 0.4412 - val_accuracy: 0.8565\n",
            "Epoch 187/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2272 - accuracy: 0.9147 - val_loss: 0.4434 - val_accuracy: 0.8558\n",
            "Epoch 188/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2292 - accuracy: 0.9139 - val_loss: 0.4389 - val_accuracy: 0.8608\n",
            "Epoch 189/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2262 - accuracy: 0.9161 - val_loss: 0.4408 - val_accuracy: 0.8560\n",
            "Epoch 190/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2281 - accuracy: 0.9138 - val_loss: 0.4410 - val_accuracy: 0.8579\n",
            "Epoch 191/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2290 - accuracy: 0.9149 - val_loss: 0.4425 - val_accuracy: 0.8568\n",
            "Epoch 192/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2289 - accuracy: 0.9138 - val_loss: 0.4398 - val_accuracy: 0.8579\n",
            "Epoch 193/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2236 - accuracy: 0.9167 - val_loss: 0.4398 - val_accuracy: 0.8579\n",
            "Epoch 194/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2268 - accuracy: 0.9160 - val_loss: 0.4414 - val_accuracy: 0.8601\n",
            "Epoch 195/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2261 - accuracy: 0.9152 - val_loss: 0.4434 - val_accuracy: 0.8579\n",
            "Epoch 196/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.2262 - accuracy: 0.9149 - val_loss: 0.4423 - val_accuracy: 0.8599\n",
            "Epoch 197/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2263 - accuracy: 0.9158 - val_loss: 0.4439 - val_accuracy: 0.8581\n",
            "Epoch 198/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2245 - accuracy: 0.9168 - val_loss: 0.4419 - val_accuracy: 0.8584\n",
            "Epoch 199/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2256 - accuracy: 0.9153 - val_loss: 0.4412 - val_accuracy: 0.8565\n",
            "Epoch 200/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2260 - accuracy: 0.9152 - val_loss: 0.4426 - val_accuracy: 0.8579\n",
            "Epoch 201/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2278 - accuracy: 0.9151 - val_loss: 0.4416 - val_accuracy: 0.8591\n",
            "Epoch 202/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2224 - accuracy: 0.9162 - val_loss: 0.4458 - val_accuracy: 0.8592\n",
            "Epoch 203/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2254 - accuracy: 0.9161 - val_loss: 0.4471 - val_accuracy: 0.8554\n",
            "Epoch 204/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2225 - accuracy: 0.9163 - val_loss: 0.4431 - val_accuracy: 0.8583\n",
            "Epoch 205/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2264 - accuracy: 0.9156 - val_loss: 0.4433 - val_accuracy: 0.8592\n",
            "Epoch 206/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2208 - accuracy: 0.9172 - val_loss: 0.4449 - val_accuracy: 0.8558\n",
            "Epoch 207/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2215 - accuracy: 0.9171 - val_loss: 0.4449 - val_accuracy: 0.8573\n",
            "Epoch 208/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2227 - accuracy: 0.9157 - val_loss: 0.4422 - val_accuracy: 0.8583\n",
            "Epoch 209/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2237 - accuracy: 0.9162 - val_loss: 0.4454 - val_accuracy: 0.8541\n",
            "Epoch 210/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2226 - accuracy: 0.9163 - val_loss: 0.4443 - val_accuracy: 0.8565\n",
            "Epoch 211/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2219 - accuracy: 0.9174 - val_loss: 0.4433 - val_accuracy: 0.8575\n",
            "Epoch 212/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2207 - accuracy: 0.9173 - val_loss: 0.4479 - val_accuracy: 0.8534\n",
            "Epoch 213/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2225 - accuracy: 0.9160 - val_loss: 0.4476 - val_accuracy: 0.8569\n",
            "Epoch 214/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2215 - accuracy: 0.9172 - val_loss: 0.4471 - val_accuracy: 0.8568\n",
            "Epoch 215/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2214 - accuracy: 0.9181 - val_loss: 0.4462 - val_accuracy: 0.8581\n",
            "Epoch 216/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2228 - accuracy: 0.9167 - val_loss: 0.4471 - val_accuracy: 0.8570\n",
            "Epoch 217/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2221 - accuracy: 0.9156 - val_loss: 0.4468 - val_accuracy: 0.8571\n",
            "Epoch 218/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2213 - accuracy: 0.9163 - val_loss: 0.4447 - val_accuracy: 0.8586\n",
            "Epoch 219/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2202 - accuracy: 0.9179 - val_loss: 0.4486 - val_accuracy: 0.8573\n",
            "Epoch 220/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2228 - accuracy: 0.9165 - val_loss: 0.4483 - val_accuracy: 0.8568\n",
            "Epoch 221/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2201 - accuracy: 0.9183 - val_loss: 0.4512 - val_accuracy: 0.8564\n",
            "Epoch 222/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2215 - accuracy: 0.9177 - val_loss: 0.4495 - val_accuracy: 0.8556\n",
            "Epoch 223/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2187 - accuracy: 0.9180 - val_loss: 0.4477 - val_accuracy: 0.8565\n",
            "Epoch 224/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2186 - accuracy: 0.9170 - val_loss: 0.4483 - val_accuracy: 0.8564\n",
            "Epoch 225/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2194 - accuracy: 0.9183 - val_loss: 0.4529 - val_accuracy: 0.8553\n",
            "Epoch 226/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2210 - accuracy: 0.9179 - val_loss: 0.4499 - val_accuracy: 0.8573\n",
            "Epoch 227/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2192 - accuracy: 0.9180 - val_loss: 0.4542 - val_accuracy: 0.8543\n",
            "Epoch 228/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2229 - accuracy: 0.9168 - val_loss: 0.4502 - val_accuracy: 0.8567\n",
            "Epoch 229/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2178 - accuracy: 0.9176 - val_loss: 0.4551 - val_accuracy: 0.8536\n",
            "Epoch 230/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2177 - accuracy: 0.9185 - val_loss: 0.4501 - val_accuracy: 0.8569\n",
            "Epoch 231/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2171 - accuracy: 0.9193 - val_loss: 0.4507 - val_accuracy: 0.8554\n",
            "Epoch 232/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2180 - accuracy: 0.9185 - val_loss: 0.4545 - val_accuracy: 0.8572\n",
            "Epoch 233/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2180 - accuracy: 0.9185 - val_loss: 0.4521 - val_accuracy: 0.8559\n",
            "Epoch 234/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2164 - accuracy: 0.9186 - val_loss: 0.4509 - val_accuracy: 0.8550\n",
            "Epoch 235/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2170 - accuracy: 0.9189 - val_loss: 0.4539 - val_accuracy: 0.8564\n",
            "Epoch 236/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2157 - accuracy: 0.9184 - val_loss: 0.4542 - val_accuracy: 0.8560\n",
            "Epoch 237/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2158 - accuracy: 0.9181 - val_loss: 0.4541 - val_accuracy: 0.8555\n",
            "Epoch 238/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2183 - accuracy: 0.9172 - val_loss: 0.4555 - val_accuracy: 0.8546\n",
            "Epoch 239/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2179 - accuracy: 0.9186 - val_loss: 0.4511 - val_accuracy: 0.8557\n",
            "Epoch 240/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2160 - accuracy: 0.9194 - val_loss: 0.4544 - val_accuracy: 0.8560\n",
            "Epoch 241/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2173 - accuracy: 0.9181 - val_loss: 0.4531 - val_accuracy: 0.8559\n",
            "Epoch 242/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2174 - accuracy: 0.9185 - val_loss: 0.4516 - val_accuracy: 0.8568\n",
            "Epoch 243/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2132 - accuracy: 0.9190 - val_loss: 0.4536 - val_accuracy: 0.8557\n",
            "Epoch 244/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2136 - accuracy: 0.9203 - val_loss: 0.4540 - val_accuracy: 0.8554\n",
            "Epoch 245/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2141 - accuracy: 0.9204 - val_loss: 0.4566 - val_accuracy: 0.8570\n",
            "Epoch 246/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2152 - accuracy: 0.9206 - val_loss: 0.4550 - val_accuracy: 0.8541\n",
            "Epoch 247/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2170 - accuracy: 0.9190 - val_loss: 0.4581 - val_accuracy: 0.8565\n",
            "Epoch 248/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2187 - accuracy: 0.9191 - val_loss: 0.4586 - val_accuracy: 0.8563\n",
            "Epoch 249/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2167 - accuracy: 0.9195 - val_loss: 0.4570 - val_accuracy: 0.8555\n",
            "Epoch 250/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2142 - accuracy: 0.9198 - val_loss: 0.4589 - val_accuracy: 0.8557\n",
            "Epoch 251/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2148 - accuracy: 0.9197 - val_loss: 0.4531 - val_accuracy: 0.8541\n",
            "Epoch 252/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2172 - accuracy: 0.9179 - val_loss: 0.4582 - val_accuracy: 0.8554\n",
            "Epoch 253/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2155 - accuracy: 0.9196 - val_loss: 0.4585 - val_accuracy: 0.8546\n",
            "Epoch 254/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2145 - accuracy: 0.9196 - val_loss: 0.4577 - val_accuracy: 0.8543\n",
            "Epoch 255/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2156 - accuracy: 0.9188 - val_loss: 0.4588 - val_accuracy: 0.8549\n",
            "Epoch 256/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2163 - accuracy: 0.9188 - val_loss: 0.4557 - val_accuracy: 0.8547\n",
            "Epoch 257/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2159 - accuracy: 0.9194 - val_loss: 0.4555 - val_accuracy: 0.8570\n",
            "Epoch 258/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2141 - accuracy: 0.9194 - val_loss: 0.4563 - val_accuracy: 0.8557\n",
            "Epoch 259/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2183 - accuracy: 0.9173 - val_loss: 0.4575 - val_accuracy: 0.8553\n",
            "Epoch 260/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2102 - accuracy: 0.9211 - val_loss: 0.4586 - val_accuracy: 0.8546\n",
            "Epoch 261/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2133 - accuracy: 0.9187 - val_loss: 0.4634 - val_accuracy: 0.8555\n",
            "Epoch 262/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2136 - accuracy: 0.9201 - val_loss: 0.4575 - val_accuracy: 0.8543\n",
            "Epoch 263/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2133 - accuracy: 0.9191 - val_loss: 0.4594 - val_accuracy: 0.8549\n",
            "Epoch 264/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2152 - accuracy: 0.9183 - val_loss: 0.4627 - val_accuracy: 0.8536\n",
            "Epoch 265/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2144 - accuracy: 0.9200 - val_loss: 0.4637 - val_accuracy: 0.8545\n",
            "Epoch 266/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2126 - accuracy: 0.9201 - val_loss: 0.4594 - val_accuracy: 0.8534\n",
            "Epoch 267/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2140 - accuracy: 0.9200 - val_loss: 0.4622 - val_accuracy: 0.8549\n",
            "Epoch 268/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2108 - accuracy: 0.9200 - val_loss: 0.4593 - val_accuracy: 0.8560\n",
            "Epoch 269/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2143 - accuracy: 0.9187 - val_loss: 0.4580 - val_accuracy: 0.8538\n",
            "Epoch 270/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2129 - accuracy: 0.9195 - val_loss: 0.4568 - val_accuracy: 0.8543\n",
            "Epoch 271/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2153 - accuracy: 0.9202 - val_loss: 0.4614 - val_accuracy: 0.8528\n",
            "Epoch 272/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2122 - accuracy: 0.9199 - val_loss: 0.4604 - val_accuracy: 0.8554\n",
            "Epoch 273/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2122 - accuracy: 0.9200 - val_loss: 0.4609 - val_accuracy: 0.8563\n",
            "Epoch 274/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2118 - accuracy: 0.9200 - val_loss: 0.4641 - val_accuracy: 0.8534\n",
            "Epoch 275/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2108 - accuracy: 0.9207 - val_loss: 0.4623 - val_accuracy: 0.8535\n",
            "Epoch 276/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2121 - accuracy: 0.9206 - val_loss: 0.4639 - val_accuracy: 0.8548\n",
            "Epoch 277/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2141 - accuracy: 0.9193 - val_loss: 0.4651 - val_accuracy: 0.8555\n",
            "Epoch 278/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2126 - accuracy: 0.9199 - val_loss: 0.4645 - val_accuracy: 0.8528\n",
            "Epoch 279/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2104 - accuracy: 0.9216 - val_loss: 0.4649 - val_accuracy: 0.8520\n",
            "Epoch 280/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2095 - accuracy: 0.9205 - val_loss: 0.4617 - val_accuracy: 0.8562\n",
            "Epoch 281/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2134 - accuracy: 0.9198 - val_loss: 0.4631 - val_accuracy: 0.8553\n",
            "Epoch 282/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2114 - accuracy: 0.9211 - val_loss: 0.4613 - val_accuracy: 0.8560\n",
            "Epoch 283/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2104 - accuracy: 0.9211 - val_loss: 0.4597 - val_accuracy: 0.8557\n",
            "Epoch 284/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.2096 - accuracy: 0.9214 - val_loss: 0.4659 - val_accuracy: 0.8553\n",
            "Epoch 285/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2092 - accuracy: 0.9212 - val_loss: 0.4644 - val_accuracy: 0.8525\n",
            "Epoch 286/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2130 - accuracy: 0.9209 - val_loss: 0.4638 - val_accuracy: 0.8529\n",
            "Epoch 287/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2097 - accuracy: 0.9203 - val_loss: 0.4644 - val_accuracy: 0.8556\n",
            "Epoch 288/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2102 - accuracy: 0.9209 - val_loss: 0.4651 - val_accuracy: 0.8546\n",
            "Epoch 289/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2117 - accuracy: 0.9203 - val_loss: 0.4626 - val_accuracy: 0.8543\n",
            "Epoch 290/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2113 - accuracy: 0.9213 - val_loss: 0.4611 - val_accuracy: 0.8561\n",
            "Epoch 291/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2111 - accuracy: 0.9205 - val_loss: 0.4640 - val_accuracy: 0.8547\n",
            "Epoch 292/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2110 - accuracy: 0.9204 - val_loss: 0.4660 - val_accuracy: 0.8539\n",
            "Epoch 293/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2113 - accuracy: 0.9204 - val_loss: 0.4648 - val_accuracy: 0.8559\n",
            "Epoch 294/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2087 - accuracy: 0.9217 - val_loss: 0.4634 - val_accuracy: 0.8548\n",
            "Epoch 295/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2092 - accuracy: 0.9208 - val_loss: 0.4620 - val_accuracy: 0.8558\n",
            "Epoch 296/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2070 - accuracy: 0.9223 - val_loss: 0.4678 - val_accuracy: 0.8549\n",
            "Epoch 297/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2101 - accuracy: 0.9216 - val_loss: 0.4663 - val_accuracy: 0.8549\n",
            "Epoch 298/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2097 - accuracy: 0.9202 - val_loss: 0.4678 - val_accuracy: 0.8537\n",
            "Epoch 299/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2077 - accuracy: 0.9222 - val_loss: 0.4711 - val_accuracy: 0.8545\n",
            "Epoch 300/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2074 - accuracy: 0.9224 - val_loss: 0.4680 - val_accuracy: 0.8553\n",
            "Epoch 301/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2097 - accuracy: 0.9213 - val_loss: 0.4679 - val_accuracy: 0.8537\n",
            "Epoch 302/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2069 - accuracy: 0.9230 - val_loss: 0.4666 - val_accuracy: 0.8543\n",
            "Epoch 303/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2073 - accuracy: 0.9223 - val_loss: 0.4685 - val_accuracy: 0.8524\n",
            "Epoch 304/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2075 - accuracy: 0.9223 - val_loss: 0.4673 - val_accuracy: 0.8540\n",
            "Epoch 305/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2078 - accuracy: 0.9226 - val_loss: 0.4712 - val_accuracy: 0.8526\n",
            "Epoch 306/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2065 - accuracy: 0.9229 - val_loss: 0.4685 - val_accuracy: 0.8567\n",
            "Epoch 307/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2091 - accuracy: 0.9203 - val_loss: 0.4668 - val_accuracy: 0.8560\n",
            "Epoch 308/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2062 - accuracy: 0.9222 - val_loss: 0.4697 - val_accuracy: 0.8543\n",
            "Epoch 309/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2081 - accuracy: 0.9214 - val_loss: 0.4689 - val_accuracy: 0.8542\n",
            "Epoch 310/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2073 - accuracy: 0.9216 - val_loss: 0.4686 - val_accuracy: 0.8550\n",
            "Epoch 311/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2054 - accuracy: 0.9235 - val_loss: 0.4686 - val_accuracy: 0.8528\n",
            "Epoch 312/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.2058 - accuracy: 0.9221 - val_loss: 0.4665 - val_accuracy: 0.8535\n",
            "Epoch 313/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2057 - accuracy: 0.9219 - val_loss: 0.4670 - val_accuracy: 0.8575\n",
            "Epoch 314/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2086 - accuracy: 0.9210 - val_loss: 0.4691 - val_accuracy: 0.8560\n",
            "Epoch 315/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2051 - accuracy: 0.9221 - val_loss: 0.4689 - val_accuracy: 0.8539\n",
            "Epoch 316/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2049 - accuracy: 0.9219 - val_loss: 0.4696 - val_accuracy: 0.8523\n",
            "Epoch 317/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2091 - accuracy: 0.9204 - val_loss: 0.4679 - val_accuracy: 0.8536\n",
            "Epoch 318/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2093 - accuracy: 0.9213 - val_loss: 0.4692 - val_accuracy: 0.8556\n",
            "Epoch 319/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2080 - accuracy: 0.9221 - val_loss: 0.4695 - val_accuracy: 0.8540\n",
            "Epoch 320/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2059 - accuracy: 0.9215 - val_loss: 0.4699 - val_accuracy: 0.8542\n",
            "Epoch 321/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2053 - accuracy: 0.9223 - val_loss: 0.4673 - val_accuracy: 0.8535\n",
            "Epoch 322/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2073 - accuracy: 0.9219 - val_loss: 0.4694 - val_accuracy: 0.8567\n",
            "Epoch 323/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2054 - accuracy: 0.9215 - val_loss: 0.4715 - val_accuracy: 0.8543\n",
            "Epoch 324/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2064 - accuracy: 0.9215 - val_loss: 0.4743 - val_accuracy: 0.8532\n",
            "Epoch 325/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2037 - accuracy: 0.9236 - val_loss: 0.4762 - val_accuracy: 0.8540\n",
            "Epoch 326/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2089 - accuracy: 0.9207 - val_loss: 0.4721 - val_accuracy: 0.8543\n",
            "Epoch 327/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2081 - accuracy: 0.9223 - val_loss: 0.4707 - val_accuracy: 0.8549\n",
            "Epoch 328/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2023 - accuracy: 0.9237 - val_loss: 0.4714 - val_accuracy: 0.8556\n",
            "Epoch 329/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2045 - accuracy: 0.9219 - val_loss: 0.4700 - val_accuracy: 0.8533\n",
            "Epoch 330/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2053 - accuracy: 0.9230 - val_loss: 0.4726 - val_accuracy: 0.8529\n",
            "Epoch 331/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2050 - accuracy: 0.9224 - val_loss: 0.4723 - val_accuracy: 0.8528\n",
            "Epoch 332/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2050 - accuracy: 0.9227 - val_loss: 0.4777 - val_accuracy: 0.8542\n",
            "Epoch 333/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2036 - accuracy: 0.9237 - val_loss: 0.4747 - val_accuracy: 0.8548\n",
            "Epoch 334/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2046 - accuracy: 0.9218 - val_loss: 0.4732 - val_accuracy: 0.8544\n",
            "Epoch 335/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2036 - accuracy: 0.9236 - val_loss: 0.4740 - val_accuracy: 0.8537\n",
            "Epoch 336/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2046 - accuracy: 0.9227 - val_loss: 0.4772 - val_accuracy: 0.8527\n",
            "Epoch 337/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2059 - accuracy: 0.9227 - val_loss: 0.4765 - val_accuracy: 0.8531\n",
            "Epoch 338/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2039 - accuracy: 0.9218 - val_loss: 0.4745 - val_accuracy: 0.8542\n",
            "Epoch 339/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2068 - accuracy: 0.9216 - val_loss: 0.4712 - val_accuracy: 0.8536\n",
            "Epoch 340/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2050 - accuracy: 0.9233 - val_loss: 0.4763 - val_accuracy: 0.8527\n",
            "Epoch 341/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2053 - accuracy: 0.9214 - val_loss: 0.4751 - val_accuracy: 0.8545\n",
            "Epoch 342/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2053 - accuracy: 0.9231 - val_loss: 0.4748 - val_accuracy: 0.8526\n",
            "Epoch 343/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.2038 - accuracy: 0.9237 - val_loss: 0.4733 - val_accuracy: 0.8539\n",
            "Epoch 344/1500\n",
            "235/235 [==============================] - 5s 14ms/step - loss: 0.2034 - accuracy: 0.9242 - val_loss: 0.4752 - val_accuracy: 0.8526\n",
            "Epoch 345/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2018 - accuracy: 0.9249 - val_loss: 0.4777 - val_accuracy: 0.8524\n",
            "Epoch 346/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2042 - accuracy: 0.9231 - val_loss: 0.4771 - val_accuracy: 0.8532\n",
            "Epoch 347/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2027 - accuracy: 0.9231 - val_loss: 0.4750 - val_accuracy: 0.8526\n",
            "Epoch 348/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2051 - accuracy: 0.9226 - val_loss: 0.4746 - val_accuracy: 0.8551\n",
            "Epoch 349/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2055 - accuracy: 0.9223 - val_loss: 0.4796 - val_accuracy: 0.8530\n",
            "Epoch 350/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2039 - accuracy: 0.9230 - val_loss: 0.4778 - val_accuracy: 0.8543\n",
            "Epoch 351/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2054 - accuracy: 0.9222 - val_loss: 0.4793 - val_accuracy: 0.8549\n",
            "Epoch 352/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2033 - accuracy: 0.9236 - val_loss: 0.4792 - val_accuracy: 0.8558\n",
            "Epoch 353/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2033 - accuracy: 0.9237 - val_loss: 0.4819 - val_accuracy: 0.8550\n",
            "Epoch 354/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2026 - accuracy: 0.9227 - val_loss: 0.4762 - val_accuracy: 0.8558\n",
            "Epoch 355/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2049 - accuracy: 0.9229 - val_loss: 0.4730 - val_accuracy: 0.8558\n",
            "Epoch 356/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2030 - accuracy: 0.9237 - val_loss: 0.4750 - val_accuracy: 0.8559\n",
            "Epoch 357/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2031 - accuracy: 0.9233 - val_loss: 0.4783 - val_accuracy: 0.8541\n",
            "Epoch 358/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2030 - accuracy: 0.9234 - val_loss: 0.4782 - val_accuracy: 0.8539\n",
            "Epoch 359/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2028 - accuracy: 0.9236 - val_loss: 0.4733 - val_accuracy: 0.8550\n",
            "Epoch 360/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.4783 - val_accuracy: 0.8542\n",
            "Epoch 361/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2062 - accuracy: 0.9219 - val_loss: 0.4740 - val_accuracy: 0.8547\n",
            "Epoch 362/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2002 - accuracy: 0.9242 - val_loss: 0.4740 - val_accuracy: 0.8542\n",
            "Epoch 363/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2022 - accuracy: 0.9242 - val_loss: 0.4796 - val_accuracy: 0.8535\n",
            "Epoch 364/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2043 - accuracy: 0.9232 - val_loss: 0.4745 - val_accuracy: 0.8550\n",
            "Epoch 365/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2047 - accuracy: 0.9231 - val_loss: 0.4761 - val_accuracy: 0.8558\n",
            "Epoch 366/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2016 - accuracy: 0.9233 - val_loss: 0.4775 - val_accuracy: 0.8548\n",
            "Epoch 367/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2038 - accuracy: 0.9225 - val_loss: 0.4771 - val_accuracy: 0.8523\n",
            "Epoch 368/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2039 - accuracy: 0.9233 - val_loss: 0.4767 - val_accuracy: 0.8545\n",
            "Epoch 369/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1999 - accuracy: 0.9244 - val_loss: 0.4758 - val_accuracy: 0.8556\n",
            "Epoch 370/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2030 - accuracy: 0.9235 - val_loss: 0.4761 - val_accuracy: 0.8539\n",
            "Epoch 371/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1982 - accuracy: 0.9256 - val_loss: 0.4772 - val_accuracy: 0.8547\n",
            "Epoch 372/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2000 - accuracy: 0.9244 - val_loss: 0.4774 - val_accuracy: 0.8567\n",
            "Epoch 373/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.4755 - val_accuracy: 0.8561\n",
            "Epoch 374/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2037 - accuracy: 0.9237 - val_loss: 0.4745 - val_accuracy: 0.8545\n",
            "Epoch 375/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2009 - accuracy: 0.9236 - val_loss: 0.4772 - val_accuracy: 0.8539\n",
            "Epoch 376/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2008 - accuracy: 0.9234 - val_loss: 0.4784 - val_accuracy: 0.8544\n",
            "Epoch 377/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.2010 - accuracy: 0.9240 - val_loss: 0.4765 - val_accuracy: 0.8542\n",
            "Epoch 378/1500\n",
            "235/235 [==============================] - 5s 14ms/step - loss: 0.1994 - accuracy: 0.9251 - val_loss: 0.4784 - val_accuracy: 0.8544\n",
            "Epoch 379/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2063 - accuracy: 0.9226 - val_loss: 0.4732 - val_accuracy: 0.8548\n",
            "Epoch 380/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2009 - accuracy: 0.9231 - val_loss: 0.4772 - val_accuracy: 0.8550\n",
            "Epoch 381/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.4761 - val_accuracy: 0.8558\n",
            "Epoch 382/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2030 - accuracy: 0.9223 - val_loss: 0.4732 - val_accuracy: 0.8558\n",
            "Epoch 383/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1982 - accuracy: 0.9248 - val_loss: 0.4790 - val_accuracy: 0.8560\n",
            "Epoch 384/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1988 - accuracy: 0.9245 - val_loss: 0.4745 - val_accuracy: 0.8566\n",
            "Epoch 385/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1988 - accuracy: 0.9256 - val_loss: 0.4803 - val_accuracy: 0.8528\n",
            "Epoch 386/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1999 - accuracy: 0.9238 - val_loss: 0.4804 - val_accuracy: 0.8549\n",
            "Epoch 387/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2008 - accuracy: 0.9232 - val_loss: 0.4755 - val_accuracy: 0.8553\n",
            "Epoch 388/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1987 - accuracy: 0.9244 - val_loss: 0.4793 - val_accuracy: 0.8567\n",
            "Epoch 389/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1991 - accuracy: 0.9255 - val_loss: 0.4807 - val_accuracy: 0.8548\n",
            "Epoch 390/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1980 - accuracy: 0.9248 - val_loss: 0.4783 - val_accuracy: 0.8584\n",
            "Epoch 391/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1994 - accuracy: 0.9254 - val_loss: 0.4783 - val_accuracy: 0.8541\n",
            "Epoch 392/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1996 - accuracy: 0.9255 - val_loss: 0.4780 - val_accuracy: 0.8584\n",
            "Epoch 393/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2008 - accuracy: 0.9239 - val_loss: 0.4804 - val_accuracy: 0.8558\n",
            "Epoch 394/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2002 - accuracy: 0.9250 - val_loss: 0.4773 - val_accuracy: 0.8582\n",
            "Epoch 395/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1981 - accuracy: 0.9247 - val_loss: 0.4813 - val_accuracy: 0.8525\n",
            "Epoch 396/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1971 - accuracy: 0.9260 - val_loss: 0.4798 - val_accuracy: 0.8546\n",
            "Epoch 397/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1991 - accuracy: 0.9255 - val_loss: 0.4823 - val_accuracy: 0.8552\n",
            "Epoch 398/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1974 - accuracy: 0.9254 - val_loss: 0.4820 - val_accuracy: 0.8539\n",
            "Epoch 399/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2012 - accuracy: 0.9252 - val_loss: 0.4809 - val_accuracy: 0.8546\n",
            "Epoch 400/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1988 - accuracy: 0.9257 - val_loss: 0.4816 - val_accuracy: 0.8548\n",
            "Epoch 401/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1974 - accuracy: 0.9258 - val_loss: 0.4785 - val_accuracy: 0.8565\n",
            "Epoch 402/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1970 - accuracy: 0.9258 - val_loss: 0.4811 - val_accuracy: 0.8572\n",
            "Epoch 403/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1983 - accuracy: 0.9246 - val_loss: 0.4827 - val_accuracy: 0.8545\n",
            "Epoch 404/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1994 - accuracy: 0.9254 - val_loss: 0.4879 - val_accuracy: 0.8529\n",
            "Epoch 405/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1989 - accuracy: 0.9246 - val_loss: 0.4842 - val_accuracy: 0.8540\n",
            "Epoch 406/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1992 - accuracy: 0.9235 - val_loss: 0.4826 - val_accuracy: 0.8548\n",
            "Epoch 407/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1987 - accuracy: 0.9241 - val_loss: 0.4854 - val_accuracy: 0.8562\n",
            "Epoch 408/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1982 - accuracy: 0.9247 - val_loss: 0.4842 - val_accuracy: 0.8561\n",
            "Epoch 409/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1976 - accuracy: 0.9253 - val_loss: 0.4844 - val_accuracy: 0.8540\n",
            "Epoch 410/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1999 - accuracy: 0.9241 - val_loss: 0.4830 - val_accuracy: 0.8545\n",
            "Epoch 411/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1985 - accuracy: 0.9243 - val_loss: 0.4811 - val_accuracy: 0.8520\n",
            "Epoch 412/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1977 - accuracy: 0.9243 - val_loss: 0.4851 - val_accuracy: 0.8543\n",
            "Epoch 413/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1985 - accuracy: 0.9243 - val_loss: 0.4837 - val_accuracy: 0.8524\n",
            "Epoch 414/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1975 - accuracy: 0.9254 - val_loss: 0.4804 - val_accuracy: 0.8531\n",
            "Epoch 415/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.1963 - accuracy: 0.9261 - val_loss: 0.4801 - val_accuracy: 0.8538\n",
            "Epoch 416/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1984 - accuracy: 0.9255 - val_loss: 0.4818 - val_accuracy: 0.8545\n",
            "Epoch 417/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1987 - accuracy: 0.9244 - val_loss: 0.4839 - val_accuracy: 0.8547\n",
            "Epoch 418/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1989 - accuracy: 0.9242 - val_loss: 0.4821 - val_accuracy: 0.8569\n",
            "Epoch 419/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1983 - accuracy: 0.9251 - val_loss: 0.4817 - val_accuracy: 0.8563\n",
            "Epoch 420/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2007 - accuracy: 0.9257 - val_loss: 0.4783 - val_accuracy: 0.8554\n",
            "Epoch 421/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1952 - accuracy: 0.9269 - val_loss: 0.4827 - val_accuracy: 0.8555\n",
            "Epoch 422/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1976 - accuracy: 0.9260 - val_loss: 0.4844 - val_accuracy: 0.8542\n",
            "Epoch 423/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1958 - accuracy: 0.9256 - val_loss: 0.4869 - val_accuracy: 0.8560\n",
            "Epoch 424/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1961 - accuracy: 0.9253 - val_loss: 0.4865 - val_accuracy: 0.8562\n",
            "Epoch 425/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1948 - accuracy: 0.9268 - val_loss: 0.4841 - val_accuracy: 0.8559\n",
            "Epoch 426/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1963 - accuracy: 0.9258 - val_loss: 0.4831 - val_accuracy: 0.8534\n",
            "Epoch 427/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2005 - accuracy: 0.9243 - val_loss: 0.4814 - val_accuracy: 0.8571\n",
            "Epoch 428/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1961 - accuracy: 0.9260 - val_loss: 0.4862 - val_accuracy: 0.8530\n",
            "Epoch 429/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1976 - accuracy: 0.9255 - val_loss: 0.4889 - val_accuracy: 0.8549\n",
            "Epoch 430/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1998 - accuracy: 0.9248 - val_loss: 0.4858 - val_accuracy: 0.8553\n",
            "Epoch 431/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1949 - accuracy: 0.9268 - val_loss: 0.4814 - val_accuracy: 0.8585\n",
            "Epoch 432/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1967 - accuracy: 0.9257 - val_loss: 0.4837 - val_accuracy: 0.8539\n",
            "Epoch 433/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1983 - accuracy: 0.9244 - val_loss: 0.4835 - val_accuracy: 0.8551\n",
            "Epoch 434/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1963 - accuracy: 0.9245 - val_loss: 0.4821 - val_accuracy: 0.8554\n",
            "Epoch 435/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1968 - accuracy: 0.9259 - val_loss: 0.4806 - val_accuracy: 0.8555\n",
            "Epoch 436/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1970 - accuracy: 0.9248 - val_loss: 0.4818 - val_accuracy: 0.8554\n",
            "Epoch 437/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1976 - accuracy: 0.9250 - val_loss: 0.4849 - val_accuracy: 0.8555\n",
            "Epoch 438/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1922 - accuracy: 0.9271 - val_loss: 0.4838 - val_accuracy: 0.8571\n",
            "Epoch 439/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1953 - accuracy: 0.9261 - val_loss: 0.4858 - val_accuracy: 0.8553\n",
            "Epoch 440/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1930 - accuracy: 0.9273 - val_loss: 0.4869 - val_accuracy: 0.8545\n",
            "Epoch 441/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1985 - accuracy: 0.9234 - val_loss: 0.4822 - val_accuracy: 0.8549\n",
            "Epoch 442/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1954 - accuracy: 0.9247 - val_loss: 0.4830 - val_accuracy: 0.8565\n",
            "Epoch 443/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1958 - accuracy: 0.9252 - val_loss: 0.4813 - val_accuracy: 0.8548\n",
            "Epoch 444/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1944 - accuracy: 0.9270 - val_loss: 0.4856 - val_accuracy: 0.8565\n",
            "Epoch 445/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1948 - accuracy: 0.9262 - val_loss: 0.4834 - val_accuracy: 0.8548\n",
            "Epoch 446/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1953 - accuracy: 0.9250 - val_loss: 0.4788 - val_accuracy: 0.8570\n",
            "Epoch 447/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1936 - accuracy: 0.9268 - val_loss: 0.4786 - val_accuracy: 0.8576\n",
            "Epoch 448/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1954 - accuracy: 0.9258 - val_loss: 0.4810 - val_accuracy: 0.8549\n",
            "Epoch 449/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1976 - accuracy: 0.9254 - val_loss: 0.4764 - val_accuracy: 0.8530\n",
            "Epoch 450/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1934 - accuracy: 0.9262 - val_loss: 0.4793 - val_accuracy: 0.8560\n",
            "Epoch 451/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1970 - accuracy: 0.9255 - val_loss: 0.4829 - val_accuracy: 0.8565\n",
            "Epoch 452/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1940 - accuracy: 0.9267 - val_loss: 0.4860 - val_accuracy: 0.8542\n",
            "Epoch 453/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1964 - accuracy: 0.9260 - val_loss: 0.4858 - val_accuracy: 0.8547\n",
            "Epoch 454/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1930 - accuracy: 0.9270 - val_loss: 0.4823 - val_accuracy: 0.8570\n",
            "Epoch 455/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.1958 - accuracy: 0.9266 - val_loss: 0.4842 - val_accuracy: 0.8563\n",
            "Epoch 456/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1968 - accuracy: 0.9256 - val_loss: 0.4856 - val_accuracy: 0.8540\n",
            "Epoch 457/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1930 - accuracy: 0.9280 - val_loss: 0.4840 - val_accuracy: 0.8550\n",
            "Epoch 458/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1937 - accuracy: 0.9271 - val_loss: 0.4898 - val_accuracy: 0.8531\n",
            "Epoch 459/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1931 - accuracy: 0.9271 - val_loss: 0.4832 - val_accuracy: 0.8538\n",
            "Epoch 460/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1957 - accuracy: 0.9267 - val_loss: 0.4829 - val_accuracy: 0.8570\n",
            "Epoch 461/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1940 - accuracy: 0.9265 - val_loss: 0.4830 - val_accuracy: 0.8568\n",
            "Epoch 462/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1944 - accuracy: 0.9268 - val_loss: 0.4846 - val_accuracy: 0.8557\n",
            "Epoch 463/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1927 - accuracy: 0.9270 - val_loss: 0.4825 - val_accuracy: 0.8564\n",
            "Epoch 464/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1933 - accuracy: 0.9266 - val_loss: 0.4812 - val_accuracy: 0.8570\n",
            "Epoch 465/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1924 - accuracy: 0.9269 - val_loss: 0.4827 - val_accuracy: 0.8574\n",
            "Epoch 466/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1923 - accuracy: 0.9262 - val_loss: 0.4833 - val_accuracy: 0.8591\n",
            "Epoch 467/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1926 - accuracy: 0.9273 - val_loss: 0.4851 - val_accuracy: 0.8545\n",
            "Epoch 468/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1936 - accuracy: 0.9265 - val_loss: 0.4833 - val_accuracy: 0.8561\n",
            "Epoch 469/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1920 - accuracy: 0.9272 - val_loss: 0.4841 - val_accuracy: 0.8572\n",
            "Epoch 470/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1943 - accuracy: 0.9268 - val_loss: 0.4838 - val_accuracy: 0.8561\n",
            "Epoch 471/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1935 - accuracy: 0.9272 - val_loss: 0.4838 - val_accuracy: 0.8580\n",
            "Epoch 472/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1913 - accuracy: 0.9273 - val_loss: 0.4874 - val_accuracy: 0.8564\n",
            "Epoch 473/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1926 - accuracy: 0.9263 - val_loss: 0.4876 - val_accuracy: 0.8559\n",
            "Epoch 474/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1922 - accuracy: 0.9273 - val_loss: 0.4852 - val_accuracy: 0.8541\n",
            "Epoch 475/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9280 - val_loss: 0.4870 - val_accuracy: 0.8551\n",
            "Epoch 476/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1951 - accuracy: 0.9271 - val_loss: 0.4849 - val_accuracy: 0.8553\n",
            "Epoch 477/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1917 - accuracy: 0.9276 - val_loss: 0.4874 - val_accuracy: 0.8547\n",
            "Epoch 478/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1926 - accuracy: 0.9274 - val_loss: 0.4812 - val_accuracy: 0.8569\n",
            "Epoch 479/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1926 - accuracy: 0.9275 - val_loss: 0.4837 - val_accuracy: 0.8557\n",
            "Epoch 480/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1940 - accuracy: 0.9262 - val_loss: 0.4894 - val_accuracy: 0.8556\n",
            "Epoch 481/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1934 - accuracy: 0.9272 - val_loss: 0.4901 - val_accuracy: 0.8551\n",
            "Epoch 482/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1943 - accuracy: 0.9256 - val_loss: 0.4847 - val_accuracy: 0.8574\n",
            "Epoch 483/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1951 - accuracy: 0.9262 - val_loss: 0.4852 - val_accuracy: 0.8583\n",
            "Epoch 484/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1912 - accuracy: 0.9269 - val_loss: 0.4862 - val_accuracy: 0.8559\n",
            "Epoch 485/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1933 - accuracy: 0.9261 - val_loss: 0.4889 - val_accuracy: 0.8567\n",
            "Epoch 486/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1900 - accuracy: 0.9281 - val_loss: 0.4896 - val_accuracy: 0.8583\n",
            "Epoch 487/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1925 - accuracy: 0.9269 - val_loss: 0.4874 - val_accuracy: 0.8578\n",
            "Epoch 488/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1910 - accuracy: 0.9270 - val_loss: 0.4859 - val_accuracy: 0.8592\n",
            "Epoch 489/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1921 - accuracy: 0.9265 - val_loss: 0.4853 - val_accuracy: 0.8561\n",
            "Epoch 490/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1902 - accuracy: 0.9279 - val_loss: 0.4886 - val_accuracy: 0.8562\n",
            "Epoch 491/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1942 - accuracy: 0.9265 - val_loss: 0.4898 - val_accuracy: 0.8580\n",
            "Epoch 492/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1925 - accuracy: 0.9271 - val_loss: 0.4847 - val_accuracy: 0.8577\n",
            "Epoch 493/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1894 - accuracy: 0.9295 - val_loss: 0.4877 - val_accuracy: 0.8575\n",
            "Epoch 494/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1922 - accuracy: 0.9269 - val_loss: 0.4873 - val_accuracy: 0.8573\n",
            "Epoch 495/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9270 - val_loss: 0.4876 - val_accuracy: 0.8555\n",
            "Epoch 496/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9266 - val_loss: 0.4913 - val_accuracy: 0.8557\n",
            "Epoch 497/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1896 - accuracy: 0.9278 - val_loss: 0.4888 - val_accuracy: 0.8558\n",
            "Epoch 498/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1934 - accuracy: 0.9261 - val_loss: 0.4907 - val_accuracy: 0.8561\n",
            "Epoch 499/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1895 - accuracy: 0.9284 - val_loss: 0.4840 - val_accuracy: 0.8576\n",
            "Epoch 500/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.1916 - accuracy: 0.9270 - val_loss: 0.4895 - val_accuracy: 0.8579\n",
            "Epoch 501/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1917 - accuracy: 0.9276 - val_loss: 0.4849 - val_accuracy: 0.8567\n",
            "Epoch 502/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1893 - accuracy: 0.9277 - val_loss: 0.4881 - val_accuracy: 0.8585\n",
            "Epoch 503/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1911 - accuracy: 0.9275 - val_loss: 0.4909 - val_accuracy: 0.8558\n",
            "Epoch 504/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1899 - accuracy: 0.9272 - val_loss: 0.4909 - val_accuracy: 0.8559\n",
            "Epoch 505/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1894 - accuracy: 0.9285 - val_loss: 0.4918 - val_accuracy: 0.8581\n",
            "Epoch 506/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1916 - accuracy: 0.9274 - val_loss: 0.4925 - val_accuracy: 0.8577\n",
            "Epoch 507/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1916 - accuracy: 0.9262 - val_loss: 0.4913 - val_accuracy: 0.8575\n",
            "Epoch 508/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1896 - accuracy: 0.9278 - val_loss: 0.4907 - val_accuracy: 0.8572\n",
            "Epoch 509/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1906 - accuracy: 0.9278 - val_loss: 0.4888 - val_accuracy: 0.8560\n",
            "Epoch 510/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1877 - accuracy: 0.9291 - val_loss: 0.4901 - val_accuracy: 0.8553\n",
            "Epoch 511/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1937 - accuracy: 0.9265 - val_loss: 0.4970 - val_accuracy: 0.8541\n",
            "Epoch 512/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1901 - accuracy: 0.9281 - val_loss: 0.4880 - val_accuracy: 0.8554\n",
            "Epoch 513/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1875 - accuracy: 0.9288 - val_loss: 0.4913 - val_accuracy: 0.8555\n",
            "Epoch 514/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1919 - accuracy: 0.9269 - val_loss: 0.4875 - val_accuracy: 0.8547\n",
            "Epoch 515/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1909 - accuracy: 0.9270 - val_loss: 0.4903 - val_accuracy: 0.8548\n",
            "Epoch 516/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1893 - accuracy: 0.9271 - val_loss: 0.4901 - val_accuracy: 0.8544\n",
            "Epoch 517/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1916 - accuracy: 0.9267 - val_loss: 0.4920 - val_accuracy: 0.8559\n",
            "Epoch 518/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1891 - accuracy: 0.9283 - val_loss: 0.4888 - val_accuracy: 0.8565\n",
            "Epoch 519/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1872 - accuracy: 0.9298 - val_loss: 0.4910 - val_accuracy: 0.8539\n",
            "Epoch 520/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1915 - accuracy: 0.9271 - val_loss: 0.4893 - val_accuracy: 0.8550\n",
            "Epoch 521/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9263 - val_loss: 0.4930 - val_accuracy: 0.8532\n",
            "Epoch 522/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1913 - accuracy: 0.9276 - val_loss: 0.4910 - val_accuracy: 0.8577\n",
            "Epoch 523/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1921 - accuracy: 0.9281 - val_loss: 0.4934 - val_accuracy: 0.8553\n",
            "Epoch 524/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1902 - accuracy: 0.9270 - val_loss: 0.4867 - val_accuracy: 0.8565\n",
            "Epoch 525/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1894 - accuracy: 0.9281 - val_loss: 0.4877 - val_accuracy: 0.8557\n",
            "Epoch 526/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1913 - accuracy: 0.9270 - val_loss: 0.4961 - val_accuracy: 0.8538\n",
            "Epoch 527/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1896 - accuracy: 0.9266 - val_loss: 0.4901 - val_accuracy: 0.8552\n",
            "Epoch 528/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1884 - accuracy: 0.9286 - val_loss: 0.4926 - val_accuracy: 0.8545\n",
            "Epoch 529/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1904 - accuracy: 0.9270 - val_loss: 0.4928 - val_accuracy: 0.8551\n",
            "Epoch 530/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1910 - accuracy: 0.9274 - val_loss: 0.4902 - val_accuracy: 0.8529\n",
            "Epoch 531/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1922 - accuracy: 0.9274 - val_loss: 0.4932 - val_accuracy: 0.8543\n",
            "Epoch 532/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1874 - accuracy: 0.9298 - val_loss: 0.4911 - val_accuracy: 0.8547\n",
            "Epoch 533/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1901 - accuracy: 0.9275 - val_loss: 0.4928 - val_accuracy: 0.8550\n",
            "Epoch 534/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1865 - accuracy: 0.9301 - val_loss: 0.4929 - val_accuracy: 0.8572\n",
            "Epoch 535/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1883 - accuracy: 0.9281 - val_loss: 0.4949 - val_accuracy: 0.8545\n",
            "Epoch 536/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1883 - accuracy: 0.9285 - val_loss: 0.4926 - val_accuracy: 0.8580\n",
            "Epoch 537/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1914 - accuracy: 0.9274 - val_loss: 0.4929 - val_accuracy: 0.8551\n",
            "Epoch 538/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1889 - accuracy: 0.9281 - val_loss: 0.4928 - val_accuracy: 0.8542\n",
            "Epoch 539/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1885 - accuracy: 0.9284 - val_loss: 0.4962 - val_accuracy: 0.8529\n",
            "Epoch 540/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1899 - accuracy: 0.9285 - val_loss: 0.4953 - val_accuracy: 0.8549\n",
            "Epoch 541/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1891 - accuracy: 0.9284 - val_loss: 0.4928 - val_accuracy: 0.8529\n",
            "Epoch 542/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1867 - accuracy: 0.9288 - val_loss: 0.4943 - val_accuracy: 0.8571\n",
            "Epoch 543/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1890 - accuracy: 0.9281 - val_loss: 0.4977 - val_accuracy: 0.8549\n",
            "Epoch 544/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1900 - accuracy: 0.9278 - val_loss: 0.4966 - val_accuracy: 0.8538\n",
            "Epoch 545/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1886 - accuracy: 0.9289 - val_loss: 0.4934 - val_accuracy: 0.8550\n",
            "Epoch 546/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1886 - accuracy: 0.9279 - val_loss: 0.4921 - val_accuracy: 0.8550\n",
            "Epoch 547/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9266 - val_loss: 0.4913 - val_accuracy: 0.8547\n",
            "Epoch 548/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1867 - accuracy: 0.9291 - val_loss: 0.4917 - val_accuracy: 0.8532\n",
            "Epoch 549/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1885 - accuracy: 0.9280 - val_loss: 0.4938 - val_accuracy: 0.8554\n",
            "Epoch 550/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.1898 - accuracy: 0.9278 - val_loss: 0.4996 - val_accuracy: 0.8534\n",
            "Epoch 551/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.1877 - accuracy: 0.9291 - val_loss: 0.4923 - val_accuracy: 0.8566\n",
            "Epoch 552/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1875 - accuracy: 0.9280 - val_loss: 0.4939 - val_accuracy: 0.8542\n",
            "Epoch 553/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1900 - accuracy: 0.9278 - val_loss: 0.4956 - val_accuracy: 0.8526\n",
            "Epoch 554/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1885 - accuracy: 0.9293 - val_loss: 0.4990 - val_accuracy: 0.8556\n",
            "Epoch 555/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1892 - accuracy: 0.9272 - val_loss: 0.4946 - val_accuracy: 0.8534\n",
            "Epoch 556/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1884 - accuracy: 0.9278 - val_loss: 0.4921 - val_accuracy: 0.8537\n",
            "Epoch 557/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1899 - accuracy: 0.9277 - val_loss: 0.4976 - val_accuracy: 0.8508\n",
            "Epoch 558/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1867 - accuracy: 0.9286 - val_loss: 0.4957 - val_accuracy: 0.8558\n",
            "Epoch 559/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1866 - accuracy: 0.9288 - val_loss: 0.4925 - val_accuracy: 0.8543\n",
            "Epoch 560/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1877 - accuracy: 0.9278 - val_loss: 0.4997 - val_accuracy: 0.8526\n",
            "Epoch 561/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1867 - accuracy: 0.9290 - val_loss: 0.4948 - val_accuracy: 0.8541\n",
            "Epoch 562/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1878 - accuracy: 0.9282 - val_loss: 0.4979 - val_accuracy: 0.8531\n",
            "Epoch 563/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1887 - accuracy: 0.9292 - val_loss: 0.4971 - val_accuracy: 0.8556\n",
            "Epoch 564/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1884 - accuracy: 0.9288 - val_loss: 0.4958 - val_accuracy: 0.8570\n",
            "Epoch 565/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1867 - accuracy: 0.9295 - val_loss: 0.4961 - val_accuracy: 0.8558\n",
            "Epoch 566/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1851 - accuracy: 0.9295 - val_loss: 0.4943 - val_accuracy: 0.8551\n",
            "Epoch 567/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1866 - accuracy: 0.9293 - val_loss: 0.4948 - val_accuracy: 0.8580\n",
            "Epoch 568/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1870 - accuracy: 0.9291 - val_loss: 0.4974 - val_accuracy: 0.8539\n",
            "Epoch 569/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1888 - accuracy: 0.9275 - val_loss: 0.4986 - val_accuracy: 0.8526\n",
            "Epoch 570/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1882 - accuracy: 0.9287 - val_loss: 0.4995 - val_accuracy: 0.8545\n",
            "Epoch 571/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1879 - accuracy: 0.9288 - val_loss: 0.4944 - val_accuracy: 0.8553\n",
            "Epoch 572/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1870 - accuracy: 0.9283 - val_loss: 0.4942 - val_accuracy: 0.8573\n",
            "Epoch 573/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1869 - accuracy: 0.9293 - val_loss: 0.5010 - val_accuracy: 0.8554\n",
            "Epoch 574/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1865 - accuracy: 0.9283 - val_loss: 0.4954 - val_accuracy: 0.8556\n",
            "Epoch 575/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1861 - accuracy: 0.9290 - val_loss: 0.4939 - val_accuracy: 0.8566\n",
            "Epoch 576/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1885 - accuracy: 0.9286 - val_loss: 0.4972 - val_accuracy: 0.8560\n",
            "Epoch 577/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1886 - accuracy: 0.9270 - val_loss: 0.4956 - val_accuracy: 0.8563\n",
            "Epoch 578/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1873 - accuracy: 0.9281 - val_loss: 0.4949 - val_accuracy: 0.8572\n",
            "Epoch 579/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1862 - accuracy: 0.9305 - val_loss: 0.4984 - val_accuracy: 0.8537\n",
            "Epoch 580/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1887 - accuracy: 0.9285 - val_loss: 0.5017 - val_accuracy: 0.8554\n",
            "Epoch 581/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1873 - accuracy: 0.9284 - val_loss: 0.4943 - val_accuracy: 0.8544\n",
            "Epoch 582/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1859 - accuracy: 0.9290 - val_loss: 0.4956 - val_accuracy: 0.8584\n",
            "Epoch 583/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1889 - accuracy: 0.9280 - val_loss: 0.4955 - val_accuracy: 0.8532\n",
            "Epoch 584/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1868 - accuracy: 0.9290 - val_loss: 0.4972 - val_accuracy: 0.8535\n",
            "Epoch 585/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1845 - accuracy: 0.9302 - val_loss: 0.4991 - val_accuracy: 0.8552\n",
            "Epoch 586/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1889 - accuracy: 0.9278 - val_loss: 0.4976 - val_accuracy: 0.8552\n",
            "Epoch 587/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1848 - accuracy: 0.9293 - val_loss: 0.4989 - val_accuracy: 0.8567\n",
            "Epoch 588/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1863 - accuracy: 0.9300 - val_loss: 0.4990 - val_accuracy: 0.8579\n",
            "Epoch 589/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1874 - accuracy: 0.9295 - val_loss: 0.4976 - val_accuracy: 0.8545\n",
            "Epoch 590/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1881 - accuracy: 0.9281 - val_loss: 0.4962 - val_accuracy: 0.8536\n",
            "Epoch 591/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1854 - accuracy: 0.9300 - val_loss: 0.5001 - val_accuracy: 0.8552\n",
            "Epoch 592/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1873 - accuracy: 0.9285 - val_loss: 0.4977 - val_accuracy: 0.8538\n",
            "Epoch 593/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1886 - accuracy: 0.9270 - val_loss: 0.4969 - val_accuracy: 0.8564\n",
            "Epoch 594/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1856 - accuracy: 0.9304 - val_loss: 0.5018 - val_accuracy: 0.8552\n",
            "Epoch 595/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1866 - accuracy: 0.9294 - val_loss: 0.4976 - val_accuracy: 0.8548\n",
            "Epoch 596/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1845 - accuracy: 0.9298 - val_loss: 0.5037 - val_accuracy: 0.8516\n",
            "Epoch 597/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1858 - accuracy: 0.9287 - val_loss: 0.5017 - val_accuracy: 0.8544\n",
            "Epoch 598/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1856 - accuracy: 0.9294 - val_loss: 0.5001 - val_accuracy: 0.8555\n",
            "Epoch 599/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1828 - accuracy: 0.9306 - val_loss: 0.5014 - val_accuracy: 0.8508\n",
            "Epoch 600/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1866 - accuracy: 0.9284 - val_loss: 0.4998 - val_accuracy: 0.8566\n",
            "Epoch 601/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1860 - accuracy: 0.9286 - val_loss: 0.4984 - val_accuracy: 0.8560\n",
            "Epoch 602/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1897 - accuracy: 0.9286 - val_loss: 0.5002 - val_accuracy: 0.8549\n",
            "Epoch 603/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1868 - accuracy: 0.9296 - val_loss: 0.4991 - val_accuracy: 0.8530\n",
            "Epoch 604/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1853 - accuracy: 0.9299 - val_loss: 0.5013 - val_accuracy: 0.8544\n",
            "Epoch 605/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.1870 - accuracy: 0.9282 - val_loss: 0.5009 - val_accuracy: 0.8519\n",
            "Epoch 606/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1859 - accuracy: 0.9287 - val_loss: 0.4982 - val_accuracy: 0.8559\n",
            "Epoch 607/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1833 - accuracy: 0.9299 - val_loss: 0.5004 - val_accuracy: 0.8547\n",
            "Epoch 608/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1845 - accuracy: 0.9296 - val_loss: 0.4978 - val_accuracy: 0.8548\n",
            "Epoch 609/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1843 - accuracy: 0.9295 - val_loss: 0.4990 - val_accuracy: 0.8536\n",
            "Epoch 610/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1838 - accuracy: 0.9306 - val_loss: 0.5034 - val_accuracy: 0.8533\n",
            "Epoch 611/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1865 - accuracy: 0.9295 - val_loss: 0.5020 - val_accuracy: 0.8533\n",
            "Epoch 612/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1857 - accuracy: 0.9288 - val_loss: 0.4998 - val_accuracy: 0.8529\n",
            "Epoch 613/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1868 - accuracy: 0.9284 - val_loss: 0.5013 - val_accuracy: 0.8523\n",
            "Epoch 614/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1836 - accuracy: 0.9301 - val_loss: 0.4989 - val_accuracy: 0.8580\n",
            "Epoch 615/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9292 - val_loss: 0.5010 - val_accuracy: 0.8562\n",
            "Epoch 616/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1827 - accuracy: 0.9300 - val_loss: 0.5021 - val_accuracy: 0.8533\n",
            "Epoch 617/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1842 - accuracy: 0.9298 - val_loss: 0.5018 - val_accuracy: 0.8547\n",
            "Epoch 618/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1863 - accuracy: 0.9287 - val_loss: 0.4992 - val_accuracy: 0.8543\n",
            "Epoch 619/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1851 - accuracy: 0.9291 - val_loss: 0.5018 - val_accuracy: 0.8555\n",
            "Epoch 620/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1879 - accuracy: 0.9291 - val_loss: 0.5002 - val_accuracy: 0.8532\n",
            "Epoch 621/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1837 - accuracy: 0.9305 - val_loss: 0.5019 - val_accuracy: 0.8558\n",
            "Epoch 622/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1858 - accuracy: 0.9290 - val_loss: 0.5016 - val_accuracy: 0.8563\n",
            "Epoch 623/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1842 - accuracy: 0.9297 - val_loss: 0.5036 - val_accuracy: 0.8537\n",
            "Epoch 624/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1855 - accuracy: 0.9294 - val_loss: 0.5020 - val_accuracy: 0.8547\n",
            "Epoch 625/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1819 - accuracy: 0.9305 - val_loss: 0.5029 - val_accuracy: 0.8531\n",
            "Epoch 626/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1847 - accuracy: 0.9296 - val_loss: 0.5074 - val_accuracy: 0.8534\n",
            "Epoch 627/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.5013 - val_accuracy: 0.8545\n",
            "Epoch 628/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1851 - accuracy: 0.9302 - val_loss: 0.5042 - val_accuracy: 0.8531\n",
            "Epoch 629/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1859 - accuracy: 0.9284 - val_loss: 0.5004 - val_accuracy: 0.8519\n",
            "Epoch 630/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1868 - accuracy: 0.9288 - val_loss: 0.5009 - val_accuracy: 0.8521\n",
            "Epoch 631/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1862 - accuracy: 0.9284 - val_loss: 0.5001 - val_accuracy: 0.8547\n",
            "Epoch 632/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1850 - accuracy: 0.9293 - val_loss: 0.5019 - val_accuracy: 0.8516\n",
            "Epoch 633/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1840 - accuracy: 0.9290 - val_loss: 0.5015 - val_accuracy: 0.8542\n",
            "Epoch 634/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1835 - accuracy: 0.9305 - val_loss: 0.5001 - val_accuracy: 0.8535\n",
            "Epoch 635/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1841 - accuracy: 0.9302 - val_loss: 0.5015 - val_accuracy: 0.8550\n",
            "Epoch 636/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1844 - accuracy: 0.9307 - val_loss: 0.5016 - val_accuracy: 0.8538\n",
            "Epoch 637/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1826 - accuracy: 0.9299 - val_loss: 0.5007 - val_accuracy: 0.8565\n",
            "Epoch 638/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1811 - accuracy: 0.9305 - val_loss: 0.5021 - val_accuracy: 0.8545\n",
            "Epoch 639/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1860 - accuracy: 0.9295 - val_loss: 0.5012 - val_accuracy: 0.8569\n",
            "Epoch 640/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1820 - accuracy: 0.9307 - val_loss: 0.5044 - val_accuracy: 0.8535\n",
            "Epoch 641/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1838 - accuracy: 0.9305 - val_loss: 0.5038 - val_accuracy: 0.8550\n",
            "Epoch 642/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1840 - accuracy: 0.9295 - val_loss: 0.5050 - val_accuracy: 0.8523\n",
            "Epoch 643/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1857 - accuracy: 0.9287 - val_loss: 0.5021 - val_accuracy: 0.8567\n",
            "Epoch 644/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1821 - accuracy: 0.9308 - val_loss: 0.4999 - val_accuracy: 0.8545\n",
            "Epoch 645/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1859 - accuracy: 0.9295 - val_loss: 0.5000 - val_accuracy: 0.8576\n",
            "Epoch 646/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1837 - accuracy: 0.9304 - val_loss: 0.5013 - val_accuracy: 0.8547\n",
            "Epoch 647/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1824 - accuracy: 0.9296 - val_loss: 0.5049 - val_accuracy: 0.8519\n",
            "Epoch 648/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9304 - val_loss: 0.5032 - val_accuracy: 0.8542\n",
            "Epoch 649/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1851 - accuracy: 0.9303 - val_loss: 0.5096 - val_accuracy: 0.8517\n",
            "Epoch 650/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1819 - accuracy: 0.9297 - val_loss: 0.5078 - val_accuracy: 0.8554\n",
            "Epoch 651/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1850 - accuracy: 0.9292 - val_loss: 0.5065 - val_accuracy: 0.8532\n",
            "Epoch 652/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1835 - accuracy: 0.9308 - val_loss: 0.5050 - val_accuracy: 0.8513\n",
            "Epoch 653/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9301 - val_loss: 0.5049 - val_accuracy: 0.8540\n",
            "Epoch 654/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1827 - accuracy: 0.9300 - val_loss: 0.5035 - val_accuracy: 0.8547\n",
            "Epoch 655/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1845 - accuracy: 0.9296 - val_loss: 0.5051 - val_accuracy: 0.8569\n",
            "Epoch 656/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9304 - val_loss: 0.5009 - val_accuracy: 0.8532\n",
            "Epoch 657/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1811 - accuracy: 0.9294 - val_loss: 0.5055 - val_accuracy: 0.8540\n",
            "Epoch 658/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1860 - accuracy: 0.9287 - val_loss: 0.5009 - val_accuracy: 0.8546\n",
            "Epoch 659/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1865 - accuracy: 0.9291 - val_loss: 0.5014 - val_accuracy: 0.8527\n",
            "Epoch 660/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1850 - accuracy: 0.9294 - val_loss: 0.5022 - val_accuracy: 0.8531\n",
            "Epoch 661/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1825 - accuracy: 0.9310 - val_loss: 0.5082 - val_accuracy: 0.8543\n",
            "Epoch 662/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1823 - accuracy: 0.9308 - val_loss: 0.5080 - val_accuracy: 0.8505\n",
            "Epoch 663/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1815 - accuracy: 0.9312 - val_loss: 0.5057 - val_accuracy: 0.8511\n",
            "Epoch 664/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1833 - accuracy: 0.9305 - val_loss: 0.5063 - val_accuracy: 0.8553\n",
            "Epoch 665/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.1818 - accuracy: 0.9296 - val_loss: 0.5078 - val_accuracy: 0.8553\n",
            "Epoch 666/1500\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.1853 - accuracy: 0.9299 - val_loss: 0.5020 - val_accuracy: 0.8536\n",
            "Epoch 667/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1823 - accuracy: 0.9308 - val_loss: 0.5041 - val_accuracy: 0.8526\n",
            "Epoch 668/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1833 - accuracy: 0.9309 - val_loss: 0.5010 - val_accuracy: 0.8543\n",
            "Epoch 669/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1823 - accuracy: 0.9298 - val_loss: 0.5042 - val_accuracy: 0.8558\n",
            "Epoch 670/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1819 - accuracy: 0.9311 - val_loss: 0.5073 - val_accuracy: 0.8558\n",
            "Epoch 671/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1832 - accuracy: 0.9307 - val_loss: 0.5020 - val_accuracy: 0.8565\n",
            "Epoch 672/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1848 - accuracy: 0.9291 - val_loss: 0.5056 - val_accuracy: 0.8545\n",
            "Epoch 673/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1821 - accuracy: 0.9315 - val_loss: 0.5053 - val_accuracy: 0.8533\n",
            "Epoch 674/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1863 - accuracy: 0.9294 - val_loss: 0.5025 - val_accuracy: 0.8534\n",
            "Epoch 675/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1798 - accuracy: 0.9317 - val_loss: 0.5016 - val_accuracy: 0.8541\n",
            "Epoch 676/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9304 - val_loss: 0.5005 - val_accuracy: 0.8548\n",
            "Epoch 677/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1866 - accuracy: 0.9295 - val_loss: 0.5020 - val_accuracy: 0.8550\n",
            "Epoch 678/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1808 - accuracy: 0.9308 - val_loss: 0.5026 - val_accuracy: 0.8545\n",
            "Epoch 679/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1818 - accuracy: 0.9311 - val_loss: 0.5043 - val_accuracy: 0.8540\n",
            "Epoch 680/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9295 - val_loss: 0.5072 - val_accuracy: 0.8569\n",
            "Epoch 681/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9301 - val_loss: 0.5051 - val_accuracy: 0.8542\n",
            "Epoch 682/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1820 - accuracy: 0.9308 - val_loss: 0.5070 - val_accuracy: 0.8548\n",
            "Epoch 683/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1830 - accuracy: 0.9306 - val_loss: 0.5058 - val_accuracy: 0.8534\n",
            "Epoch 684/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1832 - accuracy: 0.9305 - val_loss: 0.5043 - val_accuracy: 0.8540\n",
            "Epoch 685/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1815 - accuracy: 0.9304 - val_loss: 0.5066 - val_accuracy: 0.8536\n",
            "Epoch 686/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9309 - val_loss: 0.5057 - val_accuracy: 0.8531\n",
            "Epoch 687/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1809 - accuracy: 0.9319 - val_loss: 0.5042 - val_accuracy: 0.8542\n",
            "Epoch 688/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1816 - accuracy: 0.9311 - val_loss: 0.5068 - val_accuracy: 0.8549\n",
            "Epoch 689/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9297 - val_loss: 0.5017 - val_accuracy: 0.8548\n",
            "Epoch 690/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9311 - val_loss: 0.5044 - val_accuracy: 0.8517\n",
            "Epoch 691/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1838 - accuracy: 0.9296 - val_loss: 0.5061 - val_accuracy: 0.8544\n",
            "Epoch 692/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1834 - accuracy: 0.9302 - val_loss: 0.5067 - val_accuracy: 0.8555\n",
            "Epoch 693/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1809 - accuracy: 0.9312 - val_loss: 0.5080 - val_accuracy: 0.8547\n",
            "Epoch 694/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1824 - accuracy: 0.9309 - val_loss: 0.5068 - val_accuracy: 0.8518\n",
            "Epoch 695/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1815 - accuracy: 0.9299 - val_loss: 0.5031 - val_accuracy: 0.8522\n",
            "Epoch 696/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1801 - accuracy: 0.9318 - val_loss: 0.5050 - val_accuracy: 0.8547\n",
            "Epoch 697/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1815 - accuracy: 0.9304 - val_loss: 0.5088 - val_accuracy: 0.8542\n",
            "Epoch 698/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1803 - accuracy: 0.9317 - val_loss: 0.5053 - val_accuracy: 0.8530\n",
            "Epoch 699/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1832 - accuracy: 0.9308 - val_loss: 0.5043 - val_accuracy: 0.8527\n",
            "Epoch 700/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1828 - accuracy: 0.9307 - val_loss: 0.5053 - val_accuracy: 0.8528\n",
            "Epoch 701/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1833 - accuracy: 0.9303 - val_loss: 0.5018 - val_accuracy: 0.8534\n",
            "Epoch 702/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9317 - val_loss: 0.5063 - val_accuracy: 0.8544\n",
            "Epoch 703/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1811 - accuracy: 0.9304 - val_loss: 0.5061 - val_accuracy: 0.8521\n",
            "Epoch 704/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1820 - accuracy: 0.9313 - val_loss: 0.5061 - val_accuracy: 0.8554\n",
            "Epoch 705/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1814 - accuracy: 0.9311 - val_loss: 0.5037 - val_accuracy: 0.8537\n",
            "Epoch 706/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1825 - accuracy: 0.9292 - val_loss: 0.5057 - val_accuracy: 0.8530\n",
            "Epoch 707/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1824 - accuracy: 0.9308 - val_loss: 0.5055 - val_accuracy: 0.8544\n",
            "Epoch 708/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1816 - accuracy: 0.9315 - val_loss: 0.5057 - val_accuracy: 0.8544\n",
            "Epoch 709/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1826 - accuracy: 0.9302 - val_loss: 0.5059 - val_accuracy: 0.8537\n",
            "Epoch 710/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9301 - val_loss: 0.5044 - val_accuracy: 0.8534\n",
            "Epoch 711/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1806 - accuracy: 0.9310 - val_loss: 0.5071 - val_accuracy: 0.8533\n",
            "Epoch 712/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1785 - accuracy: 0.9313 - val_loss: 0.5090 - val_accuracy: 0.8542\n",
            "Epoch 713/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1813 - accuracy: 0.9312 - val_loss: 0.5067 - val_accuracy: 0.8553\n",
            "Epoch 714/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1823 - accuracy: 0.9321 - val_loss: 0.5049 - val_accuracy: 0.8538\n",
            "Epoch 715/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1822 - accuracy: 0.9305 - val_loss: 0.5067 - val_accuracy: 0.8528\n",
            "Epoch 716/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1813 - accuracy: 0.9300 - val_loss: 0.5054 - val_accuracy: 0.8520\n",
            "Epoch 717/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1799 - accuracy: 0.9309 - val_loss: 0.5065 - val_accuracy: 0.8530\n",
            "Epoch 718/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1801 - accuracy: 0.9313 - val_loss: 0.5075 - val_accuracy: 0.8538\n",
            "Epoch 719/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1808 - accuracy: 0.9309 - val_loss: 0.5050 - val_accuracy: 0.8562\n",
            "Epoch 720/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1824 - accuracy: 0.9307 - val_loss: 0.5025 - val_accuracy: 0.8541\n",
            "Epoch 721/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1808 - accuracy: 0.9308 - val_loss: 0.5067 - val_accuracy: 0.8539\n",
            "Epoch 722/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1789 - accuracy: 0.9316 - val_loss: 0.5050 - val_accuracy: 0.8534\n",
            "Epoch 723/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1781 - accuracy: 0.9320 - val_loss: 0.5042 - val_accuracy: 0.8526\n",
            "Epoch 724/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1813 - accuracy: 0.9310 - val_loss: 0.5034 - val_accuracy: 0.8523\n",
            "Epoch 725/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9296 - val_loss: 0.5037 - val_accuracy: 0.8548\n",
            "Epoch 726/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1831 - accuracy: 0.9296 - val_loss: 0.5001 - val_accuracy: 0.8546\n",
            "Epoch 727/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1817 - accuracy: 0.9303 - val_loss: 0.5061 - val_accuracy: 0.8562\n",
            "Epoch 728/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1797 - accuracy: 0.9315 - val_loss: 0.5056 - val_accuracy: 0.8554\n",
            "Epoch 729/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1777 - accuracy: 0.9319 - val_loss: 0.5086 - val_accuracy: 0.8542\n",
            "Epoch 730/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1793 - accuracy: 0.9321 - val_loss: 0.5077 - val_accuracy: 0.8531\n",
            "Epoch 731/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.1812 - accuracy: 0.9314 - val_loss: 0.5049 - val_accuracy: 0.8536\n",
            "Epoch 732/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1801 - accuracy: 0.9311 - val_loss: 0.5015 - val_accuracy: 0.8545\n",
            "Epoch 733/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1813 - accuracy: 0.9300 - val_loss: 0.5091 - val_accuracy: 0.8527\n",
            "Epoch 734/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1800 - accuracy: 0.9311 - val_loss: 0.5043 - val_accuracy: 0.8548\n",
            "Epoch 735/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9317 - val_loss: 0.5028 - val_accuracy: 0.8544\n",
            "Epoch 736/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1815 - accuracy: 0.9307 - val_loss: 0.5057 - val_accuracy: 0.8539\n",
            "Epoch 737/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1813 - accuracy: 0.9313 - val_loss: 0.5029 - val_accuracy: 0.8545\n",
            "Epoch 738/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1791 - accuracy: 0.9315 - val_loss: 0.5046 - val_accuracy: 0.8538\n",
            "Epoch 739/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1810 - accuracy: 0.9311 - val_loss: 0.5010 - val_accuracy: 0.8550\n",
            "Epoch 740/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1812 - accuracy: 0.9314 - val_loss: 0.5024 - val_accuracy: 0.8560\n",
            "Epoch 741/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1846 - accuracy: 0.9294 - val_loss: 0.5051 - val_accuracy: 0.8519\n",
            "Epoch 742/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1819 - accuracy: 0.9301 - val_loss: 0.5045 - val_accuracy: 0.8542\n",
            "Epoch 743/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1789 - accuracy: 0.9316 - val_loss: 0.5080 - val_accuracy: 0.8534\n",
            "Epoch 744/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1802 - accuracy: 0.9314 - val_loss: 0.5077 - val_accuracy: 0.8533\n",
            "Epoch 745/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1789 - accuracy: 0.9326 - val_loss: 0.5077 - val_accuracy: 0.8525\n",
            "Epoch 746/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1825 - accuracy: 0.9298 - val_loss: 0.5026 - val_accuracy: 0.8565\n",
            "Epoch 747/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1826 - accuracy: 0.9304 - val_loss: 0.5068 - val_accuracy: 0.8545\n",
            "Epoch 748/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1785 - accuracy: 0.9320 - val_loss: 0.5065 - val_accuracy: 0.8539\n",
            "Epoch 749/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1798 - accuracy: 0.9323 - val_loss: 0.5066 - val_accuracy: 0.8539\n",
            "Epoch 750/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1794 - accuracy: 0.9325 - val_loss: 0.5054 - val_accuracy: 0.8546\n",
            "Epoch 751/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1833 - accuracy: 0.9307 - val_loss: 0.5000 - val_accuracy: 0.8558\n",
            "Epoch 752/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1803 - accuracy: 0.9317 - val_loss: 0.5013 - val_accuracy: 0.8516\n",
            "Epoch 753/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1812 - accuracy: 0.9307 - val_loss: 0.5044 - val_accuracy: 0.8546\n",
            "Epoch 754/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1804 - accuracy: 0.9317 - val_loss: 0.5018 - val_accuracy: 0.8552\n",
            "Epoch 755/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1783 - accuracy: 0.9328 - val_loss: 0.5027 - val_accuracy: 0.8548\n",
            "Epoch 756/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1806 - accuracy: 0.9322 - val_loss: 0.5045 - val_accuracy: 0.8550\n",
            "Epoch 757/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1786 - accuracy: 0.9323 - val_loss: 0.5021 - val_accuracy: 0.8556\n",
            "Epoch 758/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1817 - accuracy: 0.9312 - val_loss: 0.5055 - val_accuracy: 0.8550\n",
            "Epoch 759/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1801 - accuracy: 0.9315 - val_loss: 0.5012 - val_accuracy: 0.8569\n",
            "Epoch 760/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1813 - accuracy: 0.9319 - val_loss: 0.5067 - val_accuracy: 0.8556\n",
            "Epoch 761/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1802 - accuracy: 0.9309 - val_loss: 0.5025 - val_accuracy: 0.8532\n",
            "Epoch 762/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1784 - accuracy: 0.9321 - val_loss: 0.5033 - val_accuracy: 0.8548\n",
            "Epoch 763/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1778 - accuracy: 0.9325 - val_loss: 0.5053 - val_accuracy: 0.8540\n",
            "Epoch 764/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1804 - accuracy: 0.9308 - val_loss: 0.5069 - val_accuracy: 0.8531\n",
            "Epoch 765/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1802 - accuracy: 0.9319 - val_loss: 0.5042 - val_accuracy: 0.8567\n",
            "Epoch 766/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9322 - val_loss: 0.5026 - val_accuracy: 0.8540\n",
            "Epoch 767/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1806 - accuracy: 0.9306 - val_loss: 0.5072 - val_accuracy: 0.8529\n",
            "Epoch 768/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9327 - val_loss: 0.5027 - val_accuracy: 0.8534\n",
            "Epoch 769/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1801 - accuracy: 0.9315 - val_loss: 0.5069 - val_accuracy: 0.8533\n",
            "Epoch 770/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1820 - accuracy: 0.9301 - val_loss: 0.5068 - val_accuracy: 0.8548\n",
            "Epoch 771/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1780 - accuracy: 0.9324 - val_loss: 0.5083 - val_accuracy: 0.8546\n",
            "Epoch 772/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1807 - accuracy: 0.9299 - val_loss: 0.5063 - val_accuracy: 0.8559\n",
            "Epoch 773/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1777 - accuracy: 0.9325 - val_loss: 0.5061 - val_accuracy: 0.8573\n",
            "Epoch 774/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1806 - accuracy: 0.9318 - val_loss: 0.5040 - val_accuracy: 0.8553\n",
            "Epoch 775/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1803 - accuracy: 0.9317 - val_loss: 0.5066 - val_accuracy: 0.8542\n",
            "Epoch 776/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1777 - accuracy: 0.9326 - val_loss: 0.5057 - val_accuracy: 0.8533\n",
            "Epoch 777/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1822 - accuracy: 0.9300 - val_loss: 0.5021 - val_accuracy: 0.8552\n",
            "Epoch 778/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1803 - accuracy: 0.9321 - val_loss: 0.5077 - val_accuracy: 0.8537\n",
            "Epoch 779/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1789 - accuracy: 0.9319 - val_loss: 0.5041 - val_accuracy: 0.8545\n",
            "Epoch 780/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1792 - accuracy: 0.9325 - val_loss: 0.5055 - val_accuracy: 0.8560\n",
            "Epoch 781/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1805 - accuracy: 0.9311 - val_loss: 0.5014 - val_accuracy: 0.8541\n",
            "Epoch 782/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1774 - accuracy: 0.9333 - val_loss: 0.5056 - val_accuracy: 0.8545\n",
            "Epoch 783/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1783 - accuracy: 0.9323 - val_loss: 0.5039 - val_accuracy: 0.8533\n",
            "Epoch 784/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1817 - accuracy: 0.9310 - val_loss: 0.5027 - val_accuracy: 0.8537\n",
            "Epoch 785/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9307 - val_loss: 0.5015 - val_accuracy: 0.8534\n",
            "Epoch 786/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1772 - accuracy: 0.9324 - val_loss: 0.5085 - val_accuracy: 0.8544\n",
            "Epoch 787/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1798 - accuracy: 0.9310 - val_loss: 0.5118 - val_accuracy: 0.8539\n",
            "Epoch 788/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1811 - accuracy: 0.9313 - val_loss: 0.5128 - val_accuracy: 0.8506\n",
            "Epoch 789/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1774 - accuracy: 0.9327 - val_loss: 0.5105 - val_accuracy: 0.8546\n",
            "Epoch 790/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1800 - accuracy: 0.9302 - val_loss: 0.5065 - val_accuracy: 0.8561\n",
            "Epoch 791/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1782 - accuracy: 0.9322 - val_loss: 0.5076 - val_accuracy: 0.8538\n",
            "Epoch 792/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1824 - accuracy: 0.9302 - val_loss: 0.5062 - val_accuracy: 0.8533\n",
            "Epoch 793/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1785 - accuracy: 0.9319 - val_loss: 0.5088 - val_accuracy: 0.8550\n",
            "Epoch 794/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1773 - accuracy: 0.9323 - val_loss: 0.5091 - val_accuracy: 0.8549\n",
            "Epoch 795/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1789 - accuracy: 0.9326 - val_loss: 0.5084 - val_accuracy: 0.8559\n",
            "Epoch 796/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1772 - accuracy: 0.9318 - val_loss: 0.5082 - val_accuracy: 0.8545\n",
            "Epoch 797/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1798 - accuracy: 0.9316 - val_loss: 0.5072 - val_accuracy: 0.8513\n",
            "Epoch 798/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1783 - accuracy: 0.9323 - val_loss: 0.5104 - val_accuracy: 0.8524\n",
            "Epoch 799/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1788 - accuracy: 0.9325 - val_loss: 0.5093 - val_accuracy: 0.8528\n",
            "Epoch 800/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1836 - accuracy: 0.9311 - val_loss: 0.5077 - val_accuracy: 0.8531\n",
            "Epoch 801/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1773 - accuracy: 0.9329 - val_loss: 0.5091 - val_accuracy: 0.8527\n",
            "Epoch 802/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1781 - accuracy: 0.9326 - val_loss: 0.5075 - val_accuracy: 0.8539\n",
            "Epoch 803/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1774 - accuracy: 0.9333 - val_loss: 0.5126 - val_accuracy: 0.8535\n",
            "Epoch 804/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.1785 - accuracy: 0.9326 - val_loss: 0.5109 - val_accuracy: 0.8528\n",
            "Epoch 805/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1767 - accuracy: 0.9330 - val_loss: 0.5109 - val_accuracy: 0.8527\n",
            "Epoch 806/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1817 - accuracy: 0.9313 - val_loss: 0.5072 - val_accuracy: 0.8528\n",
            "Epoch 807/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1796 - accuracy: 0.9320 - val_loss: 0.5043 - val_accuracy: 0.8521\n",
            "Epoch 808/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1761 - accuracy: 0.9325 - val_loss: 0.5056 - val_accuracy: 0.8535\n",
            "Epoch 809/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1811 - accuracy: 0.9306 - val_loss: 0.5063 - val_accuracy: 0.8548\n",
            "Epoch 810/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1778 - accuracy: 0.9330 - val_loss: 0.5108 - val_accuracy: 0.8540\n",
            "Epoch 811/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1794 - accuracy: 0.9329 - val_loss: 0.5113 - val_accuracy: 0.8535\n",
            "Epoch 812/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1776 - accuracy: 0.9322 - val_loss: 0.5127 - val_accuracy: 0.8495\n",
            "Epoch 813/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1767 - accuracy: 0.9327 - val_loss: 0.5104 - val_accuracy: 0.8535\n",
            "Epoch 814/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1761 - accuracy: 0.9332 - val_loss: 0.5117 - val_accuracy: 0.8529\n",
            "Epoch 815/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1819 - accuracy: 0.9313 - val_loss: 0.5120 - val_accuracy: 0.8517\n",
            "Epoch 816/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1780 - accuracy: 0.9322 - val_loss: 0.5098 - val_accuracy: 0.8542\n",
            "Epoch 817/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1754 - accuracy: 0.9340 - val_loss: 0.5093 - val_accuracy: 0.8541\n",
            "Epoch 818/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1791 - accuracy: 0.9319 - val_loss: 0.5112 - val_accuracy: 0.8552\n",
            "Epoch 819/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1763 - accuracy: 0.9317 - val_loss: 0.5153 - val_accuracy: 0.8522\n",
            "Epoch 820/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1794 - accuracy: 0.9320 - val_loss: 0.5122 - val_accuracy: 0.8549\n",
            "Epoch 821/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1781 - accuracy: 0.9315 - val_loss: 0.5117 - val_accuracy: 0.8530\n",
            "Epoch 822/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9334 - val_loss: 0.5148 - val_accuracy: 0.8525\n",
            "Epoch 823/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1788 - accuracy: 0.9328 - val_loss: 0.5127 - val_accuracy: 0.8522\n",
            "Epoch 824/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1789 - accuracy: 0.9317 - val_loss: 0.5119 - val_accuracy: 0.8526\n",
            "Epoch 825/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1806 - accuracy: 0.9318 - val_loss: 0.5125 - val_accuracy: 0.8536\n",
            "Epoch 826/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1778 - accuracy: 0.9329 - val_loss: 0.5196 - val_accuracy: 0.8504\n",
            "Epoch 827/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1794 - accuracy: 0.9326 - val_loss: 0.5142 - val_accuracy: 0.8535\n",
            "Epoch 828/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1785 - accuracy: 0.9319 - val_loss: 0.5127 - val_accuracy: 0.8531\n",
            "Epoch 829/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1795 - accuracy: 0.9317 - val_loss: 0.5112 - val_accuracy: 0.8534\n",
            "Epoch 830/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1789 - accuracy: 0.9323 - val_loss: 0.5136 - val_accuracy: 0.8534\n",
            "Epoch 831/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1785 - accuracy: 0.9314 - val_loss: 0.5087 - val_accuracy: 0.8533\n",
            "Epoch 832/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1774 - accuracy: 0.9329 - val_loss: 0.5118 - val_accuracy: 0.8540\n",
            "Epoch 833/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1772 - accuracy: 0.9329 - val_loss: 0.5148 - val_accuracy: 0.8504\n",
            "Epoch 834/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1756 - accuracy: 0.9344 - val_loss: 0.5125 - val_accuracy: 0.8511\n",
            "Epoch 835/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1791 - accuracy: 0.9324 - val_loss: 0.5143 - val_accuracy: 0.8524\n",
            "Epoch 836/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1730 - accuracy: 0.9331 - val_loss: 0.5164 - val_accuracy: 0.8510\n",
            "Epoch 837/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1760 - accuracy: 0.9337 - val_loss: 0.5120 - val_accuracy: 0.8527\n",
            "Epoch 838/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9328 - val_loss: 0.5181 - val_accuracy: 0.8505\n",
            "Epoch 839/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1777 - accuracy: 0.9328 - val_loss: 0.5110 - val_accuracy: 0.8525\n",
            "Epoch 840/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9346 - val_loss: 0.5110 - val_accuracy: 0.8547\n",
            "Epoch 841/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1782 - accuracy: 0.9317 - val_loss: 0.5120 - val_accuracy: 0.8522\n",
            "Epoch 842/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1766 - accuracy: 0.9326 - val_loss: 0.5172 - val_accuracy: 0.8514\n",
            "Epoch 843/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1784 - accuracy: 0.9320 - val_loss: 0.5128 - val_accuracy: 0.8515\n",
            "Epoch 844/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1770 - accuracy: 0.9317 - val_loss: 0.5115 - val_accuracy: 0.8511\n",
            "Epoch 845/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1751 - accuracy: 0.9329 - val_loss: 0.5165 - val_accuracy: 0.8520\n",
            "Epoch 846/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1770 - accuracy: 0.9326 - val_loss: 0.5166 - val_accuracy: 0.8514\n",
            "Epoch 847/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1817 - accuracy: 0.9304 - val_loss: 0.5118 - val_accuracy: 0.8524\n",
            "Epoch 848/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1778 - accuracy: 0.9317 - val_loss: 0.5122 - val_accuracy: 0.8516\n",
            "Epoch 849/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1786 - accuracy: 0.9322 - val_loss: 0.5149 - val_accuracy: 0.8532\n",
            "Epoch 850/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1780 - accuracy: 0.9331 - val_loss: 0.5142 - val_accuracy: 0.8522\n",
            "Epoch 851/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9322 - val_loss: 0.5116 - val_accuracy: 0.8519\n",
            "Epoch 852/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1763 - accuracy: 0.9331 - val_loss: 0.5158 - val_accuracy: 0.8529\n",
            "Epoch 853/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1766 - accuracy: 0.9333 - val_loss: 0.5161 - val_accuracy: 0.8511\n",
            "Epoch 854/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1781 - accuracy: 0.9313 - val_loss: 0.5126 - val_accuracy: 0.8527\n",
            "Epoch 855/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1750 - accuracy: 0.9342 - val_loss: 0.5160 - val_accuracy: 0.8524\n",
            "Epoch 856/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1766 - accuracy: 0.9330 - val_loss: 0.5222 - val_accuracy: 0.8497\n",
            "Epoch 857/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1755 - accuracy: 0.9329 - val_loss: 0.5130 - val_accuracy: 0.8523\n",
            "Epoch 858/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1782 - accuracy: 0.9331 - val_loss: 0.5124 - val_accuracy: 0.8527\n",
            "Epoch 859/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1728 - accuracy: 0.9346 - val_loss: 0.5137 - val_accuracy: 0.8560\n",
            "Epoch 860/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1768 - accuracy: 0.9330 - val_loss: 0.5178 - val_accuracy: 0.8546\n",
            "Epoch 861/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1755 - accuracy: 0.9320 - val_loss: 0.5192 - val_accuracy: 0.8538\n",
            "Epoch 862/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1770 - accuracy: 0.9324 - val_loss: 0.5196 - val_accuracy: 0.8523\n",
            "Epoch 863/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1809 - accuracy: 0.9312 - val_loss: 0.5140 - val_accuracy: 0.8553\n",
            "Epoch 864/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1804 - accuracy: 0.9306 - val_loss: 0.5150 - val_accuracy: 0.8546\n",
            "Epoch 865/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1789 - accuracy: 0.9316 - val_loss: 0.5142 - val_accuracy: 0.8524\n",
            "Epoch 866/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9348 - val_loss: 0.5150 - val_accuracy: 0.8546\n",
            "Epoch 867/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1734 - accuracy: 0.9338 - val_loss: 0.5146 - val_accuracy: 0.8571\n",
            "Epoch 868/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1753 - accuracy: 0.9323 - val_loss: 0.5203 - val_accuracy: 0.8494\n",
            "Epoch 869/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1776 - accuracy: 0.9323 - val_loss: 0.5128 - val_accuracy: 0.8535\n",
            "Epoch 870/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1797 - accuracy: 0.9319 - val_loss: 0.5164 - val_accuracy: 0.8528\n",
            "Epoch 871/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9334 - val_loss: 0.5129 - val_accuracy: 0.8519\n",
            "Epoch 872/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1720 - accuracy: 0.9352 - val_loss: 0.5197 - val_accuracy: 0.8526\n",
            "Epoch 873/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1748 - accuracy: 0.9337 - val_loss: 0.5171 - val_accuracy: 0.8508\n",
            "Epoch 874/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1770 - accuracy: 0.9324 - val_loss: 0.5204 - val_accuracy: 0.8525\n",
            "Epoch 875/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1749 - accuracy: 0.9344 - val_loss: 0.5206 - val_accuracy: 0.8539\n",
            "Epoch 876/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1761 - accuracy: 0.9338 - val_loss: 0.5184 - val_accuracy: 0.8502\n",
            "Epoch 877/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1757 - accuracy: 0.9339 - val_loss: 0.5156 - val_accuracy: 0.8518\n",
            "Epoch 878/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1761 - accuracy: 0.9331 - val_loss: 0.5137 - val_accuracy: 0.8527\n",
            "Epoch 879/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1787 - accuracy: 0.9319 - val_loss: 0.5213 - val_accuracy: 0.8518\n",
            "Epoch 880/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1762 - accuracy: 0.9335 - val_loss: 0.5169 - val_accuracy: 0.8520\n",
            "Epoch 881/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1733 - accuracy: 0.9340 - val_loss: 0.5134 - val_accuracy: 0.8555\n",
            "Epoch 882/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9338 - val_loss: 0.5170 - val_accuracy: 0.8522\n",
            "Epoch 883/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1754 - accuracy: 0.9327 - val_loss: 0.5184 - val_accuracy: 0.8530\n",
            "Epoch 884/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.1797 - accuracy: 0.9322 - val_loss: 0.5135 - val_accuracy: 0.8527\n",
            "Epoch 885/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1761 - accuracy: 0.9330 - val_loss: 0.5134 - val_accuracy: 0.8535\n",
            "Epoch 886/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1774 - accuracy: 0.9324 - val_loss: 0.5126 - val_accuracy: 0.8510\n",
            "Epoch 887/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1777 - accuracy: 0.9333 - val_loss: 0.5143 - val_accuracy: 0.8546\n",
            "Epoch 888/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1756 - accuracy: 0.9335 - val_loss: 0.5197 - val_accuracy: 0.8505\n",
            "Epoch 889/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1740 - accuracy: 0.9333 - val_loss: 0.5211 - val_accuracy: 0.8519\n",
            "Epoch 890/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1780 - accuracy: 0.9326 - val_loss: 0.5176 - val_accuracy: 0.8524\n",
            "Epoch 891/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1751 - accuracy: 0.9324 - val_loss: 0.5216 - val_accuracy: 0.8515\n",
            "Epoch 892/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9330 - val_loss: 0.5184 - val_accuracy: 0.8507\n",
            "Epoch 893/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1778 - accuracy: 0.9324 - val_loss: 0.5166 - val_accuracy: 0.8517\n",
            "Epoch 894/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9337 - val_loss: 0.5179 - val_accuracy: 0.8548\n",
            "Epoch 895/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1735 - accuracy: 0.9344 - val_loss: 0.5176 - val_accuracy: 0.8538\n",
            "Epoch 896/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1781 - accuracy: 0.9322 - val_loss: 0.5212 - val_accuracy: 0.8529\n",
            "Epoch 897/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1778 - accuracy: 0.9334 - val_loss: 0.5150 - val_accuracy: 0.8527\n",
            "Epoch 898/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1764 - accuracy: 0.9326 - val_loss: 0.5171 - val_accuracy: 0.8535\n",
            "Epoch 899/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1716 - accuracy: 0.9345 - val_loss: 0.5185 - val_accuracy: 0.8537\n",
            "Epoch 900/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1786 - accuracy: 0.9317 - val_loss: 0.5207 - val_accuracy: 0.8513\n",
            "Epoch 901/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1751 - accuracy: 0.9330 - val_loss: 0.5172 - val_accuracy: 0.8526\n",
            "Epoch 902/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1790 - accuracy: 0.9313 - val_loss: 0.5133 - val_accuracy: 0.8536\n",
            "Epoch 903/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1763 - accuracy: 0.9331 - val_loss: 0.5184 - val_accuracy: 0.8541\n",
            "Epoch 904/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1755 - accuracy: 0.9332 - val_loss: 0.5177 - val_accuracy: 0.8548\n",
            "Epoch 905/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1749 - accuracy: 0.9325 - val_loss: 0.5099 - val_accuracy: 0.8515\n",
            "Epoch 906/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1781 - accuracy: 0.9325 - val_loss: 0.5139 - val_accuracy: 0.8537\n",
            "Epoch 907/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1759 - accuracy: 0.9334 - val_loss: 0.5131 - val_accuracy: 0.8537\n",
            "Epoch 908/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1779 - accuracy: 0.9319 - val_loss: 0.5118 - val_accuracy: 0.8542\n",
            "Epoch 909/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1748 - accuracy: 0.9337 - val_loss: 0.5156 - val_accuracy: 0.8510\n",
            "Epoch 910/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1760 - accuracy: 0.9326 - val_loss: 0.5174 - val_accuracy: 0.8522\n",
            "Epoch 911/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1762 - accuracy: 0.9330 - val_loss: 0.5178 - val_accuracy: 0.8549\n",
            "Epoch 912/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1759 - accuracy: 0.9334 - val_loss: 0.5152 - val_accuracy: 0.8543\n",
            "Epoch 913/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1742 - accuracy: 0.9340 - val_loss: 0.5177 - val_accuracy: 0.8511\n",
            "Epoch 914/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1729 - accuracy: 0.9350 - val_loss: 0.5153 - val_accuracy: 0.8549\n",
            "Epoch 915/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1763 - accuracy: 0.9330 - val_loss: 0.5196 - val_accuracy: 0.8513\n",
            "Epoch 916/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1780 - accuracy: 0.9330 - val_loss: 0.5117 - val_accuracy: 0.8552\n",
            "Epoch 917/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1771 - accuracy: 0.9316 - val_loss: 0.5131 - val_accuracy: 0.8539\n",
            "Epoch 918/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1751 - accuracy: 0.9337 - val_loss: 0.5146 - val_accuracy: 0.8519\n",
            "Epoch 919/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1742 - accuracy: 0.9343 - val_loss: 0.5175 - val_accuracy: 0.8525\n",
            "Epoch 920/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1739 - accuracy: 0.9330 - val_loss: 0.5176 - val_accuracy: 0.8529\n",
            "Epoch 921/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1784 - accuracy: 0.9319 - val_loss: 0.5198 - val_accuracy: 0.8520\n",
            "Epoch 922/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9328 - val_loss: 0.5166 - val_accuracy: 0.8495\n",
            "Epoch 923/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1769 - accuracy: 0.9321 - val_loss: 0.5201 - val_accuracy: 0.8502\n",
            "Epoch 924/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1739 - accuracy: 0.9330 - val_loss: 0.5181 - val_accuracy: 0.8527\n",
            "Epoch 925/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1761 - accuracy: 0.9320 - val_loss: 0.5203 - val_accuracy: 0.8509\n",
            "Epoch 926/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1764 - accuracy: 0.9324 - val_loss: 0.5168 - val_accuracy: 0.8522\n",
            "Epoch 927/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9331 - val_loss: 0.5221 - val_accuracy: 0.8491\n",
            "Epoch 928/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1734 - accuracy: 0.9345 - val_loss: 0.5212 - val_accuracy: 0.8519\n",
            "Epoch 929/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1761 - accuracy: 0.9329 - val_loss: 0.5252 - val_accuracy: 0.8503\n",
            "Epoch 930/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1772 - accuracy: 0.9320 - val_loss: 0.5192 - val_accuracy: 0.8521\n",
            "Epoch 931/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1771 - accuracy: 0.9324 - val_loss: 0.5211 - val_accuracy: 0.8536\n",
            "Epoch 932/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1795 - accuracy: 0.9322 - val_loss: 0.5175 - val_accuracy: 0.8524\n",
            "Epoch 933/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1768 - accuracy: 0.9326 - val_loss: 0.5183 - val_accuracy: 0.8510\n",
            "Epoch 934/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9334 - val_loss: 0.5195 - val_accuracy: 0.8542\n",
            "Epoch 935/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1763 - accuracy: 0.9336 - val_loss: 0.5173 - val_accuracy: 0.8524\n",
            "Epoch 936/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1747 - accuracy: 0.9336 - val_loss: 0.5139 - val_accuracy: 0.8527\n",
            "Epoch 937/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1753 - accuracy: 0.9324 - val_loss: 0.5159 - val_accuracy: 0.8524\n",
            "Epoch 938/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1747 - accuracy: 0.9333 - val_loss: 0.5189 - val_accuracy: 0.8515\n",
            "Epoch 939/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1761 - accuracy: 0.9323 - val_loss: 0.5190 - val_accuracy: 0.8533\n",
            "Epoch 940/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1726 - accuracy: 0.9341 - val_loss: 0.5205 - val_accuracy: 0.8515\n",
            "Epoch 941/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1773 - accuracy: 0.9325 - val_loss: 0.5137 - val_accuracy: 0.8528\n",
            "Epoch 942/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1748 - accuracy: 0.9336 - val_loss: 0.5155 - val_accuracy: 0.8522\n",
            "Epoch 943/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9330 - val_loss: 0.5197 - val_accuracy: 0.8498\n",
            "Epoch 944/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1733 - accuracy: 0.9334 - val_loss: 0.5205 - val_accuracy: 0.8521\n",
            "Epoch 945/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1757 - accuracy: 0.9328 - val_loss: 0.5231 - val_accuracy: 0.8511\n",
            "Epoch 946/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1760 - accuracy: 0.9331 - val_loss: 0.5173 - val_accuracy: 0.8521\n",
            "Epoch 947/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1757 - accuracy: 0.9330 - val_loss: 0.5194 - val_accuracy: 0.8532\n",
            "Epoch 948/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1783 - accuracy: 0.9333 - val_loss: 0.5192 - val_accuracy: 0.8518\n",
            "Epoch 949/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1755 - accuracy: 0.9320 - val_loss: 0.5200 - val_accuracy: 0.8532\n",
            "Epoch 950/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1773 - accuracy: 0.9323 - val_loss: 0.5201 - val_accuracy: 0.8521\n",
            "Epoch 951/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1733 - accuracy: 0.9340 - val_loss: 0.5203 - val_accuracy: 0.8522\n",
            "Epoch 952/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1724 - accuracy: 0.9356 - val_loss: 0.5206 - val_accuracy: 0.8502\n",
            "Epoch 953/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1743 - accuracy: 0.9327 - val_loss: 0.5209 - val_accuracy: 0.8512\n",
            "Epoch 954/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1749 - accuracy: 0.9332 - val_loss: 0.5169 - val_accuracy: 0.8513\n",
            "Epoch 955/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1721 - accuracy: 0.9340 - val_loss: 0.5180 - val_accuracy: 0.8533\n",
            "Epoch 956/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1747 - accuracy: 0.9328 - val_loss: 0.5206 - val_accuracy: 0.8525\n",
            "Epoch 957/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9339 - val_loss: 0.5212 - val_accuracy: 0.8524\n",
            "Epoch 958/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1735 - accuracy: 0.9345 - val_loss: 0.5181 - val_accuracy: 0.8540\n",
            "Epoch 959/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1754 - accuracy: 0.9329 - val_loss: 0.5237 - val_accuracy: 0.8539\n",
            "Epoch 960/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1756 - accuracy: 0.9327 - val_loss: 0.5180 - val_accuracy: 0.8543\n",
            "Epoch 961/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1733 - accuracy: 0.9344 - val_loss: 0.5167 - val_accuracy: 0.8518\n",
            "Epoch 962/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1778 - accuracy: 0.9324 - val_loss: 0.5206 - val_accuracy: 0.8514\n",
            "Epoch 963/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1749 - accuracy: 0.9329 - val_loss: 0.5198 - val_accuracy: 0.8515\n",
            "Epoch 964/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1724 - accuracy: 0.9340 - val_loss: 0.5202 - val_accuracy: 0.8508\n",
            "Epoch 965/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1755 - accuracy: 0.9327 - val_loss: 0.5203 - val_accuracy: 0.8535\n",
            "Epoch 966/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1727 - accuracy: 0.9328 - val_loss: 0.5211 - val_accuracy: 0.8519\n",
            "Epoch 967/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1746 - accuracy: 0.9330 - val_loss: 0.5159 - val_accuracy: 0.8524\n",
            "Epoch 968/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1737 - accuracy: 0.9339 - val_loss: 0.5169 - val_accuracy: 0.8524\n",
            "Epoch 969/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9348 - val_loss: 0.5186 - val_accuracy: 0.8548\n",
            "Epoch 970/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9337 - val_loss: 0.5220 - val_accuracy: 0.8513\n",
            "Epoch 971/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1732 - accuracy: 0.9339 - val_loss: 0.5204 - val_accuracy: 0.8528\n",
            "Epoch 972/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1748 - accuracy: 0.9339 - val_loss: 0.5185 - val_accuracy: 0.8510\n",
            "Epoch 973/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1776 - accuracy: 0.9318 - val_loss: 0.5245 - val_accuracy: 0.8503\n",
            "Epoch 974/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1785 - accuracy: 0.9322 - val_loss: 0.5179 - val_accuracy: 0.8528\n",
            "Epoch 975/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9324 - val_loss: 0.5205 - val_accuracy: 0.8519\n",
            "Epoch 976/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1760 - accuracy: 0.9323 - val_loss: 0.5199 - val_accuracy: 0.8539\n",
            "Epoch 977/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1751 - accuracy: 0.9336 - val_loss: 0.5187 - val_accuracy: 0.8517\n",
            "Epoch 978/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9351 - val_loss: 0.5153 - val_accuracy: 0.8504\n",
            "Epoch 979/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1738 - accuracy: 0.9336 - val_loss: 0.5188 - val_accuracy: 0.8537\n",
            "Epoch 980/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1754 - accuracy: 0.9322 - val_loss: 0.5185 - val_accuracy: 0.8523\n",
            "Epoch 981/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1769 - accuracy: 0.9327 - val_loss: 0.5222 - val_accuracy: 0.8507\n",
            "Epoch 982/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1758 - accuracy: 0.9342 - val_loss: 0.5221 - val_accuracy: 0.8519\n",
            "Epoch 983/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1716 - accuracy: 0.9342 - val_loss: 0.5183 - val_accuracy: 0.8506\n",
            "Epoch 984/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1746 - accuracy: 0.9335 - val_loss: 0.5177 - val_accuracy: 0.8532\n",
            "Epoch 985/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9339 - val_loss: 0.5220 - val_accuracy: 0.8516\n",
            "Epoch 986/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1732 - accuracy: 0.9337 - val_loss: 0.5182 - val_accuracy: 0.8528\n",
            "Epoch 987/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1741 - accuracy: 0.9329 - val_loss: 0.5184 - val_accuracy: 0.8533\n",
            "Epoch 988/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1702 - accuracy: 0.9354 - val_loss: 0.5170 - val_accuracy: 0.8521\n",
            "Epoch 989/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1742 - accuracy: 0.9330 - val_loss: 0.5231 - val_accuracy: 0.8505\n",
            "Epoch 990/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9340 - val_loss: 0.5210 - val_accuracy: 0.8532\n",
            "Epoch 991/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1762 - accuracy: 0.9323 - val_loss: 0.5184 - val_accuracy: 0.8526\n",
            "Epoch 992/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9331 - val_loss: 0.5187 - val_accuracy: 0.8519\n",
            "Epoch 993/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9341 - val_loss: 0.5156 - val_accuracy: 0.8517\n",
            "Epoch 994/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9344 - val_loss: 0.5220 - val_accuracy: 0.8506\n",
            "Epoch 995/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9340 - val_loss: 0.5236 - val_accuracy: 0.8492\n",
            "Epoch 996/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1745 - accuracy: 0.9323 - val_loss: 0.5219 - val_accuracy: 0.8522\n",
            "Epoch 997/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1751 - accuracy: 0.9335 - val_loss: 0.5226 - val_accuracy: 0.8525\n",
            "Epoch 998/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1753 - accuracy: 0.9334 - val_loss: 0.5224 - val_accuracy: 0.8535\n",
            "Epoch 999/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9338 - val_loss: 0.5212 - val_accuracy: 0.8503\n",
            "Epoch 1000/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1773 - accuracy: 0.9316 - val_loss: 0.5196 - val_accuracy: 0.8510\n",
            "Epoch 1001/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9356 - val_loss: 0.5236 - val_accuracy: 0.8526\n",
            "Epoch 1002/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1775 - accuracy: 0.9325 - val_loss: 0.5250 - val_accuracy: 0.8512\n",
            "Epoch 1003/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1744 - accuracy: 0.9341 - val_loss: 0.5190 - val_accuracy: 0.8530\n",
            "Epoch 1004/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1742 - accuracy: 0.9336 - val_loss: 0.5197 - val_accuracy: 0.8531\n",
            "Epoch 1005/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9324 - val_loss: 0.5180 - val_accuracy: 0.8526\n",
            "Epoch 1006/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1767 - accuracy: 0.9316 - val_loss: 0.5190 - val_accuracy: 0.8539\n",
            "Epoch 1007/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1702 - accuracy: 0.9358 - val_loss: 0.5211 - val_accuracy: 0.8536\n",
            "Epoch 1008/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9341 - val_loss: 0.5252 - val_accuracy: 0.8541\n",
            "Epoch 1009/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9339 - val_loss: 0.5222 - val_accuracy: 0.8495\n",
            "Epoch 1010/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1765 - accuracy: 0.9326 - val_loss: 0.5217 - val_accuracy: 0.8522\n",
            "Epoch 1011/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1763 - accuracy: 0.9324 - val_loss: 0.5220 - val_accuracy: 0.8503\n",
            "Epoch 1012/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1725 - accuracy: 0.9337 - val_loss: 0.5212 - val_accuracy: 0.8519\n",
            "Epoch 1013/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9334 - val_loss: 0.5189 - val_accuracy: 0.8521\n",
            "Epoch 1014/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1740 - accuracy: 0.9332 - val_loss: 0.5209 - val_accuracy: 0.8519\n",
            "Epoch 1015/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1714 - accuracy: 0.9342 - val_loss: 0.5205 - val_accuracy: 0.8531\n",
            "Epoch 1016/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1748 - accuracy: 0.9334 - val_loss: 0.5172 - val_accuracy: 0.8525\n",
            "Epoch 1017/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 0.5200 - val_accuracy: 0.8516\n",
            "Epoch 1018/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1737 - accuracy: 0.9340 - val_loss: 0.5169 - val_accuracy: 0.8501\n",
            "Epoch 1019/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9344 - val_loss: 0.5189 - val_accuracy: 0.8520\n",
            "Epoch 1020/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1726 - accuracy: 0.9346 - val_loss: 0.5158 - val_accuracy: 0.8525\n",
            "Epoch 1021/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1746 - accuracy: 0.9335 - val_loss: 0.5162 - val_accuracy: 0.8516\n",
            "Epoch 1022/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1752 - accuracy: 0.9327 - val_loss: 0.5186 - val_accuracy: 0.8514\n",
            "Epoch 1023/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 0.5175 - val_accuracy: 0.8509\n",
            "Epoch 1024/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9347 - val_loss: 0.5145 - val_accuracy: 0.8548\n",
            "Epoch 1025/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1757 - accuracy: 0.9333 - val_loss: 0.5189 - val_accuracy: 0.8537\n",
            "Epoch 1026/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1715 - accuracy: 0.9341 - val_loss: 0.5193 - val_accuracy: 0.8536\n",
            "Epoch 1027/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1740 - accuracy: 0.9345 - val_loss: 0.5189 - val_accuracy: 0.8534\n",
            "Epoch 1028/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9334 - val_loss: 0.5215 - val_accuracy: 0.8544\n",
            "Epoch 1029/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1739 - accuracy: 0.9334 - val_loss: 0.5179 - val_accuracy: 0.8534\n",
            "Epoch 1030/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1751 - accuracy: 0.9329 - val_loss: 0.5205 - val_accuracy: 0.8555\n",
            "Epoch 1031/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1735 - accuracy: 0.9348 - val_loss: 0.5248 - val_accuracy: 0.8510\n",
            "Epoch 1032/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1755 - accuracy: 0.9326 - val_loss: 0.5180 - val_accuracy: 0.8523\n",
            "Epoch 1033/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1742 - accuracy: 0.9335 - val_loss: 0.5185 - val_accuracy: 0.8550\n",
            "Epoch 1034/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1721 - accuracy: 0.9346 - val_loss: 0.5238 - val_accuracy: 0.8527\n",
            "Epoch 1035/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1728 - accuracy: 0.9344 - val_loss: 0.5252 - val_accuracy: 0.8535\n",
            "Epoch 1036/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1757 - accuracy: 0.9328 - val_loss: 0.5244 - val_accuracy: 0.8534\n",
            "Epoch 1037/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1731 - accuracy: 0.9339 - val_loss: 0.5224 - val_accuracy: 0.8525\n",
            "Epoch 1038/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1742 - accuracy: 0.9329 - val_loss: 0.5260 - val_accuracy: 0.8529\n",
            "Epoch 1039/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1734 - accuracy: 0.9331 - val_loss: 0.5228 - val_accuracy: 0.8531\n",
            "Epoch 1040/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1714 - accuracy: 0.9349 - val_loss: 0.5261 - val_accuracy: 0.8512\n",
            "Epoch 1041/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1715 - accuracy: 0.9341 - val_loss: 0.5276 - val_accuracy: 0.8541\n",
            "Epoch 1042/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.5274 - val_accuracy: 0.8531\n",
            "Epoch 1043/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1752 - accuracy: 0.9320 - val_loss: 0.5193 - val_accuracy: 0.8539\n",
            "Epoch 1044/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9348 - val_loss: 0.5215 - val_accuracy: 0.8534\n",
            "Epoch 1045/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1714 - accuracy: 0.9342 - val_loss: 0.5237 - val_accuracy: 0.8530\n",
            "Epoch 1046/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1737 - accuracy: 0.9334 - val_loss: 0.5255 - val_accuracy: 0.8508\n",
            "Epoch 1047/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1724 - accuracy: 0.9355 - val_loss: 0.5301 - val_accuracy: 0.8518\n",
            "Epoch 1048/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1735 - accuracy: 0.9336 - val_loss: 0.5278 - val_accuracy: 0.8512\n",
            "Epoch 1049/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1719 - accuracy: 0.9352 - val_loss: 0.5260 - val_accuracy: 0.8546\n",
            "Epoch 1050/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1703 - accuracy: 0.9350 - val_loss: 0.5291 - val_accuracy: 0.8509\n",
            "Epoch 1051/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9339 - val_loss: 0.5291 - val_accuracy: 0.8510\n",
            "Epoch 1052/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1737 - accuracy: 0.9335 - val_loss: 0.5268 - val_accuracy: 0.8521\n",
            "Epoch 1053/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9341 - val_loss: 0.5282 - val_accuracy: 0.8511\n",
            "Epoch 1054/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1731 - accuracy: 0.9345 - val_loss: 0.5236 - val_accuracy: 0.8529\n",
            "Epoch 1055/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1734 - accuracy: 0.9339 - val_loss: 0.5250 - val_accuracy: 0.8533\n",
            "Epoch 1056/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1726 - accuracy: 0.9348 - val_loss: 0.5238 - val_accuracy: 0.8498\n",
            "Epoch 1057/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1723 - accuracy: 0.9338 - val_loss: 0.5249 - val_accuracy: 0.8504\n",
            "Epoch 1058/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9339 - val_loss: 0.5258 - val_accuracy: 0.8542\n",
            "Epoch 1059/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9329 - val_loss: 0.5255 - val_accuracy: 0.8529\n",
            "Epoch 1060/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1723 - accuracy: 0.9339 - val_loss: 0.5259 - val_accuracy: 0.8516\n",
            "Epoch 1061/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9330 - val_loss: 0.5286 - val_accuracy: 0.8506\n",
            "Epoch 1062/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1723 - accuracy: 0.9351 - val_loss: 0.5265 - val_accuracy: 0.8534\n",
            "Epoch 1063/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1727 - accuracy: 0.9340 - val_loss: 0.5255 - val_accuracy: 0.8524\n",
            "Epoch 1064/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1713 - accuracy: 0.9343 - val_loss: 0.5252 - val_accuracy: 0.8515\n",
            "Epoch 1065/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1717 - accuracy: 0.9346 - val_loss: 0.5224 - val_accuracy: 0.8539\n",
            "Epoch 1066/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1695 - accuracy: 0.9359 - val_loss: 0.5285 - val_accuracy: 0.8544\n",
            "Epoch 1067/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1737 - accuracy: 0.9341 - val_loss: 0.5215 - val_accuracy: 0.8521\n",
            "Epoch 1068/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1712 - accuracy: 0.9356 - val_loss: 0.5263 - val_accuracy: 0.8521\n",
            "Epoch 1069/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1727 - accuracy: 0.9352 - val_loss: 0.5230 - val_accuracy: 0.8527\n",
            "Epoch 1070/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1691 - accuracy: 0.9347 - val_loss: 0.5205 - val_accuracy: 0.8498\n",
            "Epoch 1071/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9334 - val_loss: 0.5229 - val_accuracy: 0.8533\n",
            "Epoch 1072/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1722 - accuracy: 0.9348 - val_loss: 0.5282 - val_accuracy: 0.8527\n",
            "Epoch 1073/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1745 - accuracy: 0.9335 - val_loss: 0.5247 - val_accuracy: 0.8534\n",
            "Epoch 1074/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1732 - accuracy: 0.9330 - val_loss: 0.5264 - val_accuracy: 0.8525\n",
            "Epoch 1075/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1720 - accuracy: 0.9329 - val_loss: 0.5259 - val_accuracy: 0.8525\n",
            "Epoch 1076/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9361 - val_loss: 0.5226 - val_accuracy: 0.8519\n",
            "Epoch 1077/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1731 - accuracy: 0.9332 - val_loss: 0.5248 - val_accuracy: 0.8529\n",
            "Epoch 1078/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9352 - val_loss: 0.5293 - val_accuracy: 0.8502\n",
            "Epoch 1079/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1746 - accuracy: 0.9339 - val_loss: 0.5274 - val_accuracy: 0.8517\n",
            "Epoch 1080/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1720 - accuracy: 0.9349 - val_loss: 0.5288 - val_accuracy: 0.8531\n",
            "Epoch 1081/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1735 - accuracy: 0.9340 - val_loss: 0.5278 - val_accuracy: 0.8519\n",
            "Epoch 1082/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1718 - accuracy: 0.9343 - val_loss: 0.5255 - val_accuracy: 0.8520\n",
            "Epoch 1083/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1704 - accuracy: 0.9346 - val_loss: 0.5315 - val_accuracy: 0.8502\n",
            "Epoch 1084/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1759 - accuracy: 0.9326 - val_loss: 0.5296 - val_accuracy: 0.8519\n",
            "Epoch 1085/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1755 - accuracy: 0.9335 - val_loss: 0.5264 - val_accuracy: 0.8493\n",
            "Epoch 1086/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1734 - accuracy: 0.9344 - val_loss: 0.5263 - val_accuracy: 0.8507\n",
            "Epoch 1087/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1715 - accuracy: 0.9345 - val_loss: 0.5245 - val_accuracy: 0.8535\n",
            "Epoch 1088/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1719 - accuracy: 0.9345 - val_loss: 0.5271 - val_accuracy: 0.8513\n",
            "Epoch 1089/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9353 - val_loss: 0.5223 - val_accuracy: 0.8536\n",
            "Epoch 1090/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9347 - val_loss: 0.5248 - val_accuracy: 0.8536\n",
            "Epoch 1091/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1719 - accuracy: 0.9341 - val_loss: 0.5252 - val_accuracy: 0.8523\n",
            "Epoch 1092/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.5234 - val_accuracy: 0.8551\n",
            "Epoch 1093/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1747 - accuracy: 0.9332 - val_loss: 0.5225 - val_accuracy: 0.8530\n",
            "Epoch 1094/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9347 - val_loss: 0.5223 - val_accuracy: 0.8535\n",
            "Epoch 1095/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1717 - accuracy: 0.9339 - val_loss: 0.5260 - val_accuracy: 0.8504\n",
            "Epoch 1096/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1722 - accuracy: 0.9345 - val_loss: 0.5253 - val_accuracy: 0.8530\n",
            "Epoch 1097/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1718 - accuracy: 0.9339 - val_loss: 0.5288 - val_accuracy: 0.8526\n",
            "Epoch 1098/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1703 - accuracy: 0.9351 - val_loss: 0.5263 - val_accuracy: 0.8494\n",
            "Epoch 1099/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1699 - accuracy: 0.9351 - val_loss: 0.5294 - val_accuracy: 0.8506\n",
            "Epoch 1100/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1736 - accuracy: 0.9345 - val_loss: 0.5271 - val_accuracy: 0.8496\n",
            "Epoch 1101/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1734 - accuracy: 0.9333 - val_loss: 0.5249 - val_accuracy: 0.8506\n",
            "Epoch 1102/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9358 - val_loss: 0.5261 - val_accuracy: 0.8521\n",
            "Epoch 1103/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9350 - val_loss: 0.5274 - val_accuracy: 0.8520\n",
            "Epoch 1104/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1734 - accuracy: 0.9334 - val_loss: 0.5277 - val_accuracy: 0.8523\n",
            "Epoch 1105/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9349 - val_loss: 0.5307 - val_accuracy: 0.8512\n",
            "Epoch 1106/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1704 - accuracy: 0.9354 - val_loss: 0.5297 - val_accuracy: 0.8527\n",
            "Epoch 1107/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1719 - accuracy: 0.9344 - val_loss: 0.5267 - val_accuracy: 0.8529\n",
            "Epoch 1108/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1734 - accuracy: 0.9333 - val_loss: 0.5268 - val_accuracy: 0.8530\n",
            "Epoch 1109/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1716 - accuracy: 0.9348 - val_loss: 0.5264 - val_accuracy: 0.8529\n",
            "Epoch 1110/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1709 - accuracy: 0.9358 - val_loss: 0.5257 - val_accuracy: 0.8535\n",
            "Epoch 1111/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1720 - accuracy: 0.9347 - val_loss: 0.5284 - val_accuracy: 0.8515\n",
            "Epoch 1112/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1716 - accuracy: 0.9343 - val_loss: 0.5252 - val_accuracy: 0.8499\n",
            "Epoch 1113/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1705 - accuracy: 0.9349 - val_loss: 0.5280 - val_accuracy: 0.8549\n",
            "Epoch 1114/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9335 - val_loss: 0.5251 - val_accuracy: 0.8516\n",
            "Epoch 1115/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9352 - val_loss: 0.5316 - val_accuracy: 0.8519\n",
            "Epoch 1116/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9352 - val_loss: 0.5280 - val_accuracy: 0.8518\n",
            "Epoch 1117/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1747 - accuracy: 0.9334 - val_loss: 0.5316 - val_accuracy: 0.8488\n",
            "Epoch 1118/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1757 - accuracy: 0.9339 - val_loss: 0.5294 - val_accuracy: 0.8521\n",
            "Epoch 1119/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1692 - accuracy: 0.9349 - val_loss: 0.5275 - val_accuracy: 0.8553\n",
            "Epoch 1120/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9350 - val_loss: 0.5284 - val_accuracy: 0.8531\n",
            "Epoch 1121/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9351 - val_loss: 0.5301 - val_accuracy: 0.8539\n",
            "Epoch 1122/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1739 - accuracy: 0.9341 - val_loss: 0.5283 - val_accuracy: 0.8531\n",
            "Epoch 1123/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1733 - accuracy: 0.9352 - val_loss: 0.5297 - val_accuracy: 0.8526\n",
            "Epoch 1124/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1702 - accuracy: 0.9340 - val_loss: 0.5322 - val_accuracy: 0.8506\n",
            "Epoch 1125/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1739 - accuracy: 0.9327 - val_loss: 0.5319 - val_accuracy: 0.8507\n",
            "Epoch 1126/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1723 - accuracy: 0.9338 - val_loss: 0.5267 - val_accuracy: 0.8525\n",
            "Epoch 1127/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1728 - accuracy: 0.9348 - val_loss: 0.5294 - val_accuracy: 0.8515\n",
            "Epoch 1128/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9345 - val_loss: 0.5306 - val_accuracy: 0.8491\n",
            "Epoch 1129/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1723 - accuracy: 0.9339 - val_loss: 0.5291 - val_accuracy: 0.8514\n",
            "Epoch 1130/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1727 - accuracy: 0.9344 - val_loss: 0.5322 - val_accuracy: 0.8522\n",
            "Epoch 1131/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1703 - accuracy: 0.9361 - val_loss: 0.5313 - val_accuracy: 0.8501\n",
            "Epoch 1132/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1704 - accuracy: 0.9343 - val_loss: 0.5332 - val_accuracy: 0.8514\n",
            "Epoch 1133/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1718 - accuracy: 0.9342 - val_loss: 0.5339 - val_accuracy: 0.8505\n",
            "Epoch 1134/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1723 - accuracy: 0.9346 - val_loss: 0.5285 - val_accuracy: 0.8519\n",
            "Epoch 1135/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9367 - val_loss: 0.5312 - val_accuracy: 0.8524\n",
            "Epoch 1136/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1719 - accuracy: 0.9339 - val_loss: 0.5308 - val_accuracy: 0.8496\n",
            "Epoch 1137/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9347 - val_loss: 0.5269 - val_accuracy: 0.8503\n",
            "Epoch 1138/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1720 - accuracy: 0.9338 - val_loss: 0.5295 - val_accuracy: 0.8514\n",
            "Epoch 1139/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1726 - accuracy: 0.9345 - val_loss: 0.5292 - val_accuracy: 0.8519\n",
            "Epoch 1140/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9356 - val_loss: 0.5262 - val_accuracy: 0.8512\n",
            "Epoch 1141/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9354 - val_loss: 0.5339 - val_accuracy: 0.8476\n",
            "Epoch 1142/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1719 - accuracy: 0.9346 - val_loss: 0.5337 - val_accuracy: 0.8518\n",
            "Epoch 1143/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1681 - accuracy: 0.9355 - val_loss: 0.5355 - val_accuracy: 0.8478\n",
            "Epoch 1144/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9344 - val_loss: 0.5291 - val_accuracy: 0.8480\n",
            "Epoch 1145/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1720 - accuracy: 0.9345 - val_loss: 0.5305 - val_accuracy: 0.8529\n",
            "Epoch 1146/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1730 - accuracy: 0.9349 - val_loss: 0.5300 - val_accuracy: 0.8521\n",
            "Epoch 1147/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1700 - accuracy: 0.9351 - val_loss: 0.5303 - val_accuracy: 0.8527\n",
            "Epoch 1148/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1704 - accuracy: 0.9346 - val_loss: 0.5346 - val_accuracy: 0.8515\n",
            "Epoch 1149/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9369 - val_loss: 0.5330 - val_accuracy: 0.8516\n",
            "Epoch 1150/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1693 - accuracy: 0.9353 - val_loss: 0.5342 - val_accuracy: 0.8516\n",
            "Epoch 1151/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1728 - accuracy: 0.9342 - val_loss: 0.5321 - val_accuracy: 0.8498\n",
            "Epoch 1152/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9351 - val_loss: 0.5336 - val_accuracy: 0.8495\n",
            "Epoch 1153/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9350 - val_loss: 0.5322 - val_accuracy: 0.8506\n",
            "Epoch 1154/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1749 - accuracy: 0.9337 - val_loss: 0.5265 - val_accuracy: 0.8517\n",
            "Epoch 1155/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1694 - accuracy: 0.9361 - val_loss: 0.5281 - val_accuracy: 0.8522\n",
            "Epoch 1156/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1705 - accuracy: 0.9346 - val_loss: 0.5295 - val_accuracy: 0.8518\n",
            "Epoch 1157/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1710 - accuracy: 0.9359 - val_loss: 0.5276 - val_accuracy: 0.8505\n",
            "Epoch 1158/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1710 - accuracy: 0.9345 - val_loss: 0.5270 - val_accuracy: 0.8513\n",
            "Epoch 1159/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9346 - val_loss: 0.5234 - val_accuracy: 0.8520\n",
            "Epoch 1160/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1701 - accuracy: 0.9359 - val_loss: 0.5205 - val_accuracy: 0.8522\n",
            "Epoch 1161/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9343 - val_loss: 0.5225 - val_accuracy: 0.8545\n",
            "Epoch 1162/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1717 - accuracy: 0.9352 - val_loss: 0.5241 - val_accuracy: 0.8547\n",
            "Epoch 1163/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9353 - val_loss: 0.5289 - val_accuracy: 0.8541\n",
            "Epoch 1164/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9345 - val_loss: 0.5204 - val_accuracy: 0.8535\n",
            "Epoch 1165/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 0.5231 - val_accuracy: 0.8517\n",
            "Epoch 1166/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1709 - accuracy: 0.9351 - val_loss: 0.5247 - val_accuracy: 0.8505\n",
            "Epoch 1167/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1699 - accuracy: 0.9354 - val_loss: 0.5286 - val_accuracy: 0.8493\n",
            "Epoch 1168/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9345 - val_loss: 0.5301 - val_accuracy: 0.8507\n",
            "Epoch 1169/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9346 - val_loss: 0.5281 - val_accuracy: 0.8498\n",
            "Epoch 1170/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1721 - accuracy: 0.9350 - val_loss: 0.5318 - val_accuracy: 0.8482\n",
            "Epoch 1171/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1751 - accuracy: 0.9332 - val_loss: 0.5309 - val_accuracy: 0.8515\n",
            "Epoch 1172/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9353 - val_loss: 0.5353 - val_accuracy: 0.8502\n",
            "Epoch 1173/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1714 - accuracy: 0.9330 - val_loss: 0.5348 - val_accuracy: 0.8513\n",
            "Epoch 1174/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1688 - accuracy: 0.9355 - val_loss: 0.5334 - val_accuracy: 0.8519\n",
            "Epoch 1175/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.1710 - accuracy: 0.9335 - val_loss: 0.5323 - val_accuracy: 0.8524\n",
            "Epoch 1176/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1705 - accuracy: 0.9353 - val_loss: 0.5291 - val_accuracy: 0.8526\n",
            "Epoch 1177/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1679 - accuracy: 0.9351 - val_loss: 0.5310 - val_accuracy: 0.8518\n",
            "Epoch 1178/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9356 - val_loss: 0.5310 - val_accuracy: 0.8527\n",
            "Epoch 1179/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1681 - accuracy: 0.9354 - val_loss: 0.5357 - val_accuracy: 0.8506\n",
            "Epoch 1180/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1739 - accuracy: 0.9327 - val_loss: 0.5337 - val_accuracy: 0.8507\n",
            "Epoch 1181/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1707 - accuracy: 0.9352 - val_loss: 0.5324 - val_accuracy: 0.8506\n",
            "Epoch 1182/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9348 - val_loss: 0.5309 - val_accuracy: 0.8503\n",
            "Epoch 1183/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1697 - accuracy: 0.9353 - val_loss: 0.5318 - val_accuracy: 0.8504\n",
            "Epoch 1184/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1704 - accuracy: 0.9351 - val_loss: 0.5307 - val_accuracy: 0.8506\n",
            "Epoch 1185/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1722 - accuracy: 0.9340 - val_loss: 0.5329 - val_accuracy: 0.8507\n",
            "Epoch 1186/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9360 - val_loss: 0.5323 - val_accuracy: 0.8517\n",
            "Epoch 1187/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9345 - val_loss: 0.5320 - val_accuracy: 0.8522\n",
            "Epoch 1188/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1710 - accuracy: 0.9352 - val_loss: 0.5347 - val_accuracy: 0.8490\n",
            "Epoch 1189/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1715 - accuracy: 0.9347 - val_loss: 0.5309 - val_accuracy: 0.8516\n",
            "Epoch 1190/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1700 - accuracy: 0.9346 - val_loss: 0.5335 - val_accuracy: 0.8505\n",
            "Epoch 1191/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1739 - accuracy: 0.9325 - val_loss: 0.5260 - val_accuracy: 0.8525\n",
            "Epoch 1192/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9352 - val_loss: 0.5274 - val_accuracy: 0.8524\n",
            "Epoch 1193/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1705 - accuracy: 0.9341 - val_loss: 0.5288 - val_accuracy: 0.8511\n",
            "Epoch 1194/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9350 - val_loss: 0.5384 - val_accuracy: 0.8504\n",
            "Epoch 1195/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1716 - accuracy: 0.9338 - val_loss: 0.5322 - val_accuracy: 0.8495\n",
            "Epoch 1196/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1717 - accuracy: 0.9347 - val_loss: 0.5297 - val_accuracy: 0.8516\n",
            "Epoch 1197/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9353 - val_loss: 0.5357 - val_accuracy: 0.8520\n",
            "Epoch 1198/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9359 - val_loss: 0.5330 - val_accuracy: 0.8506\n",
            "Epoch 1199/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9362 - val_loss: 0.5372 - val_accuracy: 0.8505\n",
            "Epoch 1200/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9351 - val_loss: 0.5319 - val_accuracy: 0.8496\n",
            "Epoch 1201/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9362 - val_loss: 0.5384 - val_accuracy: 0.8522\n",
            "Epoch 1202/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1679 - accuracy: 0.9355 - val_loss: 0.5373 - val_accuracy: 0.8501\n",
            "Epoch 1203/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1699 - accuracy: 0.9353 - val_loss: 0.5324 - val_accuracy: 0.8505\n",
            "Epoch 1204/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1671 - accuracy: 0.9365 - val_loss: 0.5342 - val_accuracy: 0.8520\n",
            "Epoch 1205/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9353 - val_loss: 0.5321 - val_accuracy: 0.8500\n",
            "Epoch 1206/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9349 - val_loss: 0.5303 - val_accuracy: 0.8525\n",
            "Epoch 1207/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1703 - accuracy: 0.9348 - val_loss: 0.5298 - val_accuracy: 0.8527\n",
            "Epoch 1208/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1692 - accuracy: 0.9347 - val_loss: 0.5291 - val_accuracy: 0.8498\n",
            "Epoch 1209/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1718 - accuracy: 0.9340 - val_loss: 0.5326 - val_accuracy: 0.8512\n",
            "Epoch 1210/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1709 - accuracy: 0.9349 - val_loss: 0.5338 - val_accuracy: 0.8505\n",
            "Epoch 1211/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9354 - val_loss: 0.5324 - val_accuracy: 0.8500\n",
            "Epoch 1212/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9351 - val_loss: 0.5328 - val_accuracy: 0.8504\n",
            "Epoch 1213/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1713 - accuracy: 0.9344 - val_loss: 0.5342 - val_accuracy: 0.8502\n",
            "Epoch 1214/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1705 - accuracy: 0.9348 - val_loss: 0.5285 - val_accuracy: 0.8526\n",
            "Epoch 1215/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1699 - accuracy: 0.9337 - val_loss: 0.5292 - val_accuracy: 0.8511\n",
            "Epoch 1216/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1667 - accuracy: 0.9358 - val_loss: 0.5331 - val_accuracy: 0.8531\n",
            "Epoch 1217/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9344 - val_loss: 0.5330 - val_accuracy: 0.8482\n",
            "Epoch 1218/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1697 - accuracy: 0.9360 - val_loss: 0.5324 - val_accuracy: 0.8526\n",
            "Epoch 1219/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9364 - val_loss: 0.5327 - val_accuracy: 0.8511\n",
            "Epoch 1220/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9369 - val_loss: 0.5329 - val_accuracy: 0.8511\n",
            "Epoch 1221/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1706 - accuracy: 0.9342 - val_loss: 0.5328 - val_accuracy: 0.8499\n",
            "Epoch 1222/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1723 - accuracy: 0.9341 - val_loss: 0.5287 - val_accuracy: 0.8508\n",
            "Epoch 1223/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9348 - val_loss: 0.5281 - val_accuracy: 0.8522\n",
            "Epoch 1224/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1704 - accuracy: 0.9347 - val_loss: 0.5308 - val_accuracy: 0.8518\n",
            "Epoch 1225/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9365 - val_loss: 0.5331 - val_accuracy: 0.8540\n",
            "Epoch 1226/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9352 - val_loss: 0.5327 - val_accuracy: 0.8537\n",
            "Epoch 1227/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9362 - val_loss: 0.5338 - val_accuracy: 0.8533\n",
            "Epoch 1228/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.5333 - val_accuracy: 0.8531\n",
            "Epoch 1229/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1729 - accuracy: 0.9331 - val_loss: 0.5352 - val_accuracy: 0.8506\n",
            "Epoch 1230/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1714 - accuracy: 0.9336 - val_loss: 0.5283 - val_accuracy: 0.8517\n",
            "Epoch 1231/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9355 - val_loss: 0.5314 - val_accuracy: 0.8517\n",
            "Epoch 1232/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1665 - accuracy: 0.9367 - val_loss: 0.5320 - val_accuracy: 0.8527\n",
            "Epoch 1233/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1710 - accuracy: 0.9347 - val_loss: 0.5364 - val_accuracy: 0.8497\n",
            "Epoch 1234/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9339 - val_loss: 0.5307 - val_accuracy: 0.8528\n",
            "Epoch 1235/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1705 - accuracy: 0.9341 - val_loss: 0.5318 - val_accuracy: 0.8517\n",
            "Epoch 1236/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1700 - accuracy: 0.9337 - val_loss: 0.5310 - val_accuracy: 0.8520\n",
            "Epoch 1237/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9351 - val_loss: 0.5334 - val_accuracy: 0.8518\n",
            "Epoch 1238/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9354 - val_loss: 0.5302 - val_accuracy: 0.8542\n",
            "Epoch 1239/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1701 - accuracy: 0.9344 - val_loss: 0.5322 - val_accuracy: 0.8520\n",
            "Epoch 1240/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9355 - val_loss: 0.5327 - val_accuracy: 0.8495\n",
            "Epoch 1241/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1707 - accuracy: 0.9349 - val_loss: 0.5338 - val_accuracy: 0.8516\n",
            "Epoch 1242/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1709 - accuracy: 0.9341 - val_loss: 0.5287 - val_accuracy: 0.8493\n",
            "Epoch 1243/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1698 - accuracy: 0.9347 - val_loss: 0.5322 - val_accuracy: 0.8514\n",
            "Epoch 1244/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9349 - val_loss: 0.5298 - val_accuracy: 0.8504\n",
            "Epoch 1245/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9351 - val_loss: 0.5330 - val_accuracy: 0.8522\n",
            "Epoch 1246/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1680 - accuracy: 0.9363 - val_loss: 0.5357 - val_accuracy: 0.8509\n",
            "Epoch 1247/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1707 - accuracy: 0.9338 - val_loss: 0.5354 - val_accuracy: 0.8507\n",
            "Epoch 1248/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9348 - val_loss: 0.5319 - val_accuracy: 0.8538\n",
            "Epoch 1249/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9361 - val_loss: 0.5328 - val_accuracy: 0.8515\n",
            "Epoch 1250/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9356 - val_loss: 0.5353 - val_accuracy: 0.8518\n",
            "Epoch 1251/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9352 - val_loss: 0.5337 - val_accuracy: 0.8528\n",
            "Epoch 1252/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1713 - accuracy: 0.9349 - val_loss: 0.5331 - val_accuracy: 0.8522\n",
            "Epoch 1253/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1737 - accuracy: 0.9337 - val_loss: 0.5313 - val_accuracy: 0.8511\n",
            "Epoch 1254/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1694 - accuracy: 0.9354 - val_loss: 0.5310 - val_accuracy: 0.8531\n",
            "Epoch 1255/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1700 - accuracy: 0.9356 - val_loss: 0.5317 - val_accuracy: 0.8521\n",
            "Epoch 1256/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1717 - accuracy: 0.9355 - val_loss: 0.5291 - val_accuracy: 0.8535\n",
            "Epoch 1257/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1702 - accuracy: 0.9339 - val_loss: 0.5294 - val_accuracy: 0.8504\n",
            "Epoch 1258/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9359 - val_loss: 0.5346 - val_accuracy: 0.8498\n",
            "Epoch 1259/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9348 - val_loss: 0.5297 - val_accuracy: 0.8499\n",
            "Epoch 1260/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1718 - accuracy: 0.9345 - val_loss: 0.5282 - val_accuracy: 0.8529\n",
            "Epoch 1261/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1675 - accuracy: 0.9355 - val_loss: 0.5326 - val_accuracy: 0.8549\n",
            "Epoch 1262/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1706 - accuracy: 0.9343 - val_loss: 0.5320 - val_accuracy: 0.8520\n",
            "Epoch 1263/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1678 - accuracy: 0.9351 - val_loss: 0.5320 - val_accuracy: 0.8507\n",
            "Epoch 1264/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9364 - val_loss: 0.5346 - val_accuracy: 0.8508\n",
            "Epoch 1265/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1693 - accuracy: 0.9357 - val_loss: 0.5342 - val_accuracy: 0.8502\n",
            "Epoch 1266/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1677 - accuracy: 0.9351 - val_loss: 0.5312 - val_accuracy: 0.8544\n",
            "Epoch 1267/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1706 - accuracy: 0.9353 - val_loss: 0.5302 - val_accuracy: 0.8496\n",
            "Epoch 1268/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1719 - accuracy: 0.9347 - val_loss: 0.5310 - val_accuracy: 0.8536\n",
            "Epoch 1269/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9346 - val_loss: 0.5286 - val_accuracy: 0.8532\n",
            "Epoch 1270/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9356 - val_loss: 0.5284 - val_accuracy: 0.8516\n",
            "Epoch 1271/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.5324 - val_accuracy: 0.8506\n",
            "Epoch 1272/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.5267 - val_accuracy: 0.8540\n",
            "Epoch 1273/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1707 - accuracy: 0.9352 - val_loss: 0.5289 - val_accuracy: 0.8540\n",
            "Epoch 1274/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1696 - accuracy: 0.9356 - val_loss: 0.5263 - val_accuracy: 0.8528\n",
            "Epoch 1275/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1691 - accuracy: 0.9351 - val_loss: 0.5286 - val_accuracy: 0.8537\n",
            "Epoch 1276/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9352 - val_loss: 0.5298 - val_accuracy: 0.8510\n",
            "Epoch 1277/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9349 - val_loss: 0.5336 - val_accuracy: 0.8495\n",
            "Epoch 1278/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9357 - val_loss: 0.5280 - val_accuracy: 0.8517\n",
            "Epoch 1279/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9346 - val_loss: 0.5251 - val_accuracy: 0.8542\n",
            "Epoch 1280/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1699 - accuracy: 0.9342 - val_loss: 0.5303 - val_accuracy: 0.8507\n",
            "Epoch 1281/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9344 - val_loss: 0.5255 - val_accuracy: 0.8526\n",
            "Epoch 1282/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9350 - val_loss: 0.5290 - val_accuracy: 0.8519\n",
            "Epoch 1283/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9350 - val_loss: 0.5281 - val_accuracy: 0.8520\n",
            "Epoch 1284/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1708 - accuracy: 0.9339 - val_loss: 0.5287 - val_accuracy: 0.8537\n",
            "Epoch 1285/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9346 - val_loss: 0.5259 - val_accuracy: 0.8529\n",
            "Epoch 1286/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1691 - accuracy: 0.9354 - val_loss: 0.5279 - val_accuracy: 0.8515\n",
            "Epoch 1287/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1687 - accuracy: 0.9351 - val_loss: 0.5295 - val_accuracy: 0.8522\n",
            "Epoch 1288/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9352 - val_loss: 0.5287 - val_accuracy: 0.8551\n",
            "Epoch 1289/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9357 - val_loss: 0.5268 - val_accuracy: 0.8530\n",
            "Epoch 1290/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1691 - accuracy: 0.9348 - val_loss: 0.5277 - val_accuracy: 0.8527\n",
            "Epoch 1291/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1688 - accuracy: 0.9348 - val_loss: 0.5325 - val_accuracy: 0.8520\n",
            "Epoch 1292/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.1686 - accuracy: 0.9353 - val_loss: 0.5319 - val_accuracy: 0.8516\n",
            "Epoch 1293/1500\n",
            "235/235 [==============================] - 5s 14ms/step - loss: 0.1664 - accuracy: 0.9361 - val_loss: 0.5318 - val_accuracy: 0.8525\n",
            "Epoch 1294/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9359 - val_loss: 0.5292 - val_accuracy: 0.8527\n",
            "Epoch 1295/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9348 - val_loss: 0.5311 - val_accuracy: 0.8531\n",
            "Epoch 1296/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1725 - accuracy: 0.9335 - val_loss: 0.5319 - val_accuracy: 0.8524\n",
            "Epoch 1297/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1667 - accuracy: 0.9363 - val_loss: 0.5340 - val_accuracy: 0.8512\n",
            "Epoch 1298/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9364 - val_loss: 0.5361 - val_accuracy: 0.8533\n",
            "Epoch 1299/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9349 - val_loss: 0.5351 - val_accuracy: 0.8501\n",
            "Epoch 1300/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1684 - accuracy: 0.9353 - val_loss: 0.5342 - val_accuracy: 0.8524\n",
            "Epoch 1301/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9348 - val_loss: 0.5294 - val_accuracy: 0.8528\n",
            "Epoch 1302/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1695 - accuracy: 0.9353 - val_loss: 0.5329 - val_accuracy: 0.8528\n",
            "Epoch 1303/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9345 - val_loss: 0.5293 - val_accuracy: 0.8539\n",
            "Epoch 1304/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1669 - accuracy: 0.9363 - val_loss: 0.5346 - val_accuracy: 0.8518\n",
            "Epoch 1305/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1688 - accuracy: 0.9347 - val_loss: 0.5320 - val_accuracy: 0.8547\n",
            "Epoch 1306/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1646 - accuracy: 0.9369 - val_loss: 0.5329 - val_accuracy: 0.8505\n",
            "Epoch 1307/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9356 - val_loss: 0.5325 - val_accuracy: 0.8540\n",
            "Epoch 1308/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9343 - val_loss: 0.5354 - val_accuracy: 0.8517\n",
            "Epoch 1309/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9368 - val_loss: 0.5342 - val_accuracy: 0.8505\n",
            "Epoch 1310/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1665 - accuracy: 0.9357 - val_loss: 0.5301 - val_accuracy: 0.8527\n",
            "Epoch 1311/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9346 - val_loss: 0.5309 - val_accuracy: 0.8521\n",
            "Epoch 1312/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1698 - accuracy: 0.9350 - val_loss: 0.5263 - val_accuracy: 0.8539\n",
            "Epoch 1313/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9355 - val_loss: 0.5349 - val_accuracy: 0.8494\n",
            "Epoch 1314/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1666 - accuracy: 0.9367 - val_loss: 0.5286 - val_accuracy: 0.8520\n",
            "Epoch 1315/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1664 - accuracy: 0.9362 - val_loss: 0.5307 - val_accuracy: 0.8534\n",
            "Epoch 1316/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9357 - val_loss: 0.5359 - val_accuracy: 0.8526\n",
            "Epoch 1317/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1689 - accuracy: 0.9353 - val_loss: 0.5323 - val_accuracy: 0.8531\n",
            "Epoch 1318/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9343 - val_loss: 0.5327 - val_accuracy: 0.8522\n",
            "Epoch 1319/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1692 - accuracy: 0.9348 - val_loss: 0.5279 - val_accuracy: 0.8526\n",
            "Epoch 1320/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1695 - accuracy: 0.9357 - val_loss: 0.5325 - val_accuracy: 0.8514\n",
            "Epoch 1321/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.5330 - val_accuracy: 0.8539\n",
            "Epoch 1322/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9356 - val_loss: 0.5344 - val_accuracy: 0.8526\n",
            "Epoch 1323/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9365 - val_loss: 0.5382 - val_accuracy: 0.8518\n",
            "Epoch 1324/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1709 - accuracy: 0.9347 - val_loss: 0.5325 - val_accuracy: 0.8559\n",
            "Epoch 1325/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1651 - accuracy: 0.9381 - val_loss: 0.5383 - val_accuracy: 0.8504\n",
            "Epoch 1326/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9355 - val_loss: 0.5346 - val_accuracy: 0.8543\n",
            "Epoch 1327/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9367 - val_loss: 0.5327 - val_accuracy: 0.8540\n",
            "Epoch 1328/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1710 - accuracy: 0.9342 - val_loss: 0.5293 - val_accuracy: 0.8527\n",
            "Epoch 1329/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1681 - accuracy: 0.9357 - val_loss: 0.5340 - val_accuracy: 0.8514\n",
            "Epoch 1330/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9369 - val_loss: 0.5360 - val_accuracy: 0.8517\n",
            "Epoch 1331/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1682 - accuracy: 0.9356 - val_loss: 0.5380 - val_accuracy: 0.8523\n",
            "Epoch 1332/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1659 - accuracy: 0.9363 - val_loss: 0.5401 - val_accuracy: 0.8518\n",
            "Epoch 1333/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9348 - val_loss: 0.5376 - val_accuracy: 0.8524\n",
            "Epoch 1334/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1701 - accuracy: 0.9362 - val_loss: 0.5354 - val_accuracy: 0.8505\n",
            "Epoch 1335/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9362 - val_loss: 0.5351 - val_accuracy: 0.8531\n",
            "Epoch 1336/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9355 - val_loss: 0.5349 - val_accuracy: 0.8504\n",
            "Epoch 1337/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9342 - val_loss: 0.5369 - val_accuracy: 0.8504\n",
            "Epoch 1338/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1669 - accuracy: 0.9363 - val_loss: 0.5375 - val_accuracy: 0.8511\n",
            "Epoch 1339/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1679 - accuracy: 0.9355 - val_loss: 0.5314 - val_accuracy: 0.8517\n",
            "Epoch 1340/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1645 - accuracy: 0.9376 - val_loss: 0.5378 - val_accuracy: 0.8513\n",
            "Epoch 1341/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1674 - accuracy: 0.9355 - val_loss: 0.5354 - val_accuracy: 0.8534\n",
            "Epoch 1342/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9353 - val_loss: 0.5365 - val_accuracy: 0.8494\n",
            "Epoch 1343/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9353 - val_loss: 0.5370 - val_accuracy: 0.8496\n",
            "Epoch 1344/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9347 - val_loss: 0.5343 - val_accuracy: 0.8515\n",
            "Epoch 1345/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9345 - val_loss: 0.5325 - val_accuracy: 0.8533\n",
            "Epoch 1346/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1661 - accuracy: 0.9357 - val_loss: 0.5318 - val_accuracy: 0.8491\n",
            "Epoch 1347/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1643 - accuracy: 0.9363 - val_loss: 0.5303 - val_accuracy: 0.8523\n",
            "Epoch 1348/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1696 - accuracy: 0.9351 - val_loss: 0.5371 - val_accuracy: 0.8514\n",
            "Epoch 1349/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9356 - val_loss: 0.5324 - val_accuracy: 0.8513\n",
            "Epoch 1350/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9353 - val_loss: 0.5365 - val_accuracy: 0.8512\n",
            "Epoch 1351/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1687 - accuracy: 0.9358 - val_loss: 0.5365 - val_accuracy: 0.8508\n",
            "Epoch 1352/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1701 - accuracy: 0.9350 - val_loss: 0.5315 - val_accuracy: 0.8524\n",
            "Epoch 1353/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9368 - val_loss: 0.5352 - val_accuracy: 0.8500\n",
            "Epoch 1354/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1664 - accuracy: 0.9348 - val_loss: 0.5333 - val_accuracy: 0.8529\n",
            "Epoch 1355/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1661 - accuracy: 0.9365 - val_loss: 0.5393 - val_accuracy: 0.8514\n",
            "Epoch 1356/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1654 - accuracy: 0.9362 - val_loss: 0.5331 - val_accuracy: 0.8534\n",
            "Epoch 1357/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1675 - accuracy: 0.9360 - val_loss: 0.5340 - val_accuracy: 0.8529\n",
            "Epoch 1358/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1663 - accuracy: 0.9370 - val_loss: 0.5377 - val_accuracy: 0.8520\n",
            "Epoch 1359/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1692 - accuracy: 0.9349 - val_loss: 0.5398 - val_accuracy: 0.8524\n",
            "Epoch 1360/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1646 - accuracy: 0.9367 - val_loss: 0.5384 - val_accuracy: 0.8546\n",
            "Epoch 1361/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1710 - accuracy: 0.9350 - val_loss: 0.5360 - val_accuracy: 0.8525\n",
            "Epoch 1362/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1661 - accuracy: 0.9363 - val_loss: 0.5404 - val_accuracy: 0.8512\n",
            "Epoch 1363/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9361 - val_loss: 0.5356 - val_accuracy: 0.8528\n",
            "Epoch 1364/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1687 - accuracy: 0.9355 - val_loss: 0.5369 - val_accuracy: 0.8513\n",
            "Epoch 1365/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1656 - accuracy: 0.9368 - val_loss: 0.5368 - val_accuracy: 0.8508\n",
            "Epoch 1366/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9351 - val_loss: 0.5396 - val_accuracy: 0.8521\n",
            "Epoch 1367/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1670 - accuracy: 0.9355 - val_loss: 0.5349 - val_accuracy: 0.8537\n",
            "Epoch 1368/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9358 - val_loss: 0.5343 - val_accuracy: 0.8534\n",
            "Epoch 1369/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1676 - accuracy: 0.9365 - val_loss: 0.5379 - val_accuracy: 0.8534\n",
            "Epoch 1370/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1678 - accuracy: 0.9348 - val_loss: 0.5329 - val_accuracy: 0.8541\n",
            "Epoch 1371/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1678 - accuracy: 0.9357 - val_loss: 0.5369 - val_accuracy: 0.8521\n",
            "Epoch 1372/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1669 - accuracy: 0.9359 - val_loss: 0.5394 - val_accuracy: 0.8501\n",
            "Epoch 1373/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9365 - val_loss: 0.5395 - val_accuracy: 0.8516\n",
            "Epoch 1374/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1658 - accuracy: 0.9366 - val_loss: 0.5358 - val_accuracy: 0.8525\n",
            "Epoch 1375/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9348 - val_loss: 0.5361 - val_accuracy: 0.8528\n",
            "Epoch 1376/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9366 - val_loss: 0.5354 - val_accuracy: 0.8542\n",
            "Epoch 1377/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1717 - accuracy: 0.9342 - val_loss: 0.5381 - val_accuracy: 0.8501\n",
            "Epoch 1378/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1667 - accuracy: 0.9366 - val_loss: 0.5354 - val_accuracy: 0.8545\n",
            "Epoch 1379/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9351 - val_loss: 0.5385 - val_accuracy: 0.8510\n",
            "Epoch 1380/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1655 - accuracy: 0.9360 - val_loss: 0.5371 - val_accuracy: 0.8526\n",
            "Epoch 1381/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.5415 - val_accuracy: 0.8529\n",
            "Epoch 1382/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9355 - val_loss: 0.5384 - val_accuracy: 0.8529\n",
            "Epoch 1383/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1684 - accuracy: 0.9356 - val_loss: 0.5316 - val_accuracy: 0.8534\n",
            "Epoch 1384/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1651 - accuracy: 0.9367 - val_loss: 0.5392 - val_accuracy: 0.8506\n",
            "Epoch 1385/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1683 - accuracy: 0.9350 - val_loss: 0.5333 - val_accuracy: 0.8541\n",
            "Epoch 1386/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1697 - accuracy: 0.9343 - val_loss: 0.5366 - val_accuracy: 0.8522\n",
            "Epoch 1387/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1650 - accuracy: 0.9376 - val_loss: 0.5363 - val_accuracy: 0.8526\n",
            "Epoch 1388/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1698 - accuracy: 0.9348 - val_loss: 0.5340 - val_accuracy: 0.8521\n",
            "Epoch 1389/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9351 - val_loss: 0.5320 - val_accuracy: 0.8537\n",
            "Epoch 1390/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1683 - accuracy: 0.9356 - val_loss: 0.5405 - val_accuracy: 0.8504\n",
            "Epoch 1391/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1675 - accuracy: 0.9367 - val_loss: 0.5359 - val_accuracy: 0.8527\n",
            "Epoch 1392/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1689 - accuracy: 0.9355 - val_loss: 0.5377 - val_accuracy: 0.8520\n",
            "Epoch 1393/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1686 - accuracy: 0.9357 - val_loss: 0.5386 - val_accuracy: 0.8521\n",
            "Epoch 1394/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9369 - val_loss: 0.5335 - val_accuracy: 0.8527\n",
            "Epoch 1395/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.5383 - val_accuracy: 0.8518\n",
            "Epoch 1396/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1675 - accuracy: 0.9360 - val_loss: 0.5361 - val_accuracy: 0.8531\n",
            "Epoch 1397/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1633 - accuracy: 0.9366 - val_loss: 0.5367 - val_accuracy: 0.8536\n",
            "Epoch 1398/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1661 - accuracy: 0.9359 - val_loss: 0.5370 - val_accuracy: 0.8508\n",
            "Epoch 1399/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1664 - accuracy: 0.9371 - val_loss: 0.5394 - val_accuracy: 0.8513\n",
            "Epoch 1400/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9344 - val_loss: 0.5356 - val_accuracy: 0.8551\n",
            "Epoch 1401/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1672 - accuracy: 0.9357 - val_loss: 0.5386 - val_accuracy: 0.8538\n",
            "Epoch 1402/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1654 - accuracy: 0.9357 - val_loss: 0.5413 - val_accuracy: 0.8513\n",
            "Epoch 1403/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1648 - accuracy: 0.9369 - val_loss: 0.5394 - val_accuracy: 0.8521\n",
            "Epoch 1404/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9357 - val_loss: 0.5386 - val_accuracy: 0.8531\n",
            "Epoch 1405/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9366 - val_loss: 0.5359 - val_accuracy: 0.8553\n",
            "Epoch 1406/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9347 - val_loss: 0.5367 - val_accuracy: 0.8541\n",
            "Epoch 1407/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1660 - accuracy: 0.9368 - val_loss: 0.5408 - val_accuracy: 0.8528\n",
            "Epoch 1408/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1677 - accuracy: 0.9359 - val_loss: 0.5380 - val_accuracy: 0.8520\n",
            "Epoch 1409/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1688 - accuracy: 0.9354 - val_loss: 0.5360 - val_accuracy: 0.8526\n",
            "Epoch 1410/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1658 - accuracy: 0.9367 - val_loss: 0.5351 - val_accuracy: 0.8537\n",
            "Epoch 1411/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9356 - val_loss: 0.5378 - val_accuracy: 0.8530\n",
            "Epoch 1412/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1652 - accuracy: 0.9357 - val_loss: 0.5412 - val_accuracy: 0.8515\n",
            "Epoch 1413/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1660 - accuracy: 0.9372 - val_loss: 0.5375 - val_accuracy: 0.8538\n",
            "Epoch 1414/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1682 - accuracy: 0.9355 - val_loss: 0.5382 - val_accuracy: 0.8536\n",
            "Epoch 1415/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1671 - accuracy: 0.9356 - val_loss: 0.5345 - val_accuracy: 0.8544\n",
            "Epoch 1416/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1688 - accuracy: 0.9356 - val_loss: 0.5383 - val_accuracy: 0.8527\n",
            "Epoch 1417/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1646 - accuracy: 0.9367 - val_loss: 0.5384 - val_accuracy: 0.8529\n",
            "Epoch 1418/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9371 - val_loss: 0.5417 - val_accuracy: 0.8515\n",
            "Epoch 1419/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.5374 - val_accuracy: 0.8523\n",
            "Epoch 1420/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1649 - accuracy: 0.9367 - val_loss: 0.5401 - val_accuracy: 0.8503\n",
            "Epoch 1421/1500\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.1683 - accuracy: 0.9367 - val_loss: 0.5377 - val_accuracy: 0.8528\n",
            "Epoch 1422/1500\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.1705 - accuracy: 0.9331 - val_loss: 0.5386 - val_accuracy: 0.8500\n",
            "Epoch 1423/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1670 - accuracy: 0.9354 - val_loss: 0.5314 - val_accuracy: 0.8525\n",
            "Epoch 1424/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1661 - accuracy: 0.9363 - val_loss: 0.5400 - val_accuracy: 0.8508\n",
            "Epoch 1425/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.5363 - val_accuracy: 0.8518\n",
            "Epoch 1426/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1675 - accuracy: 0.9352 - val_loss: 0.5396 - val_accuracy: 0.8517\n",
            "Epoch 1427/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1699 - accuracy: 0.9345 - val_loss: 0.5388 - val_accuracy: 0.8515\n",
            "Epoch 1428/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.5395 - val_accuracy: 0.8540\n",
            "Epoch 1429/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1637 - accuracy: 0.9371 - val_loss: 0.5399 - val_accuracy: 0.8504\n",
            "Epoch 1430/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1658 - accuracy: 0.9373 - val_loss: 0.5392 - val_accuracy: 0.8524\n",
            "Epoch 1431/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1676 - accuracy: 0.9370 - val_loss: 0.5403 - val_accuracy: 0.8533\n",
            "Epoch 1432/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1673 - accuracy: 0.9372 - val_loss: 0.5381 - val_accuracy: 0.8512\n",
            "Epoch 1433/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9364 - val_loss: 0.5371 - val_accuracy: 0.8517\n",
            "Epoch 1434/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1651 - accuracy: 0.9369 - val_loss: 0.5355 - val_accuracy: 0.8513\n",
            "Epoch 1435/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1639 - accuracy: 0.9373 - val_loss: 0.5384 - val_accuracy: 0.8512\n",
            "Epoch 1436/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1680 - accuracy: 0.9358 - val_loss: 0.5369 - val_accuracy: 0.8540\n",
            "Epoch 1437/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1669 - accuracy: 0.9363 - val_loss: 0.5380 - val_accuracy: 0.8519\n",
            "Epoch 1438/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9367 - val_loss: 0.5383 - val_accuracy: 0.8506\n",
            "Epoch 1439/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1695 - accuracy: 0.9360 - val_loss: 0.5374 - val_accuracy: 0.8538\n",
            "Epoch 1440/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1633 - accuracy: 0.9378 - val_loss: 0.5405 - val_accuracy: 0.8523\n",
            "Epoch 1441/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1667 - accuracy: 0.9361 - val_loss: 0.5349 - val_accuracy: 0.8522\n",
            "Epoch 1442/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1657 - accuracy: 0.9373 - val_loss: 0.5389 - val_accuracy: 0.8529\n",
            "Epoch 1443/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9354 - val_loss: 0.5390 - val_accuracy: 0.8503\n",
            "Epoch 1444/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1671 - accuracy: 0.9359 - val_loss: 0.5403 - val_accuracy: 0.8502\n",
            "Epoch 1445/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1666 - accuracy: 0.9364 - val_loss: 0.5412 - val_accuracy: 0.8513\n",
            "Epoch 1446/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1682 - accuracy: 0.9359 - val_loss: 0.5365 - val_accuracy: 0.8537\n",
            "Epoch 1447/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1690 - accuracy: 0.9356 - val_loss: 0.5350 - val_accuracy: 0.8516\n",
            "Epoch 1448/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1693 - accuracy: 0.9352 - val_loss: 0.5359 - val_accuracy: 0.8502\n",
            "Epoch 1449/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1634 - accuracy: 0.9372 - val_loss: 0.5339 - val_accuracy: 0.8522\n",
            "Epoch 1450/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1646 - accuracy: 0.9372 - val_loss: 0.5413 - val_accuracy: 0.8504\n",
            "Epoch 1451/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1669 - accuracy: 0.9357 - val_loss: 0.5405 - val_accuracy: 0.8513\n",
            "Epoch 1452/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1685 - accuracy: 0.9350 - val_loss: 0.5369 - val_accuracy: 0.8516\n",
            "Epoch 1453/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9358 - val_loss: 0.5369 - val_accuracy: 0.8523\n",
            "Epoch 1454/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1670 - accuracy: 0.9362 - val_loss: 0.5344 - val_accuracy: 0.8522\n",
            "Epoch 1455/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1657 - accuracy: 0.9363 - val_loss: 0.5356 - val_accuracy: 0.8521\n",
            "Epoch 1456/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9358 - val_loss: 0.5433 - val_accuracy: 0.8510\n",
            "Epoch 1457/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1670 - accuracy: 0.9361 - val_loss: 0.5396 - val_accuracy: 0.8531\n",
            "Epoch 1458/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1662 - accuracy: 0.9359 - val_loss: 0.5383 - val_accuracy: 0.8506\n",
            "Epoch 1459/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1644 - accuracy: 0.9370 - val_loss: 0.5388 - val_accuracy: 0.8529\n",
            "Epoch 1460/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1654 - accuracy: 0.9360 - val_loss: 0.5384 - val_accuracy: 0.8525\n",
            "Epoch 1461/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1661 - accuracy: 0.9370 - val_loss: 0.5451 - val_accuracy: 0.8534\n",
            "Epoch 1462/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1647 - accuracy: 0.9367 - val_loss: 0.5377 - val_accuracy: 0.8526\n",
            "Epoch 1463/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1658 - accuracy: 0.9369 - val_loss: 0.5384 - val_accuracy: 0.8514\n",
            "Epoch 1464/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1656 - accuracy: 0.9359 - val_loss: 0.5452 - val_accuracy: 0.8531\n",
            "Epoch 1465/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1694 - accuracy: 0.9351 - val_loss: 0.5402 - val_accuracy: 0.8509\n",
            "Epoch 1466/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1670 - accuracy: 0.9352 - val_loss: 0.5396 - val_accuracy: 0.8540\n",
            "Epoch 1467/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9364 - val_loss: 0.5347 - val_accuracy: 0.8540\n",
            "Epoch 1468/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.5365 - val_accuracy: 0.8549\n",
            "Epoch 1469/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1659 - accuracy: 0.9369 - val_loss: 0.5404 - val_accuracy: 0.8517\n",
            "Epoch 1470/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1650 - accuracy: 0.9369 - val_loss: 0.5393 - val_accuracy: 0.8506\n",
            "Epoch 1471/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1671 - accuracy: 0.9364 - val_loss: 0.5350 - val_accuracy: 0.8526\n",
            "Epoch 1472/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1656 - accuracy: 0.9373 - val_loss: 0.5375 - val_accuracy: 0.8509\n",
            "Epoch 1473/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1660 - accuracy: 0.9367 - val_loss: 0.5312 - val_accuracy: 0.8548\n",
            "Epoch 1474/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1645 - accuracy: 0.9376 - val_loss: 0.5369 - val_accuracy: 0.8546\n",
            "Epoch 1475/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9339 - val_loss: 0.5414 - val_accuracy: 0.8522\n",
            "Epoch 1476/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9356 - val_loss: 0.5363 - val_accuracy: 0.8524\n",
            "Epoch 1477/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1648 - accuracy: 0.9364 - val_loss: 0.5394 - val_accuracy: 0.8509\n",
            "Epoch 1478/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1672 - accuracy: 0.9356 - val_loss: 0.5386 - val_accuracy: 0.8525\n",
            "Epoch 1479/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1698 - accuracy: 0.9347 - val_loss: 0.5385 - val_accuracy: 0.8529\n",
            "Epoch 1480/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1642 - accuracy: 0.9376 - val_loss: 0.5421 - val_accuracy: 0.8510\n",
            "Epoch 1481/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1653 - accuracy: 0.9373 - val_loss: 0.5406 - val_accuracy: 0.8545\n",
            "Epoch 1482/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1641 - accuracy: 0.9378 - val_loss: 0.5374 - val_accuracy: 0.8527\n",
            "Epoch 1483/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1631 - accuracy: 0.9377 - val_loss: 0.5371 - val_accuracy: 0.8533\n",
            "Epoch 1484/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1657 - accuracy: 0.9364 - val_loss: 0.5400 - val_accuracy: 0.8529\n",
            "Epoch 1485/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9358 - val_loss: 0.5398 - val_accuracy: 0.8523\n",
            "Epoch 1486/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1641 - accuracy: 0.9366 - val_loss: 0.5385 - val_accuracy: 0.8520\n",
            "Epoch 1487/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1660 - accuracy: 0.9368 - val_loss: 0.5398 - val_accuracy: 0.8506\n",
            "Epoch 1488/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1659 - accuracy: 0.9361 - val_loss: 0.5366 - val_accuracy: 0.8541\n",
            "Epoch 1489/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1638 - accuracy: 0.9376 - val_loss: 0.5400 - val_accuracy: 0.8532\n",
            "Epoch 1490/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1665 - accuracy: 0.9355 - val_loss: 0.5375 - val_accuracy: 0.8511\n",
            "Epoch 1491/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1666 - accuracy: 0.9360 - val_loss: 0.5376 - val_accuracy: 0.8518\n",
            "Epoch 1492/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1638 - accuracy: 0.9379 - val_loss: 0.5400 - val_accuracy: 0.8534\n",
            "Epoch 1493/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1669 - accuracy: 0.9350 - val_loss: 0.5371 - val_accuracy: 0.8531\n",
            "Epoch 1494/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1669 - accuracy: 0.9368 - val_loss: 0.5389 - val_accuracy: 0.8536\n",
            "Epoch 1495/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1635 - accuracy: 0.9370 - val_loss: 0.5380 - val_accuracy: 0.8526\n",
            "Epoch 1496/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1640 - accuracy: 0.9365 - val_loss: 0.5430 - val_accuracy: 0.8543\n",
            "Epoch 1497/1500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1650 - accuracy: 0.9365 - val_loss: 0.5399 - val_accuracy: 0.8546\n",
            "Epoch 1498/1500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1643 - accuracy: 0.9364 - val_loss: 0.5455 - val_accuracy: 0.8514\n",
            "Epoch 1499/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1665 - accuracy: 0.9369 - val_loss: 0.5448 - val_accuracy: 0.8527\n",
            "Epoch 1500/1500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1689 - accuracy: 0.9353 - val_loss: 0.5340 - val_accuracy: 0.8532\n",
            "===============Save loss and acc===============\n",
            "===============get spin===============\n",
            "===============get calc===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.20it/s]\n",
            "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
          ]
        }
      ],
      "source": [
        "print('='*15+'Data Load'+'='*15)\n",
        "set_seed(seed=CFG.data_seed)\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "del fashion_mnist\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print('='*15+'Preprocess data'+'='*15)\n",
        "X_train, X_test = preprocess_data(X_train, X_test)\n",
        "\n",
        "\n",
        "idx = np.random.choice(X_train.shape[0], size=CFG.M, replace=False)\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "print('N_classes:',n_classes)\n",
        "print('Train size:',X_train.shape, 'Test size:', y_train.shape)\n",
        "\n",
        "\n",
        "print('='*15+'PCA'+'='*15)\n",
        "X_train,X_test, pca1, scaler1 = PCA_SS_func(X_train, X_test)\n",
        "print('Train size after PCA:',X_train.shape, 'Test size after PCA:', X_test.shape)\n",
        "\n",
        "if CFG.M == 60000:\n",
        "  print('M=60000')\n",
        "  idx = np.random.choice(X_train.shape[0], size=6000, replace=False)\n",
        "  X_train_ = X_train[idx]\n",
        "  y_train_ = y_train[idx]\n",
        "  print('X_train for mesure:',X_train_.shape,'y_train for mesure:',y_train_.shape, )\n",
        "\n",
        "print('='*15+'get_mask'+'='*15)\n",
        "mask_list = []\n",
        "for i in range(CFG.L-1):\n",
        "  mask = get_mask(shape=(100,100),C=CFG.C)\n",
        "  mask_list.append(mask)\n",
        "\n",
        "if CFG.task == 'classification':\n",
        "  mask = get_mask(shape=(100,10),C=CFG.C)\n",
        "  mask_list.append(mask)\n",
        "\n",
        "\n",
        "print('='*15+'Build model1'+'='*15)\n",
        "set_seed(CFG.seed1)\n",
        "w_intializer1 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "model1 = create_model(params=model_params, w_initializer=w_intializer1,Mask_list=mask_list)\n",
        "print(model1.layers[3].get_weights()[0])\n",
        "\n",
        "print('='*15+'Train model1'+'='*15)\n",
        "history1 = model1.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='001')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform001_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history1.history, handle)\n",
        "\n",
        "\n",
        "print('='*15+'build model2'+'='*15)\n",
        "set_seed(CFG.seed2)\n",
        "w_intializer2 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "model2 = create_model(params=model_params, w_initializer=w_intializer2, Mask_list=mask_list)\n",
        "print(model2.layers[3].get_weights()[0])\n",
        "print('='*15+'Train model2'+'='*15)\n",
        "history2 = model2.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='002')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform002_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history2.history, handle)\n",
        "\n",
        "print('='*15+'get spin'+'='*15)\n",
        "with open(f'./Output/Spin/M{CFG.M}/model001_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_A=pickle.loads(f.read())\n",
        "\n",
        "with open(f'./Output/Spin/M{CFG.M}/model002_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_B=pickle.loads(f.read())\n",
        "\n",
        "\n",
        "print('='*15+'get calc'+'='*15)\n",
        "A_norm, B_norm = get_normalized_spin(spin_A, spin_B)\n",
        "qab, qaa, q2 = get_q2(A_norm,B_norm)\n",
        "layer_q = get_layer_overlap(qab,qaa,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKgIOyX5Ifra",
        "outputId": "e5cc8d8d-5c93-4e57-b3df-43d111330851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5554974 , 0.41611877, 0.6853589 , ..., 0.46637967, 0.5933072 ,\n",
              "        0.62960565],\n",
              "       [0.50903034, 0.41271752, 0.4183731 , ..., 0.52093285, 0.37295356,\n",
              "        0.5466342 ],\n",
              "       [0.5772942 , 0.5577097 , 0.559672  , ..., 0.39791462, 0.48866946,\n",
              "        0.41233742],\n",
              "       ...,\n",
              "       [0.52792096, 0.634394  , 0.5156597 , ..., 0.5708189 , 0.5270455 ,\n",
              "        0.55502146],\n",
              "       [0.7703586 , 0.63596606, 0.33139995, ..., 0.39232844, 0.61132675,\n",
              "        0.6333111 ],\n",
              "       [0.5556694 , 0.528474  , 0.35455886, ..., 0.31359658, 0.59010214,\n",
              "        0.48215544]], dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.layers[3].get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWtWJuuRIzeb",
        "outputId": "97719d0b-eba4-4f06-c334-c02f77bb744e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.60707605, 0.62318873, 0.49948236, ..., 0.5055981 , 0.5884864 ,\n",
              "        0.49151805],\n",
              "       [0.5248788 , 0.46442148, 0.59005594, ..., 0.27667317, 0.457283  ,\n",
              "        0.47383314],\n",
              "       [0.5594902 , 0.47122252, 0.2843042 , ..., 0.5993855 , 0.59575015,\n",
              "        0.5694343 ],\n",
              "       ...,\n",
              "       [0.3556454 , 0.45203435, 0.5141023 , ..., 0.33416975, 0.6285027 ,\n",
              "        0.5519512 ],\n",
              "       [0.5439774 , 0.51687604, 0.612774  , ..., 0.42206675, 0.42387837,\n",
              "        0.50127476],\n",
              "       [0.52299255, 0.4855569 , 0.4749592 , ..., 0.46458545, 0.48944747,\n",
              "        0.34632617]], dtype=float32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.layers[3].get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FelB4lyGKgHj"
      },
      "outputs": [],
      "source": [
        "def calc_q_(A: np.ndarray, B: np.ndarray) -> float:\n",
        "    M, N = A.shape\n",
        "    dot_product = np.dot(A.T, B)\n",
        "    x = np.sum(dot_product ** 2)\n",
        "    x /= N * M * M\n",
        "    x -= N / M\n",
        "    return x\n",
        "\n",
        "def get_q2(spinA, spinB):\n",
        "    qab_dict={'time':spinA['time']}#時刻の初期化\n",
        "    qaa_dict={'time':spinA['time']}\n",
        "    q2_dict={'time':spinA['time']}\n",
        "    for l in tqdm(CFG.layer_name_list):\n",
        "        qab_list=[]\n",
        "        qaa_list=[]\n",
        "        q2_list=[]\n",
        "        for i in range(len(spinA[l])):\n",
        "            ab = calc_q_(spinA[l][i],spinB[l][i])\n",
        "            aa= calc_q_(spinA[l][i],spinA[l][i])\n",
        "            bb = calc_q_(spinB[l][i],spinB[l][i])\n",
        "            q2 = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
        "            qab_list.append(ab)\n",
        "            qaa_list.append(aa)\n",
        "            q2_list.append(q2)\n",
        "        qab_dict[l] = qab_list\n",
        "        qaa_dict[l] = qaa_list\n",
        "        q2_dict[l] = q2_list\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qab_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qab_dict, handle)\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qaa_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qaa_dict, handle)\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/M{CFG.M}/q2_norm_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(q2_dict, handle)\n",
        "    return qab_dict, qaa_dict, q2_dict\n",
        "\n",
        "\n",
        "\n",
        "def get_layer_overlap(qab:dict,qaa:dict,q2:dict):\n",
        "  layer_dict={}\n",
        "  layer_q2=[]\n",
        "  layer_qab=[]\n",
        "  layer_qaa=[]\n",
        "\n",
        "  for i, l in enumerate(CFG.layer_name_list):\n",
        "      layer_q2.append(q2[l][-1])#平衡状態のOverlapを取得\n",
        "      layer_qab.append(qab[l][-1])\n",
        "      layer_qaa.append(qaa[l][-1])\n",
        "  layer_dict['q2']=layer_q2\n",
        "  layer_dict['qab']=layer_qab\n",
        "  layer_dict['qaa']=layer_qaa\n",
        "\n",
        "  with open(f'./Output/Overlap/Layer_q/M{CFG.M}/layerq_norm_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(layer_dict, handle)\n",
        "  return layer_dict\n",
        "\n",
        "def get_normalized_spin(SpinA, SpinB):\n",
        "  spinA_norm = SpinA.copy()\n",
        "  spinB_norm = SpinB.copy()\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "        squared_sum_A = np.sum(SpinA[l]**2, axis=2)\n",
        "        squared_sum_B = np.sum(SpinB[l]**2, axis=2)\n",
        "        # 規格化定数を計算\n",
        "        normalization_constA = np.sqrt(100 / squared_sum_A)\n",
        "        normalization_constB = np.sqrt(100 / squared_sum_B)\n",
        "        # 規格化した配列を計算\n",
        "        spinA_norm[l] = SpinA[l] * normalization_constA[:, :, np.newaxis]\n",
        "        spinB_norm[l] = SpinB[l] * normalization_constB[:, :, np.newaxis]\n",
        "\n",
        "  return spinA_norm, spinB_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBsFv6RzyKIv"
      },
      "outputs": [],
      "source": [
        "with open(f'./Output/Spin/M{CFG.M}/model001_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_A=pickle.loads(f.read())\n",
        "\n",
        "with open(f'./Output/Spin/M{CFG.M}/model002_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_B=pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2AkBEzQ_BfK7",
        "outputId": "29ebe711-ab5b-4919-973f-e78b445d6b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7de1846d2110>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "for i, l in enumerate(CFG.layer_name_list):\n",
        "    ax.plot(q2['time'],q2[l],label=f'layer{i}')\n",
        "ax.set_xlabel('Epoch',fontsize=16)\n",
        "ax.set_ylabel('q2', fontsize=16)\n",
        "#ax.set_xscale('log')\n",
        "ax.set_title(f'Train Data (M:{CFG.M} L:{CFG.L})',fontsize=16)\n",
        "#ax.set_ylim(0,1)\n",
        "ax.grid(axis='y')\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TAG-8rYn2sD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMFq0YGG2u3krQE5CJKD+H8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}